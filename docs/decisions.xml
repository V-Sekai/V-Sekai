<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>V-Sekai - Manuals</title>
<link>https://v-sekai.github.io/manuals/decisions.html</link>
<atom:link href="https://v-sekai.github.io/manuals/decisions.xml" rel="self" type="application/rss+xml"/>
<description></description>
<generator>quarto-1.3.450</generator>
<lastBuildDate>Wed, 25 Oct 2023 19:05:30 GMT</lastBuildDate>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/present-proposal-template.html</link>
  <description><![CDATA[ 



<section id="overcoming-a-v-sekai-limit" class="level1">
<h1>Overcoming a V-Sekai limit</h1>
<section id="metadata" class="level2">
<h2 class="anchored" data-anchor-id="metadata">Metadata</h2>
<ul>
<li>Status: Proposed <!-- Draft | Proposed | Rejected | Accepted | Deprecated | Superseded by --><br>
</li>
<li>Deciders: V-Sekai<br>
</li>
<li>Tags: V-Sekai</li>
</ul>
</section>
<section id="the-backdrop" class="level2">
<h2 class="anchored" data-anchor-id="the-backdrop">The Backdrop</h2>
</section>
<section id="the-challenge" class="level2">
<h2 class="anchored" data-anchor-id="the-challenge">The Challenge</h2>
</section>
<section id="the-strategy" class="level2">
<h2 class="anchored" data-anchor-id="the-strategy">The Strategy</h2>
</section>
<section id="the-upside" class="level2">
<h2 class="anchored" data-anchor-id="the-upside">The Upside</h2>
</section>
<section id="the-downside" class="level2">
<h2 class="anchored" data-anchor-id="the-downside">The Downside</h2>
</section>
<section id="the-road-not-taken" class="level2">
<h2 class="anchored" data-anchor-id="the-road-not-taken">The Road Not Taken</h2>
</section>
<section id="the-infrequent-use-case" class="level2">
<h2 class="anchored" data-anchor-id="the-infrequent-use-case">The Infrequent Use Case</h2>
</section>
<section id="in-core-and-done-by-us" class="level2">
<h2 class="anchored" data-anchor-id="in-core-and-done-by-us">In Core and Done by Us?</h2>
</section>
<section id="further-reading" class="level2">
<h2 class="anchored" data-anchor-id="further-reading">Further Reading</h2>
<ul>
<li><a href="https://github.com/v-sekai/">V-Sekai</a></li>
<li>AI assists this article.</li>
</ul>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/present-proposal-template.html</guid>
  <pubDate>Wed, 25 Oct 2023 19:05:30 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20231024-training-simulators.html</link>
  <description><![CDATA[ 



<section id="implementing-advanced-training-simulators-in-v-sekai" class="level1">
<h1>Implementing Advanced Training Simulators in V-Sekai</h1>
<section id="metadata" class="level2">
<h2 class="anchored" data-anchor-id="metadata">Metadata</h2>
<ul>
<li><strong>Status:</strong> Proposed</li>
<li><strong>Deciders:</strong> V-Sekai</li>
<li><strong>Tags:</strong> V-Sekai, Game Development, Skill Simulation</li>
</ul>
</section>
<section id="the-backdrop" class="level2">
<h2 class="anchored" data-anchor-id="the-backdrop">The Backdrop</h2>
<p>In the world of V-Sekai, players can level up their skills and unlock advanced training simulators. These simulators provide access to comprehensive Standard Operating Procedures (SOPs) and allow players to practice actions in a safe environment.</p>
</section>
<section id="the-challenge" class="level2">
<h2 class="anchored" data-anchor-id="the-challenge">The Challenge</h2>
<p>The challenge lies in creating an immersive and realistic simulation experience that doesn’t harm the player’s character. For instance, if a player is an engineer, they should be able to practice replacing a plasma conduit, learn how to use the tools, and understand how to safely isolate sections for repairs.</p>
</section>
<section id="the-strategy" class="level2">
<h2 class="anchored" data-anchor-id="the-strategy">The Strategy</h2>
<p>To overcome this challenge, we propose developing a robust system that allows players to interact with the game environment in a meaningful way. This includes creating detailed SOPs, designing intuitive user interfaces for tool manipulation, and implementing safety measures within the game.</p>
</section>
<section id="the-upside" class="level2">
<h2 class="anchored" data-anchor-id="the-upside">The Upside</h2>
<p>By providing a realistic and immersive simulation experience, we can enhance player engagement and satisfaction. Players will have the opportunity to learn and practice new skills, which can add depth to the gameplay.</p>
</section>
<section id="the-downside" class="level2">
<h2 class="anchored" data-anchor-id="the-downside">The Downside</h2>
<p>The main downside is the complexity and resources required to implement such a system. It may also be challenging to balance realism with fun gameplay.</p>
</section>
<section id="the-road-not-taken" class="level2">
<h2 class="anchored" data-anchor-id="the-road-not-taken">The Road Not Taken</h2>
<p>An alternative approach could be to simplify the skill system and focus more on traditional gameplay elements. However, this would not provide the same level of immersion and learning opportunities for the players.</p>
</section>
<section id="the-infrequent-use-case" class="level2">
<h2 class="anchored" data-anchor-id="the-infrequent-use-case">The Infrequent Use Case</h2>
<p>In some cases, players may prefer a more straightforward gameplay experience and may not fully utilize the advanced training simulators.</p>
</section>
<section id="in-core-and-done-by-us" class="level2">
<h2 class="anchored" data-anchor-id="in-core-and-done-by-us">In Core and Done by Us?</h2>
<p>Yes, this feature is core to the V-Sekai experience and will be developed by our team.</p>
</section>
<section id="further-reading" class="level2">
<h2 class="anchored" data-anchor-id="further-reading">Further Reading</h2>
<ul>
<li><a href="https://github.com/v-sekai/">V-Sekai</a></li>
<li>AI assists this article.</li>
</ul>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20231024-training-simulators.html</guid>
  <pubDate>Wed, 25 Oct 2023 19:05:30 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20231024-finetuning-workflow.html</link>
  <description><![CDATA[ 



<section id="enhancing-task-specific-model-performance-through-fine-tuning-with-axolotl" class="level1">
<h1>Enhancing Task-Specific Model Performance through Fine-Tuning with Axolotl</h1>
<section id="metadata" class="level2">
<h2 class="anchored" data-anchor-id="metadata">Metadata</h2>
<ul>
<li>Status: Proposed</li>
<li>Deciders: V-Sekai, fire</li>
<li>Tags: V-Sekai, Model Fine-tuning, Axolotl</li>
</ul>
</section>
<section id="the-backdrop" class="level2">
<h2 class="anchored" data-anchor-id="the-backdrop">The Backdrop</h2>
<p>We have multiple tasks each with a minimum of 100 samples and we want to fine-tune the latest models with our data. We are considering using the <a href="https://github.com/OpenAccess-AI-Collective/axolotl">Axolotl</a> library in a mode that batches the inputs.</p>
</section>
<section id="the-challenge" class="level2">
<h2 class="anchored" data-anchor-id="the-challenge">The Challenge</h2>
<p>The challenge is to effectively use these samples to fine-tune the model for each task without overfitting, while also ensuring that the model generalizes well to unseen data.</p>
</section>
<section id="the-strategy" class="level2">
<h2 class="anchored" data-anchor-id="the-strategy">The Strategy</h2>
<ol type="1">
<li><p><strong>Data Preparation</strong>: First, we need to prepare our data for each task. This involves cleaning the data and splitting it into training and validation sets.</p></li>
<li><p><strong>Model Selection</strong>: Next, we select the latest models that we want to fine-tune. These could be models from Hugging Face’s model hub or any other source.</p></li>
<li><p><strong>Fine-tuning with Axolotl</strong>: We will use the Axolotl library for fine-tuning. We can batch-mask our inputs to efficiently utilize our computational resources. This process will be repeated for each task.</p></li>
<li><p><strong>Evaluation</strong>: After fine-tuning, we evaluate the model on our validation set for each task to see how well it performs.</p></li>
</ol>
</section>
<section id="the-upside" class="level2">
<h2 class="anchored" data-anchor-id="the-upside">The Upside</h2>
<p>By fine-tuning the latest models on our specific tasks, we can potentially achieve better performance than using pre-trained models out-of-the-box. Also, Axolotl provides an easy-to-use interface for fine-tuning models.</p>
</section>
<section id="the-downside" class="level2">
<h2 class="anchored" data-anchor-id="the-downside">The Downside</h2>
<p>Fine-tuning models requires computational resources and time. Also, with only 100 samples per task, there’s a risk of overfitting.</p>
</section>
<section id="the-road-not-taken" class="level2">
<h2 class="anchored" data-anchor-id="the-road-not-taken">The Road Not Taken</h2>
<p>An alternative approach could be to use data augmentation techniques to increase the size of our dataset before fine-tuning.</p>
</section>
<section id="the-infrequent-use-case" class="level2">
<h2 class="anchored" data-anchor-id="the-infrequent-use-case">The Infrequent Use Case</h2>
<p>If we have tasks that are infrequently performed, it might not be worth the effort to fine-tune a model specifically for these tasks.</p>
</section>
<section id="in-core-and-done-by-us" class="level2">
<h2 class="anchored" data-anchor-id="in-core-and-done-by-us">In Core and Done by Us?</h2>
<p>Yes, this strategy involves us actively participating in the fine-tuning process.</p>
</section>
<section id="further-reading" class="level2">
<h2 class="anchored" data-anchor-id="further-reading">Further Reading</h2>
<ul>
<li><a href="https://github.com/v-sekai/">V-Sekai</a></li>
<li><a href="https://github.com/OpenAccess-AI-Collective/axolotl">Axolotl</a></li>
<li>AI assists this article.</li>
</ul>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20231024-finetuning-workflow.html</guid>
  <pubDate>Wed, 25 Oct 2023 19:05:30 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20231022-hover-to-ocean-game.html</link>
  <description><![CDATA[ 



<section id="navigating-new-horizons-a-proposal-for-expanding-exploration-in-v-sekai" class="level1">
<h1>Navigating New Horizons: A Proposal for Expanding Exploration in V-Sekai</h1>
<section id="metadata" class="level2">
<h2 class="anchored" data-anchor-id="metadata">Metadata</h2>
<ul>
<li>Status: Proposed</li>
<li>Deciders: V-Sekai, fire, cyberpunkmermaid</li>
<li>Tags: V-Sekai</li>
</ul>
</section>
<section id="the-backdrop" class="level2">
<h2 class="anchored" data-anchor-id="the-backdrop">The Backdrop</h2>
<p>The player starts with a hovercar and uses an upgrade to transform it into a hover submarine for ocean exploration. This involves navigating through surreal landscapes, encountering storms, avoiding volcanic eruptions, exploring coral reefs, and finally reaching a new island.</p>
</section>
<section id="the-challenge" class="level2">
<h2 class="anchored" data-anchor-id="the-challenge">The Challenge</h2>
<p>The main challenge lies in transitioning from land to underwater exploration while maintaining an engaging experience for the player. Creating diverse and interactive environments such as the cyber surrealist/impressionist voxel blocks landscape and the vibrant coral reef poses its own set of challenges.</p>
</section>
<section id="the-strategy" class="level2">
<h2 class="anchored" data-anchor-id="the-strategy">The Strategy</h2>
<p>We can use voxel-based rendering for creating the surreal landscapes and procedural generation for creating diverse marine life in the coral reef. For the transition from hovercar to hover submarine, we can design a special animation sequence that showcases the transformation.</p>
</section>
<section id="the-upside" class="level2">
<h2 class="anchored" data-anchor-id="the-upside">The Upside</h2>
<p>Implementing this would result in a unique and engaging gaming experience that combines elements of exploration, adventure, and survival. It would also showcase the capabilities of V-Sekai in creating diverse and immersive virtual worlds.</p>
</section>
<section id="the-downside" class="level2">
<h2 class="anchored" data-anchor-id="the-downside">The Downside</h2>
<p>The complexity involved in implementing the proposed features would require significant resources and expertise. There’s also a risk that the final product may not meet the expectations due to technical limitations or unforeseen challenges.</p>
</section>
<section id="the-road-not-taken" class="level2">
<h2 class="anchored" data-anchor-id="the-road-not-taken">The Road Not Taken</h2>
<p>An alternative approach could be to simplify the journey by limiting the number of environments or removing the transformation aspect. However, this would likely result in a less engaging experience for the player.</p>
</section>
<section id="in-core-and-done-by-us" class="level2">
<h2 class="anchored" data-anchor-id="in-core-and-done-by-us">In Core and Done by Us?</h2>
<p>Yes, this proposal aligns with the core values of V-Sekai and can be implemented by our team with the right resources and planning.</p>
</section>
<section id="further-reading" class="level2">
<h2 class="anchored" data-anchor-id="further-reading">Further Reading</h2>
<ul>
<li><a href="https://github.com/v-sekai/">V-Sekai</a></li>
</ul>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20231022-hover-to-ocean-game.html</guid>
  <pubDate>Wed, 25 Oct 2023 19:05:30 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20231020-llama-cpp-mistral-npc.html</link>
  <description><![CDATA[ 



<section id="llama-cpp-ai-model-npc" class="level1">
<h1>Llama CPP AI Model NPC</h1>
<section id="metadata" class="level2">
<h2 class="anchored" data-anchor-id="metadata">Metadata</h2>
<ul>
<li>Status: Proposed</li>
<li>Deciders: V-Sekai<br>
</li>
<li>Tags: V-Sekai, AI, NPC, Godot 4</li>
</ul>
</section>
<section id="the-backdrop" class="level2">
<h2 class="anchored" data-anchor-id="the-backdrop">The Backdrop</h2>
<p>In the realm of game development, creating engaging and dynamic Non-Player Characters (NPCs) is a challenging task. With advancements in AI, there’s an opportunity to leverage these technologies to enhance NPC interactions.</p>
</section>
<section id="the-challenge" class="level2">
<h2 class="anchored" data-anchor-id="the-challenge">The Challenge</h2>
<p>The challenge lies in effectively using various AI models to create the “brain” of an AI NPC in Godot 4. This involves generating realistic and contextually appropriate dialogues for the NPCs.</p>
</section>
<section id="the-strategy" class="level2">
<h2 class="anchored" data-anchor-id="the-strategy">The Strategy</h2>
<p>The strategy involves using a local GPT4All model for generating AI-based NPC dialogue. The script includes several exported variables that can be set in the Godot editor, such as <code>npc_background_directions</code>, <code>sample_npc_question_prompt</code>, and <code>sample_npc_prompt_response</code>. These variables are used to configure the behavior of the AI dialogue generation.</p>
<p>Key functions include:</p>
<ul>
<li><code>call_model(prompt)</code>: Calls the local model with a given prompt.</li>
<li><code>set_model(new_model_name : String)</code>: Sets the model name.</li>
</ul>
</section>
<section id="the-upside" class="level2">
<h2 class="anchored" data-anchor-id="the-upside">The Upside</h2>
<p>Leveraging AI for NPC dialogue generation can lead to more dynamic and engaging gameplay. It allows for a wide range of responses and can adapt to different player inputs.</p>
</section>
<section id="the-downside" class="level2">
<h2 class="anchored" data-anchor-id="the-downside">The Downside</h2>
<p>AI models require significant computational resources and may not be suitable for all platforms. Additionally, ensuring the appropriateness and quality of generated dialogues can be challenging.</p>
</section>
<section id="the-road-not-taken" class="level2">
<h2 class="anchored" data-anchor-id="the-road-not-taken">The Road Not Taken</h2>
<p>Traditional methods of NPC dialogue generation involve pre-scripted dialogues or simple decision trees. While these methods are less resource-intensive, they lack the dynamism and adaptability of AI-generated dialogues.</p>
</section>
<section id="the-infrequent-use-case" class="level2">
<h2 class="anchored" data-anchor-id="the-infrequent-use-case">The Infrequent Use Case</h2>
<p>In games with minimal NPC interactions or where dialogue is not a significant aspect of gameplay, the use of AI for dialogue generation may not be necessary.</p>
</section>
<section id="in-core-and-done-by-us" class="level2">
<h2 class="anchored" data-anchor-id="in-core-and-done-by-us">In Core and Done by Us?</h2>
<p>Yes, the implementation of this strategy is done by us in the core of our game development process.</p>
</section>
<section id="further-reading" class="level2">
<h2 class="anchored" data-anchor-id="further-reading">Further Reading</h2>
<ul>
<li><a href="https://github.com/v-sekai/">V-Sekai GitHub</a></li>
<li>AI assists this article.<br>
</li>
<li><a href="https://github.com/OpenAccess-AI-Collective/axolotl/tree/main/examples/mistral">Axolotl Mistral Example</a></li>
</ul>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20231020-llama-cpp-mistral-npc.html</guid>
  <pubDate>Wed, 25 Oct 2023 19:05:30 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20231019-quest3-mocap-steam-lighthouse.html</link>
  <description><![CDATA[ 



<section id="valve-vr-ecosystem-with-quest-3" class="level1">
<h1>Valve VR Ecosystem with Quest 3</h1>
<section id="metadata" class="level2">
<h2 class="anchored" data-anchor-id="metadata">Metadata</h2>
<ul>
<li>Status: Proposed <!-- Draft | Proposed | Rejected | Accepted | Deprecated | Superseded by --></li>
<li>Deciders: V-Sekai</li>
<li>Tags: V-Sekai, Valve VR Ecosystem, Quest 3</li>
</ul>
</section>
<section id="the-backdrop" class="level2">
<h2 class="anchored" data-anchor-id="the-backdrop">The Backdrop</h2>
<p>The conversation between iFire and cyberpunkmermaid reveals an innovative idea of creating a portable VR setup. iFire has a cart with a PCVR computer in it. This setup streams to a Quest 3, which is a virtual reality headset. The system uses portable light houses on clamped sticks for tracking.</p>
</section>
<section id="the-challenge" class="level2">
<h2 class="anchored" data-anchor-id="the-challenge">The Challenge</h2>
<p>The challenge lies in integrating the power of the Valve VR ecosystem with the portability of the Quest series. It requires careful selection and arrangement of components to create a mobile VR station that can stream your desktop to your Meta Quest 2 or 3.</p>
</section>
<section id="the-strategy" class="level2">
<h2 class="anchored" data-anchor-id="the-strategy">The Strategy</h2>
<p>The strategy involves using 6 HTC or Tundra trackers motion capture. One tracker is dedicated to the continuous calibration with the Meta Quest 3 HMD and the SteamVR ecosystem. Two are used for the foot, two for the shoulders, one for the chest, one for the hips. The setup also includes 2 or 4 light houses and requires the purchase of Virtual Desktop for the Meta Quest 3.</p>
</section>
<section id="the-upside" class="level2">
<h2 class="anchored" data-anchor-id="the-upside">The Upside</h2>
<p>The upside of this setup is its portability and versatility. It essentially turns your laptop into a mobile VR station, allowing you to leverage the power of the Valve VR ecosystem anywhere you go.</p>
</section>
<section id="the-downside" class="level2">
<h2 class="anchored" data-anchor-id="the-downside">The Downside</h2>
<p>The downside could be the complexity of the setup and the cost of purchasing all the necessary components. However, the benefits of having a portable VR setup may outweigh these drawbacks for many users.</p>
</section>
<section id="the-road-not-taken" class="level2">
<h2 class="anchored" data-anchor-id="the-road-not-taken">The Road Not Taken</h2>
<p>An alternative approach could be to use a standalone VR headset like the Oculus Quest 2, but this would not provide the same level of performance and compatibility with the Valve VR ecosystem.</p>
</section>
<section id="the-infrequent-use-case" class="level2">
<h2 class="anchored" data-anchor-id="the-infrequent-use-case">The Infrequent Use Case</h2>
<p>In addition to regular use, the <a href="https://github.com/V-Sekai/V-Sekai-faceless">V-Sekai-faceless</a> repository on GitHub provides a solution for interacting with the virtual world without needing to wear the HMD (Head-Mounted Display). This can be beneficial in various scenarios such as testing or when the HMD is uncomfortable to wear for extended periods.</p>
</section>
<section id="in-core-and-done-by-us" class="level2">
<h2 class="anchored" data-anchor-id="in-core-and-done-by-us">In Core and Done by Us?</h2>
<p>This setup is not part of the core V-Sekai offering but is an innovative idea proposed by members of the community. It demonstrates the potential for creativity and innovation within the V-Sekai ecosystem.</p>
</section>
<section id="further-reading" class="level2">
<h2 class="anchored" data-anchor-id="further-reading">Further Reading</h2>
<ul>
<li>[V-Sekai] - AI assists this article.</li>
<li><a href="https://github.com/ArcticFox8515/OpenVR-SpaceCalibrator/releases/tag/v1.4-bd_%2Baf-r5">OpenVR-SpaceCalibrator</a></li>
<li><a href="https://github.com/V-Sekai/V-Sekai-faceless">V-Sekai-faceless</a></li>
</ul>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20231019-quest3-mocap-steam-lighthouse.html</guid>
  <pubDate>Wed, 25 Oct 2023 19:05:30 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20230922-spacetime-shadow-shards-sync.html</link>
  <description><![CDATA[ 



<section id="streamlining-v-sekai-performance" class="level1">
<h1>Streamlining V-Sekai Performance</h1>
<section id="metadata" class="level2">
<h2 class="anchored" data-anchor-id="metadata">Metadata</h2>
<ul>
<li>Status: Proposed</li>
<li>Deciders: V-Sekai</li>
<li>Tags: V-Sekai, Godot, Networking</li>
</ul>
</section>
<section id="background" class="level2">
<h2 class="anchored" data-anchor-id="background">Background</h2>
<p>V-Sekai, leveraging the Godot client-server model, aspires to support 1000-2000 clients. The objective is to deliver uninterrupted gameplay and a comprehensive gaming experience.</p>
</section>
<section id="challenges" class="level2">
<h2 class="anchored" data-anchor-id="challenges">Challenges</h2>
<p>Key challenges encompass managing single-shard overload, administering shadow shards, and implementing state synchronization and game state transitions. These tasks necessitate precise planning, execution, and monitoring for peak performance.</p>
</section>
<section id="approach" class="level2">
<h2 class="anchored" data-anchor-id="approach">Approach</h2>
<p>A simple gameplay session will be initiated where an art seller can upload artwork. The game environment will be a flat surface with a boundary, allowing mathematical movement calculations without a navigation mesh.</p>
<p>The number of clients connecting to the server will gradually increase, starting small and eventually reaching 2,000. This will test the server’s capacity to handle multiple connections. During testing, system resources will be monitored to estimate the cost and resources required to support 2000 players. Gameplay sessions will be recorded for the trade show, and load testing will be conducted to ensure our server can manage the maximum number of players without crashing or significant slowdowns.</p>
<ol type="1">
<li><strong>Server Configuration</strong>: Set up a Godot server that listens on a designated port.</li>
<li><strong>Client Development</strong>: Build a Godot client that connects to our server using High-Level Networking.</li>
<li><strong>Shadow Shard Administration</strong>: Generate shadow copies of the original shard, serialize them for network transmission, and synchronize their state periodically.</li>
<li><strong>State Synchronization</strong>: Develop <code>Ref&lt;Animation&gt;</code> data structures symbolizing different parts of the model and outline their interactions.</li>
<li><strong>Game State Transitions</strong>: Preserve, the current game state, pinpoint the target state, transition to it, and validate the transition using an orphan <code>AnimationTree</code>.</li>
</ol>
</section>
<section id="advantages" class="level2">
<h2 class="anchored" data-anchor-id="advantages">Advantages</h2>
<p>This strategy allows us to accommodate numerous clients simultaneously without sacrificing performance or user experience. It also provides a systematic method to monitor and enhance gaming sessions.</p>
</section>
<section id="limitations" class="level2">
<h2 class="anchored" data-anchor-id="limitations">Limitations</h2>
<p>This approach requires substantial resources and expertise in server configuration, networking, and game development. Unexpected challenges may surface during implementation and testing.</p>
</section>
<section id="alternatives" class="level2">
<h2 class="anchored" data-anchor-id="alternatives">Alternatives</h2>
<p>A potential alternative could have been adopting a different game engine or networking model. However, this would demand a complete revamp of our existing setup, possibly compromising performance and flexibility.</p>
</section>
<section id="exceptional-scenarios" class="level2">
<h2 class="anchored" data-anchor-id="exceptional-scenarios">Exceptional Scenarios</h2>
<p>Controversial plans are essential to minimize gameplay disruption in unexpected traffic surges or server outages.</p>
</section>
<section id="responsibility" class="level2">
<h2 class="anchored" data-anchor-id="responsibility">Responsibility</h2>
<p>All tasks outlined are integral to our operations and will be undertaken by us.</p>
</section>
<section id="additional-resources" class="level2">
<h2 class="anchored" data-anchor-id="additional-resources">Additional Resources</h2>
<ul>
<li>[V-Sekai]</li>
<li>AI assists this article.</li>
</ul>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20230922-spacetime-shadow-shards-sync.html</guid>
  <pubDate>Wed, 25 Oct 2023 19:05:30 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20230920-godot-project-search.html</link>
  <description><![CDATA[ 



<section id="use-embedding-search-with-godot-engine-projects" class="level1">
<h1>Use embedding search with Godot Engine projects</h1>
<section id="metadata" class="level2">
<h2 class="anchored" data-anchor-id="metadata">Metadata</h2>
<ul>
<li>Status: proposed</li>
<li>Deciders: V-Sekai</li>
<li>Tags: V-Sekai</li>
</ul>
</section>
<section id="the-backdrop" class="level2">
<h2 class="anchored" data-anchor-id="the-backdrop">The Backdrop</h2>
<p>The Godot Engine is a powerful tool for creating games and other interactive content. However, finding specific pieces of code or resources within a large project can be challenging. This is where an embedding search engine like SeaGOAT can come in handy.</p>
</section>
<section id="the-challenge" class="level2">
<h2 class="anchored" data-anchor-id="the-challenge">The Challenge</h2>
<p>The challenge lies in integrating the SeaGOAT search engine with Godot Engine projects. Specifically, we need to ensure that it can effectively index and search <code>.tscn</code>, <code>.tres</code>, <code>.gd</code>, <code>.cpp</code>, <code>.h</code>, and <code>.xml</code> files, which are commonly used in Godot projects.</p>
</section>
<section id="the-strategy" class="level2">
<h2 class="anchored" data-anchor-id="the-strategy">The Strategy</h2>
<p>To use SeaGOAT with Godot Engine projects, you’ll need to add support for <code>.tscn</code>, <code>.tres</code>, <code>.gd</code>, <code>.cpp</code>, <code>.h</code>, and <code>.xml</code> files. You can do this by modifying the <code>common.py</code> file in the SeaGOAT repository. Specifically, you’ll want to add these extensions to the <code>FILE_EXTENSIONS</code> list:</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1">FILE_EXTENSIONS <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [</span>
<span id="cb1-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># existing extensions...</span></span>
<span id="cb1-3">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">".tscn"</span>,</span>
<span id="cb1-4">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">".tres"</span>,</span>
<span id="cb1-5">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">".gd"</span>,</span>
<span id="cb1-6">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">".cpp"</span>,</span>
<span id="cb1-7">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">".h"</span>,</span>
<span id="cb1-8">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">".xml"</span></span>
<span id="cb1-9">]</span></code></pre></div>
<p>Once you’ve done this, SeaGOAT should be able to index and search your Godot Engine projects.</p>
</section>
<section id="the-upside" class="level2">
<h2 class="anchored" data-anchor-id="the-upside">The Upside</h2>
<p>By integrating SeaGOAT with your Godot Engine projects, you’ll be able to quickly and easily find specific pieces of code or resources. This can greatly speed up your development process and make it easier to manage large projects.</p>
</section>
<section id="the-downside" class="level2">
<h2 class="anchored" data-anchor-id="the-downside">The Downside</h2>
<p>The downside is that this requires modifying the SeaGOAT source code, which may not be ideal if you’re not comfortable with Python or if you want to keep your SeaGOAT installation up-to-date with the official repository.</p>
</section>
<section id="the-road-not-taken" class="level2">
<h2 class="anchored" data-anchor-id="the-road-not-taken">The Road Not Taken</h2>
<p>An alternative approach would be to use a different search engine that already supports <code>.tscn</code>, <code>.tres</code>, <code>.gd</code>, <code>.cpp</code>, <code>.h</code>, and <code>.xml</code> files. However, this may not provide the same level of functionality as SeaGOAT.</p>
</section>
<section id="the-infrequent-use-case" class="level2">
<h2 class="anchored" data-anchor-id="the-infrequent-use-case">The Infrequent Use Case</h2>
<p>This strategy is most useful for large Godot Engine projects where finding specific pieces of code or resources can be challenging. For smaller projects, the built-in search functionality in Godot may be sufficient.</p>
</section>
<section id="in-core-and-done-by-us" class="level2">
<h2 class="anchored" data-anchor-id="in-core-and-done-by-us">In Core and Done by Us?</h2>
<p>This modification would need to be done by us, as it involves changing the SeaGOAT source code. It’s not clear whether this change would be accepted into the core SeaGOAT project.</p>
</section>
<section id="further-reading" class="level2">
<h2 class="anchored" data-anchor-id="further-reading">Further Reading</h2>
<ul>
<li><a href="https://v-sekai.org/">V-Sekai</a></li>
<li><a href="https://github.com/kantord/SeaGOAT">SeaGOAT</a></li>
<li>This article is assisted by AI.</li>
</ul>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20230920-godot-project-search.html</guid>
  <pubDate>Wed, 25 Oct 2023 19:05:30 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20230913-V-Sekai-bugs.html</link>
  <description><![CDATA[ 



<section id="challenges-that-need-to-be-addressed-in-v-sekai" class="level1">
<h1>Challenges that need to be addressed in V-Sekai</h1>
<section id="metadata" class="level2">
<h2 class="anchored" data-anchor-id="metadata">Metadata</h2>
<ul>
<li><strong>Status:</strong> Proposed</li>
<li><strong>Deciders:</strong> V-Sekai</li>
<li><strong>Tags:</strong> V-Sekai</li>
</ul>
</section>
<section id="the-backdrop" class="level2">
<h2 class="anchored" data-anchor-id="the-backdrop">The Backdrop</h2>
<p>In our quest to expand our community, we are faced with several challenges that need to be addressed.</p>
</section>
<section id="the-challenge" class="level2">
<h2 class="anchored" data-anchor-id="the-challenge">The Challenge</h2>
<p>Our game has been QA Engineered by Facade, which was a great help. However, there are still issues that need to be resolved.</p>
</section>
<section id="the-strategy" class="level2">
<h2 class="anchored" data-anchor-id="the-strategy">The Strategy</h2>
<p>We have identified several areas of concern and have charted them in the following flow diagram:</p>
<pre class="mermaid"><code>graph TD
    Crash["V-Sekai crash on start on RADV, Ubuntu 22.04.2 LTS (Jammy Jellyfish) #115"]
    VR["VR doesn't work #228"]
    Avatar["Restore avatar upload #243"]
    Uploads["Restore world uploads #244"]
    Mirror["Restore mirror in the preview server #249"]
    Freeze["Pressing escape button while ingame freezes client #250"]
    Escape["Escape button in menu should go back, instead does nothing #251"]
    Text["UI dropdown text is invisible until hovered #252"]
    Sensitivity["Increase default mouse sensitivity #253"]
    Gestures["Restore gestures #254"]
    VOIP["Restore VOIP #255"]
    IK["IK errors ingame #256"]

    Crash--&gt;VR
    VR--&gt;Avatar
    Avatar--&gt;Uploads
    Uploads--&gt;Mirror
    Mirror--&gt;Freeze
    Freeze--&gt;Escape
    Escape--&gt;Text
    Text--&gt;Sensitivity
    Sensitivity--&gt;Gestures
    Gestures--&gt;VOIP
    VOIP--&gt;IK</code></pre>
</section>
<section id="the-upside" class="level2">
<h2 class="anchored" data-anchor-id="the-upside">The Upside</h2>
<p>Addressing these issues will significantly improve the user experience, making our game more enjoyable and accessible. This could lead to an increase in our user base and community engagement.</p>
</section>
<section id="the-downside" class="level2">
<h2 class="anchored" data-anchor-id="the-downside">The Downside</h2>
<p>The process of resolving these issues may require significant time and resources. It might also involve some trial and error, which could potentially introduce new bugs or problems.</p>
</section>
<section id="the-road-not-taken" class="level2">
<h2 class="anchored" data-anchor-id="the-road-not-taken">The Road Not Taken</h2>
<p>Ignoring these issues is not an option as it would negatively impact the user experience and could hinder the growth of our community.</p>
</section>
<section id="the-infrequent-use-case" class="level2">
<h2 class="anchored" data-anchor-id="the-infrequent-use-case">The Infrequent Use Case</h2>
<p>While some of these issues might only affect a small number of users or occur under specific circumstances, it’s important to address them to ensure a smooth and enjoyable experience for all users.</p>
</section>
<section id="in-core-and-done-by-us" class="level2">
<h2 class="anchored" data-anchor-id="in-core-and-done-by-us">In Core and Done by Us?</h2>
<p>Yes, these issues are core to the functionality of our game and should be addressed by our team.</p>
</section>
<section id="further-reading" class="level2">
<h2 class="anchored" data-anchor-id="further-reading">Further Reading</h2>
<ul>
<li><a href="https://v-sekai.org/">V-Sekai</a></li>
<li>This article is assisted by AI.</li>
</ul>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20230913-V-Sekai-bugs.html</guid>
  <pubDate>Wed, 25 Oct 2023 19:05:30 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20230912-target-most-popular-resolution.html</link>
  <description><![CDATA[ 



<section id="address-screen-resolution-compatibility-issues" class="level1">
<h1>Address Screen Resolution Compatibility Issues</h1>
<section id="metadata" class="level2">
<h2 class="anchored" data-anchor-id="metadata">Metadata</h2>
<ul>
<li><strong>Status:</strong> Proposed</li>
<li><strong>Deciders:</strong> V-Sekai</li>
<li><strong>Tags:</strong> V-Sekai</li>
</ul>
</section>
<section id="context-and-problem-statement" class="level2">
<h2 class="anchored" data-anchor-id="context-and-problem-statement">Context and Problem Statement</h2>
<p>Several users, including Lyuma, have reported that their monitors are not compatible with the V-Sekai menu system. This issue is causing a significant hindrance in the user experience.</p>
</section>
<section id="decision-drivers" class="level2">
<h2 class="anchored" data-anchor-id="decision-drivers">Decision Drivers</h2>
<ul>
<li>User satisfaction</li>
<li>Compatibility with various screen resolutions</li>
</ul>
</section>
<section id="considered-options" class="level2">
<h2 class="anchored" data-anchor-id="considered-options">Considered Options</h2>
<ol type="1">
<li>Leave as is</li>
<li>Set V-Sekai’s screen resolution to fit the default resolution of the Valve hardware survey’s most popular resolution.</li>
</ol>
</section>
<section id="decision-outcome" class="level2">
<h2 class="anchored" data-anchor-id="decision-outcome">Decision Outcome</h2>
<p>Chosen option: “Set V-Sekai’s screen resolution to fit the default resolution of the Valve hardware survey’s most popular resolution.”, because it will increase compatibility and improve user experience.</p>
</section>
<section id="pros-and-cons-of-the-options" class="level2">
<h2 class="anchored" data-anchor-id="pros-and-cons-of-the-options">Pros and Cons of the Options</h2>
<section id="setting-v-sekais-screen-resolution-to-fit-the-default-resolution-of-the-valve-hardware-surveys-most-popular-resolution" class="level3">
<h3 class="anchored" data-anchor-id="setting-v-sekais-screen-resolution-to-fit-the-default-resolution-of-the-valve-hardware-surveys-most-popular-resolution">Setting V-Sekai’s Screen Resolution to Fit the Default Resolution of the Valve Hardware Survey’s Most Popular Resolution</h3>
<ul>
<li>Good, because it increases compatibility with the majority of users’ monitors.</li>
<li>Bad, because it may not cover all possible monitor resolutions, leaving some users still facing issues.</li>
</ul>
</section>
<section id="leaving-as-is" class="level3">
<h3 class="anchored" data-anchor-id="leaving-as-is">Leaving as Is</h3>
<ul>
<li>Good, because it requires no additional work or changes.</li>
<li>Bad, because it does not solve the problem and leaves users frustrated.</li>
</ul>
</section>
</section>
<section id="links" class="level2">
<h2 class="anchored" data-anchor-id="links">Links</h2>
<ul>
<li><a href="https://v-sekai.org/">V-Sekai</a></li>
<li>This article is assisted by AI.</li>
</ul>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20230912-target-most-popular-resolution.html</guid>
  <pubDate>Wed, 25 Oct 2023 19:05:30 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20230911-xr-grid-with-drawing.html</link>
  <description><![CDATA[ 



<section id="improving-xr-grid-with-new-enhancements" class="level1">
<h1>Improving xr grid with new enhancements</h1>
<section id="metadata" class="level2">
<h2 class="anchored" data-anchor-id="metadata">Metadata</h2>
<ul>
<li><strong>Status:</strong> proposed</li>
<li><strong>Deciders:</strong> V-Sekai, fire, detox,</li>
<li><strong>Tags:</strong> V-Sekai</li>
</ul>
</section>
<section id="context-and-problem-statement" class="level2">
<h2 class="anchored" data-anchor-id="context-and-problem-statement">Context and Problem Statement</h2>
<p>We are developing an xr grid project, but it’s in a nice easy to understand state.</p>
</section>
<section id="considered-options" class="level2">
<h2 class="anchored" data-anchor-id="considered-options">Considered Options</h2>
<p>DETOX suggested comparing different modes of navigation before making any changes. Fire shared that they have three modes in mind: blob pen, 2D beautifications for 3D, and patch mode. However, these are not functioning correctly yet due to complexity.</p>
</section>
<section id="decision-outcome" class="level2">
<h2 class="anchored" data-anchor-id="decision-outcome">Decision Outcome</h2>
<p>Fire will think up some UI for xr-grid, create a simple UI system based on GUI in VR, and add it to xr-grid. We also discuss the possibility of adding a glTF export menu and other features to the UI.</p>
</section>
<section id="positive-consequences" class="level2">
<h2 class="anchored" data-anchor-id="positive-consequences">Positive Consequences</h2>
<p>The team is considering various improvements such as fixing grid bugs, exporting loadable content in Blender, adding branding/instructions, and improving the UI.</p>
</section>
<section id="negative-consequences" class="level2">
<h2 class="anchored" data-anchor-id="negative-consequences">Negative Consequences</h2>
<p>The main challenge is to avoid bloating the main project with art tools. This might require branching or forking the project.</p>
</section>
<section id="prospects-for-the-future" class="level2">
<h2 class="anchored" data-anchor-id="prospects-for-the-future">Prospects for the Future</h2>
<p>DETOX suggested creating a branch for the new features, while Fire expressed a desire to work on networking. They also discussed the possibility of building a tool similar to Cassie on the branch.</p>
</section>
<section id="links" class="level2">
<h2 class="anchored" data-anchor-id="links">Links</h2>
<ul>
<li><a href="https://v-sekai.org/">V-Sekai</a></li>
<li>This article is assisted by AI.</li>
</ul>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20230911-xr-grid-with-drawing.html</guid>
  <pubDate>Wed, 25 Oct 2023 19:05:30 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20230911-xpr.exs.html</link>
  <description><![CDATA[ 



<section id="xpr-in-elixir" class="level1">
<h1>XPR in Elixir</h1>
<p>defmodule AveragableLerpable do <span class="citation" data-cites="callback">@callback</span> average(a :: any(), b :: any(), t :: number()) :: any() <span class="citation" data-cites="callback">@callback</span> lerp(a :: any(), b :: any(), t :: number()) :: any() <span class="citation" data-cites="callback">@callback</span> spherical_interpolate(a :: any(), b :: any(), t :: number()) :: any() <span class="citation" data-cites="callback">@callback</span> spherical_cubic_interpolate(a :: any(), b :: any(), c :: any(), d :: any(), t1 :: number(), t2 :: number(), t3 :: number(), t4 :: number()) :: any() <span class="citation" data-cites="callback">@callback</span> cubic_interpolate(a :: any(), b :: any(), c :: any(), d :: any(), t1 :: number(), t2 :: number(), t3 :: number(), t4 :: number()) :: any() end</p>
<p>defmodule Rotation6D do <span class="citation" data-cites="behaviour">@behaviour</span> AveragableLerpable</p>
<p>defstruct [:x1, :y1, :z1, :x2, :y2, :z2]</p>
<p># Implement the required methods here end</p>
<p>defmodule Position3D do <span class="citation" data-cites="behaviour">@behaviour</span> AveragableLerpable</p>
<p>defstruct [:x, :y, :z]</p>
<p># Implement the required methods here end</p>
<p>defmodule LightCone do <span class="citation" data-cites="type">@type</span> t :: %{ count: [AveragableLerpable.t()], accumulate: [function()], array: [AveragableLerpable.t()], set: MapSet.t(any()) } end</p>
<p><span class="citation" data-cites="type">@type</span> event :: {:expand} | {:superposition} | {:spacetime_bubble} | {:light_cone} | {:collapse} | {:avg_lerp} | {:plus} | {:union}</p>
<p>defmodule PropagateFilter do use Membrane.Filter</p>
<p><span class="citation" data-cites="impl">@impl</span> true def handle_init(_) do {:ok, %{}} end</p>
<p><span class="citation" data-cites="impl">@impl</span> true def handle_demand(:output, size, :buffers, _ctx) do {{:ok, demand: {:input, size}}, %{}} end</p>
<p><span class="citation" data-cites="impl">@impl</span> true def handle_process(:input, buffer, _ctx) do # Process the input data and generate the output data output_data = process(buffer.payload)</p>
<pre><code># Create a new buffer with the output data
output_buffer = %Membrane.Buffer{payload: output_data}

{{:ok, buffer: {:output, output_buffer}}, %{}}</code></pre>
<p>end</p>
<p>defp process(input_data) do # Implement your processing logic here # For example, if input_data is a list of numbers, you can calculate their sum: Enum.reduce(input_data, 0, &amp;(&amp;1 + &amp;2)) end end</p>
<p>defmodule XprPipeline do use Membrane.Pipeline</p>
<p>alias Membrane.Element.Tee.Master alias Membrane.Element.Funnel alias Membrane.Element.Clock</p>
<p><span class="citation" data-cites="impl">@impl</span> true def handle_init(_) do children = [ clock: Clock, light_cone: LightConeElement, expanding: ExpandingElement, collapsing: CollapsingElement, reduce: ReduceElement, update: UpdateElement, tee: Master, funnel: Funnel, propagate: PropagateFilter ]</p>
<pre><code>links = [
  link(:clock)
  |&gt; via_out(:tick, options: [interval: 1000]) # Adjust the interval as needed
  |&gt; to(:tee)
  |&gt; to(:expanding)
  |&gt; to(:light_cone)
  |&gt; to(:collapsing)
  |&gt; to(:reduce)
  |&gt; to(:propagate)
  |&gt; to(:funnel)
  |&gt; to(:update)
]

{{:ok, %ParentSpec{children: children, links: links}}, %{}}</code></pre>
<p>end end</p>


</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20230911-xpr.exs.html</guid>
  <pubDate>Wed, 25 Oct 2023 19:05:30 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20230911-first-alpha-tag.html</link>
  <description><![CDATA[ 



<section id="implementing-semantic-versioning-for-alpha-releases-in-v-sekai" class="level1">
<h1>Implementing Semantic Versioning for Alpha Releases in V-Sekai</h1>
<section id="metadata" class="level2">
<h2 class="anchored" data-anchor-id="metadata">Metadata</h2>
<ul>
<li>Status: Proposed <!-- Draft | Proposed | Rejected | Accepted | Deprecated | Superseded by --></li>
<li>Deciders: V-Sekai</li>
<li>Tags: V-Sekai, Semantic Versioning, Alpha Release</li>
</ul>
</section>
<section id="the-backdrop" class="level2">
<h2 class="anchored" data-anchor-id="the-backdrop">The Backdrop</h2>
<p>In software development, semantic versioning (semver) is a popular method for versioning software. It provides a clear and concise way to communicate changes in versions and the associated implications.</p>
</section>
<section id="the-challenge" class="level2">
<h2 class="anchored" data-anchor-id="the-challenge">The Challenge</h2>
<p>The challenge lies in correctly denoting the first alpha release in semver. This is crucial as it communicates the stability of the software and sets expectations for users and developers.</p>
</section>
<section id="the-strategy" class="level2">
<h2 class="anchored" data-anchor-id="the-strategy">The Strategy</h2>
<p>In semver, the first alpha release would typically be denoted with a hyphen followed by the word “alpha” and a number. For example, it could be something like “0.1.0-alpha.1”. The specific alpha release number may vary depending on the project and its release cycle.</p>
</section>
<section id="the-upside" class="level2">
<h2 class="anchored" data-anchor-id="the-upside">The Upside</h2>
<p>Using semver for alpha releases helps to set clear expectations about the stability and features of the software. It allows developers and users to understand that the software is in an early stage of development and may not yet have all planned features or be fully stable.</p>
</section>
<section id="the-downside" class="level2">
<h2 class="anchored" data-anchor-id="the-downside">The Downside</h2>
<p>The downside could be the potential confusion around the naming convention, especially for those unfamiliar with semver. However, this can be mitigated through clear documentation and communication.</p>
</section>
<section id="the-road-not-taken" class="level2">
<h2 class="anchored" data-anchor-id="the-road-not-taken">The Road Not Taken</h2>
<p>An alternative approach could be to use a different versioning system or to not denote alpha releases specifically. However, these approaches may not provide the same level of clarity and communication as semver.</p>
</section>
<section id="the-infrequent-use-case" class="level2">
<h2 class="anchored" data-anchor-id="the-infrequent-use-case">The Infrequent Use Case</h2>
<p>While the alpha release notation is common in semver, it may not be used frequently in projects that have shorter development cycles or that do not release alpha versions to the public.</p>
</section>
<section id="in-core-and-done-by-us" class="level2">
<h2 class="anchored" data-anchor-id="in-core-and-done-by-us">In Core and Done by Us?</h2>
<p>Yes, this strategy of using semver for denoting alpha releases is a core part of the V-Sekai project management and release process.</p>
</section>
<section id="further-reading" class="level2">
<h2 class="anchored" data-anchor-id="further-reading">Further Reading</h2>
<ul>
<li>[V-Sekai] - AI assists this article.</li>
<li><a href="https://semver.org/">Semantic Versioning</a></li>
</ul>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20230911-first-alpha-tag.html</guid>
  <pubDate>Wed, 25 Oct 2023 19:05:30 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20230911-can-poly-green-coords-extend-to-3d.html</link>
  <description><![CDATA[ 



<section id="can-poly-green-coords-extend-to-3d" class="level1">
<h1>Can Poly Green Coords extend to 3d?</h1>
<p>Reminded by works by pixar: https://graphics.pixar.com/library/ProfileMover/</p>
<p>How applicable is this to 3d polygonal cages?</p>
<pre><code>You may be interested by *[Green Coordinates for Triquad Cages in 3D](https://research.adobe.com/publication/green-coordinates-for-triquad-cages-in-3d/)* by Thiery and Boubekeur (SIGGRAPH Asia 2022). It is only for straight polygons though, the deformed cage cannot have Bézier arcs like this 2D version has, that's future work. ;) Profile curves are definitly a very nice and related work!</code></pre>
<p><em>Originally posted by <span class="citation" data-cites="eliemichel">@eliemichel</span> in https://github.com/eliemichel/PolyGreenCoords/issues/1#issuecomment-1683045650</em></p>


</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20230911-can-poly-green-coords-extend-to-3d.html</guid>
  <pubDate>Wed, 25 Oct 2023 19:05:30 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20230908-bendable-screen-generative-assistant-ggml.html</link>
  <description><![CDATA[ 



<section id="translationtranscription-badge-with-ggmls-whisper" class="level1">
<h1>Translation/Transcription Badge with GGML’s Whisper</h1>
<section id="overview" class="level2">
<h2 class="anchored" data-anchor-id="overview">Overview</h2>
<p>The project aims to develop a translation/transcription badge using GGML’s Whisper, a part of the GGML library that provides access to large language models (LLMs). The primary focus is on voice interactions.</p>
</section>
<section id="key-features" class="level2">
<h2 class="anchored" data-anchor-id="key-features">Key Features</h2>
<ul>
<li><strong>Voice Interactions</strong>: The system will prioritize voice interactions, leveraging GGML’s Whisper capabilities to create a responsive AI. Python will not be used in this context.</li>
<li><strong>Speech-to-Text Interface</strong>: A speech-to-text interface will be incorporated to process voice inputs effectively.</li>
<li><strong>Direct Connection to Compute Module</strong>: The display, set in portrait mode, will connect directly to the compute module, a standard Linux amd64 computer, eliminating the need for embedded software development.</li>
<li><strong>Flexible OLED Display</strong>: The system will utilize a 6-inch flexible OLED display from Wisecoco with a resolution of 2880*1440 at 60Hz refresh rate.</li>
<li><strong>No Holograph Displays</strong>: The design will be streamlined and efficient, excluding holograph displays.</li>
</ul>
</section>
<section id="potential-challenges" class="level2">
<h2 class="anchored" data-anchor-id="potential-challenges">Potential Challenges</h2>
<p>The project’s complexity and the expertise required in areas such as GGML, the Godot engine, and AI development pose significant challenges.</p>
</section>
<section id="alternatives-not-considered" class="level2">
<h2 class="anchored" data-anchor-id="alternatives-not-considered">Alternatives Not Considered</h2>
<p>We have decided against integrating Python with GGML and using a pre-existing AI framework instead of developing one from scratch.</p>
</section>
<section id="target-audience" class="level2">
<h2 class="anchored" data-anchor-id="target-audience">Target Audience</h2>
<p>The project may not be suitable for individuals without familiarity with GGML or a background in AI development.</p>
</section>
<section id="development-strategy" class="level2">
<h2 class="anchored" data-anchor-id="development-strategy">Development Strategy</h2>
<p>The project will be developed in-house, utilizing our expertise in AI and game development.</p>
</section>
<section id="further-reading" class="level2">
<h2 class="anchored" data-anchor-id="further-reading">Further Reading</h2>
<p>For more information, please refer to these resources:</p>
<ul>
<li><a href="https://v-sekai.org/">V-Sekai</a></li>
<li><a href="https://github.com/georgi-gerganov/ggml">GGML on GitHub</a></li>
<li><a href="https://github.com/sanchit-gandhi/whisper-jax">Whisper JAX on GitHub</a></li>
<li><a href="https://twitter.com/jav6868/status/1698260873352212662?s=20">Twitter inspiration</a></li>
<li><a href="https://www.amazon.ca/wisecoco-Flexible-Display-Screen-Bendable/dp/B0C7YY16Z5">wisecoco 6 inch 2K Flexible OLED Display IPS 2880 * 1440 Flexible Screen Curved Bendable Screen</a></li>
</ul>
</section>
<section id="system-diagram" class="level2">
<h2 class="anchored" data-anchor-id="system-diagram">System Diagram</h2>
<pre class="mermaid"><code>graph TD
A[Edge Device: Compute Unit] --&gt;|Hosts| B[VRM1 Character Layer]
C[Whisper for Speech-to-Text running on GGML] -- Audio Processing --&gt; B
B --&gt; D[Wisecoco 6-inch Flexible OLED Display in Portrait Mode]
E[Microphone] -- Audio Input --&gt; C</code></pre>
</section>
<section id="system-diagram-explanation" class="level2">
<h2 class="anchored" data-anchor-id="system-diagram-explanation">System Diagram Explanation:</h2>
<section id="edge-device-compute-unit-a" class="level3">
<h3 class="anchored" data-anchor-id="edge-device-compute-unit-a">1. Edge Device: Compute Unit (A)</h3>
<p>This unit is a standard Linux amd64 computer that hosts the VRM1 Character Layer (B).</p>
</section>
<section id="whisper-for-speech-to-text-module-c" class="level3">
<h3 class="anchored" data-anchor-id="whisper-for-speech-to-text-module-c">2. Whisper for Speech-to-Text module (C)</h3>
<p>This module, running on GGML, captures audio input from the Microphone (E) and converts it into text.</p>
</section>
<section id="vrm1-character-layer-b" class="level3">
<h3 class="anchored" data-anchor-id="vrm1-character-layer-b">3. VRM1 Character Layer (B)</h3>
<p>The processed data from the Whisper module animates a virtual character in this layer. The character can be in speaking or idle mode.</p>
</section>
<section id="wisecoco-6-inch-flexible-oled-display-in-portrait-mode-d" class="level3">
<h3 class="anchored" data-anchor-id="wisecoco-6-inch-flexible-oled-display-in-portrait-mode-d">4. Wisecoco 6-inch Flexible OLED Display in Portrait Mode (D)</h3>
<p>The resulting texts are displayed on this screen.</p>
<blockquote class="blockquote">
<p><strong>Note:</strong> Currently, the system only supports speaking and idle states. Other modes are not available.</p>
</blockquote>
<p>The choice of portrait mode for the display aligns with the specific needs and constraints of the project. As the project heavily relies on text-based interactions, specifically transcriptions, portrait mode allows more lines of text to be visible at once, thereby improving the user experience.</p>
<p>The system utilizes a 6-inch flexible OLED display from Wisecoco. Portrait mode is more space-efficient in such scenarios, taking up less horizontal space while still providing ample vertical space for text display.</p>
<p>Given that the primary focus of the project is voice interactions, the display mode should ideally support easy reading of transcriptions. Portrait mode, with its vertical orientation, is more suited to this task as it mimics the natural top-to-bottom reading flow.</p>
<p>According to the system diagram, the processed data from the Whisper for Speech-to-Text module running on GGML is used to animate a virtual character and display the resulting texts. These texts are likely to be dialogue or conversation-based, and portrait mode would allow for a more coherent and continuous display of these text blocks.</p>


</section>
</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20230908-bendable-screen-generative-assistant-ggml.html</guid>
  <pubDate>Wed, 25 Oct 2023 19:05:30 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20230903-replicate-vrm-transform.html</link>
  <description><![CDATA[ 



<section id="enabling-vrm-to-blender-conversion-with-cloud-gpus-and-replicate.com" class="level1">
<h1>Enabling VRM to Blender Conversion with Cloud GPUs and replicate.com</h1>
<section id="metadata" class="level2">
<h2 class="anchored" data-anchor-id="metadata">Metadata</h2>
<ul>
<li>Status: rejected</li>
<li>Deciders: V-Sekai, fire, antpb</li>
<li>Tags: V-Sekai</li>
</ul>
</section>
<section id="the-backdrop" class="level2">
<h2 class="anchored" data-anchor-id="the-backdrop">The Backdrop</h2>
<p>The VRM format is becoming increasingly popular in the field of 3D modeling and animation. It allows for easy sharing and transfer of humanoid 3D models with skeletal animations between different software applications. One such application is the Godot Engine, a popular open-source game engine.</p>
</section>
<section id="the-challenge" class="level2">
<h2 class="anchored" data-anchor-id="the-challenge">The Challenge</h2>
<p>Currently, developers working with VRM files in Godot Engine face difficulties when trying to convert these files to Blender format for further editing or manipulation. Manual conversion processes can be time-consuming and error-prone.</p>
</section>
<section id="the-strategy" class="level2">
<h2 class="anchored" data-anchor-id="the-strategy">The Strategy</h2>
<p>The proposed strategy for enabling VRM to Blender conversion involves leveraging the computational power of cloud GPUs provided by replicate.com. By running a GPU-accelerated Blender instance, developers can perform an identity operation on the VRM input, converting it to Blender format. This simplifies the process of converting VRM files to Blender format.</p>
<p>To convert VRM files to Blender format, developers can follow these steps:</p>
<ol type="1">
<li>Install the necessary libraries or plugins in Blender that support the VRM format.</li>
<li>Leverage replicate.com’s infrastructure to spin up a GPU-accelerated Blender instance.</li>
<li>Develop a script or tool that takes the VRM file as input and sends it to the GPU-accelerated Blender instance via a REST interface.</li>
<li>In the GPU-accelerated Blender instance, use the installed libraries or plugins to perform the conversion from VRM to Blender format.</li>
<li>Also use Blender to perform the conversion from Blender to VRM/GLTF format.</li>
</ol>
<p>This strategy streamlines the workflow for developers, saving time and improving collaboration between designers and developers. The use of cloud GPUs and replicate.com’s infrastructure ensures fast and efficient conversion processes.</p>
<p>Additionally, this strategy can also be extended to other software applications or websites that can utilize a REST interface, allowing developers working with VRM files to convert them to Blender format seamlessly, regardless of the software they are using.</p>
</section>
<section id="the-upside" class="level2">
<h2 class="anchored" data-anchor-id="the-upside">The Upside</h2>
<ul>
<li>Streamlined workflow: Developers can easily convert VRM files to Blender format, opening up a wide range of editing and manipulation possibilities.</li>
<li>Time-saving: The use of cloud GPUs and replicate.com’s infrastructure ensures fast and efficient conversion processes.</li>
<li>Improved collaboration: The ability to work with VRM models in both Godot Engine and Blender facilitates collaboration between designers and developers.</li>
</ul>
</section>
<section id="the-downside" class="level2">
<h2 class="anchored" data-anchor-id="the-downside">The Downside</h2>
<ul>
<li>Development effort and expertise: Creating the necessary library or plugin may require significant technical knowledge in both the Godot Engine and VRM format.</li>
<li>Compatibility issues: Different versions of FBX or GLB files may introduce compatibility challenges during the conversion process.</li>
<li>Maintenance challenges: Keeping up with future updates to the Godot Engine and VRM specifications may require ongoing effort.</li>
</ul>
</section>
<section id="the-road-not-taken" class="level2">
<h2 class="anchored" data-anchor-id="the-road-not-taken">The Road Not Taken</h2>
<p>We considered developing a web application, but it was deemed to have heavy engineering costs.</p>
</section>
<section id="the-infrequent-use-case" class="level2">
<h2 class="anchored" data-anchor-id="the-infrequent-use-case">The Infrequent Use Case</h2>
<p>While the proposed solution focuses on streamlining VRM to Blender conversion for the Godot Engine ecosystem, the same concept can be extended to other software applications or websites that can utilize a REST interface. This allows developers working with VRM files to convert them to Blender format seamlessly, regardless of the software they are using. The use of cloud GPUs and replicate.com’s infrastructure still ensures fast and efficient conversion processes.</p>
</section>
<section id="in-core-and-done-by-us" class="level2">
<h2 class="anchored" data-anchor-id="in-core-and-done-by-us">In Core and Done by Us?</h2>
<p>Fire knows the way.</p>
</section>
<section id="further-reading" class="level2">
<h2 class="anchored" data-anchor-id="further-reading">Further Reading</h2>
<ul>
<li><a href="https://v-sekai.org/">V-Sekai</a></li>
<li><a href="https://github.com/vrm-c/vrm-specification/tree/master/specification/VRMC_vrm_animation-1.0">VRM Animation Specification</a></li>
<li><a href="https://replicate.com/fire/v-sekai.mediapipe-labeler">Replicate - Cloud GPU Toy</a></li>
</ul>
<p>This article is assisted by AI.</p>
<p>Is there anything else I can assist you with?</p>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20230903-replicate-vrm-transform.html</guid>
  <pubDate>Wed, 25 Oct 2023 19:05:30 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20230831-fixing-upload-limits.html</link>
  <description><![CDATA[ 



<section id="enhancing-map-uploads" class="level1">
<h1>Enhancing Map Uploads</h1>
<section id="metadata" class="level2">
<h2 class="anchored" data-anchor-id="metadata">Metadata</h2>
<ul>
<li>Status: accepted</li>
<li>Deciders: V-Sekai, fire, Scipi</li>
<li>Tags: V-Sekai</li>
</ul>
</section>
<section id="the-backdrop" class="level2">
<h2 class="anchored" data-anchor-id="the-backdrop">The Backdrop</h2>
<p>V-Sekai is facing limitations in its Elixir uro backend when uploading maps, specifically related to the Godot Engine scenes. These limitations are believed to be caused by a restriction in the Waffles library.</p>
</section>
<section id="the-challenge" class="level2">
<h2 class="anchored" data-anchor-id="the-challenge">The Challenge</h2>
<p>The challenge at hand is to address the arbitrary limitations imposed by the Waffles library on the Godot Engine scenes during map uploads in the Elixir uro backend of V-Sekai.</p>
</section>
<section id="the-strategy" class="level2">
<h2 class="anchored" data-anchor-id="the-strategy">The Strategy</h2>
<p>To overcome this challenge, we propose patching the Waffles library in collaboration with our new contributor.</p>
</section>
<section id="the-upside" class="level2">
<h2 class="anchored" data-anchor-id="the-upside">The Upside</h2>
<p>By patching the Waffles library, we can effectively remove the limitations on the Godot Engine scenes and improve the functionality of map uploads in V-Sekai.</p>
</section>
<section id="the-downside" class="level2">
<h2 class="anchored" data-anchor-id="the-downside">The Downside</h2>
<p>It is important to consider any potential downsides or risks associated with patching the Waffles library. Further analysis and testing may be required to ensure compatibility and stability.</p>
</section>
<section id="the-road-not-taken" class="level2">
<h2 class="anchored" data-anchor-id="the-road-not-taken">The Road Not Taken</h2>
<p>Alternative solutions to address the limitations have been explored, but patching the Waffles library appears to be the most viable option.</p>
</section>
<section id="the-infrequent-use-case" class="level2">
<h2 class="anchored" data-anchor-id="the-infrequent-use-case">The Infrequent Use Case</h2>
<p>This limitation impacts the specific use case of map uploads in the Elixir uro backend, and may not affect other functionalities in V-Sekai.</p>
</section>
<section id="in-core-and-done-by-us" class="level2">
<h2 class="anchored" data-anchor-id="in-core-and-done-by-us">In Core and Done by Us?</h2>
<p>As a core functionality of V-Sekai, addressing the limitations in the Godot Engine scenes during map uploads is a task that should be done by our team.</p>
</section>
<section id="further-reading" class="level2">
<h2 class="anchored" data-anchor-id="further-reading">Further Reading</h2>
<ul>
<li><a href="https://v-sekai.org/">V-Sekai</a></li>
<li>This article is assisted by AI.</li>
<li>https://github.com/V-Sekai/v-sekai-game/issues/68</li>
</ul>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20230831-fixing-upload-limits.html</guid>
  <pubDate>Wed, 25 Oct 2023 19:05:30 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20230831-fixing-menus.html</link>
  <description><![CDATA[ 



<section id="fix-menus-in-game" class="level1">
<h1>Fix menus in-game</h1>
<section id="metadata" class="level2">
<h2 class="anchored" data-anchor-id="metadata">Metadata</h2>
<ul>
<li>Status: accepted</li>
<li>Deciders: V-Sekai</li>
<li>Tags: V-Sekai</li>
</ul>
</section>
<section id="the-backdrop" class="level2">
<h2 class="anchored" data-anchor-id="the-backdrop">The Backdrop</h2>
</section>
<section id="the-challenge" class="level2">
<h2 class="anchored" data-anchor-id="the-challenge">The Challenge</h2>
<p>The menus in-game are unable to capture events from the VR controllers.</p>
</section>
<section id="the-strategy" class="level2">
<h2 class="anchored" data-anchor-id="the-strategy">The Strategy</h2>
<p>Debug the <code>on_pointer_pressed</code> function as it is not working correctly due to an issue with <code>Transform3D.xform_inv</code>. The current implementation mimics mouse input, but it fails to translate global positions correctly. Review the <code>global_to_viewport</code> function and ensure it returns the correct value for <code>local_at</code>.</p>
</section>
<section id="the-upside" class="level2">
<h2 class="anchored" data-anchor-id="the-upside">The Upside</h2>
<p>Fixing the menus will enable players to interact with them using VR controllers, enhancing the user experience.</p>
</section>
<section id="the-downside" class="level2">
<h2 class="anchored" data-anchor-id="the-downside">The Downside</h2>
<p>Fixing the menus may require significant code changes, introducing potential bugs or conflicts that need proper testing to ensure stability.</p>
</section>
<section id="the-road-not-taken" class="level2">
<h2 class="anchored" data-anchor-id="the-road-not-taken">The Road Not Taken</h2>
<p>Exploring alternative input systems specifically designed for VR controllers could be considered, but it may involve rewriting a large portion of the menu code and potentially introducing new dependencies.</p>
</section>
<section id="the-infrequent-use-case" class="level2">
<h2 class="anchored" data-anchor-id="the-infrequent-use-case">The Infrequent Use Case</h2>
<p>This fix targets players using VR controllers to interact with the menus. Players without VR controllers will not be affected.</p>
</section>
<section id="in-core-and-done-by-us" class="level2">
<h2 class="anchored" data-anchor-id="in-core-and-done-by-us">In Core and Done by Us?</h2>
<p>Yes, this issue falls within our core development responsibilities, and we will take ownership of fixing the menus.</p>
</section>
<section id="further-reading" class="level2">
<h2 class="anchored" data-anchor-id="further-reading">Further Reading</h2>
<ul>
<li><a href="https://v-sekai.org/">V-Sekai</a></li>
<li>This article is assisted by AI.</li>
</ul>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20230831-fixing-menus.html</guid>
  <pubDate>Wed, 25 Oct 2023 19:05:30 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20230830-generating-v-sekai-worlds.html</link>
  <description><![CDATA[ 



<section id="expanding-worlds" class="level1">
<h1>Expanding Worlds</h1>
<section id="metadata" class="level2">
<h2 class="anchored" data-anchor-id="metadata">Metadata</h2>
<ul>
<li>Status: proposed</li>
<li>Deciders: V-Sekai</li>
<li>Tags: V-Sekai</li>
</ul>
</section>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>V-Sekai is a virtual reality (VR) platform that offers users the opportunity to immerse themselves in virtual worlds. However, there are certain limitations that hinder the overall user experience. This proposal aims to address these limitations by proposing specific areas for improvement within V-Sekai.</p>
</section>
<section id="the-challenge" class="level2">
<h2 class="anchored" data-anchor-id="the-challenge">The Challenge</h2>
<p>V-Sekai currently faces several limitations, including non-functional menus in VR mode and a limited number of available worlds. These challenges affect the usability and variety of experiences for the users. To overcome these challenges and enhance the V-Sekai user experience, we must prioritize and focus on one area for improvement.</p>
<section id="proposed-solutions" class="level3">
<h3 class="anchored" data-anchor-id="proposed-solutions">Proposed Solutions</h3>
<p>We propose focusing on <strong>Generating More Worlds</strong> as the first step towards enhancing V-Sekai. By creating new VR worlds within V-Sekai, users will have a wider range of experiences to explore. This involves designing and implementing new environments to expand the options available. With more worlds to choose from, users will have increased engagement and longer sessions within the V-Sekai platform.</p>
</section>
</section>
<section id="the-strategy" class="level2">
<h2 class="anchored" data-anchor-id="the-strategy">The Strategy</h2>
<p>To generate more worlds for V-Sekai, we will follow a comprehensive strategy that includes the following steps:</p>
<ol type="1">
<li><p><strong>Identify User Preferences</strong>: Understand the target audience and their preferences. Research popular VR themes, genres, and settings to get an idea of what users would enjoy.</p></li>
<li><p><strong>Design New Environments</strong>: Use 3D modeling software like Blender or Unity to design new virtual environments for V-Sekai. Consider creating diverse worlds like fantasy realms, futuristic cities, natural landscapes, or historical settings.</p></li>
<li><p><strong>Implement Interactive Elements</strong>: Make the new worlds interactive by adding objects, characters, and elements that users can engage with. This can include non-playable characters (NPCs), puzzles, hidden items, or mini-games within each world.</p></li>
<li><p><strong>Test and Refine</strong>: Conduct thorough testing to ensure the new worlds are visually appealing, optimized for performance, and provide a seamless VR experience. Gather user feedback and make necessary improvements based on their suggestions.</p></li>
<li><p><strong>Integrate with V-Sekai</strong>: Once the new worlds are ready, integrate them into the V-Sekai platform. Ensure they are easily accessible through the menus or navigation system within V-Sekai’s VR interface.</p></li>
<li><p><strong>Release and Promote</strong>: Launch the updated version of V-Sekai with the newly generated worlds. Promote the release through various channels, such as social media, gaming forums, Virtual Reality communities, and V-Sekai’s official website.</p></li>
</ol>
<p>By following this strategy, we will not only address the current limitations but also create an engaging and immersive VR experience for V-Sekai users.</p>
</section>
<section id="upsides" class="level2">
<h2 class="anchored" data-anchor-id="upsides">Upsides</h2>
<ul>
<li>Increased user engagement: The availability of more worlds will provide users with greater options to explore, leading to longer sessions and increased immersion in V-Sekai.</li>
<li>Expanded user base: With a wider range of experiences, V-Sekai will attract new users who are looking for diverse VR environments.</li>
<li>Positive word-of-mouth: Satisfied users will share their experiences with others, generating positive reviews and recommendations for V-Sekai.</li>
</ul>
</section>
<section id="downsides" class="level2">
<h2 class="anchored" data-anchor-id="downsides">Downsides</h2>
<ul>
<li>Development complexity: Creating new worlds requires significant effort and resources, including 3D modeling, programming, and testing. This may lead to increased development time and costs.</li>
<li>Upfront investment: Generating more worlds will require upfront investment in terms of design, implementation, and integration with V-Sekai.</li>
<li>User feedback and iteration: Continuous user feedback is crucial to refine and improve the new worlds. This iterative process may extend the development timeline.</li>
</ul>
</section>
<section id="the-road-not-taken" class="level2">
<h2 class="anchored" data-anchor-id="the-road-not-taken">The Road Not Taken</h2>
<p>An alternative solution that was considered was <strong>Integrating Backend Services</strong>. This would involve improving the backend infrastructure of V-Sekai to enhance scalability, performance, and reliability. However, after careful consideration, we prioritize generating more worlds as it directly addresses user experience limitations and provides tangible benefits in terms of user engagement and appeal.</p>
</section>
<section id="in-core-and-done-by-us" class="level2">
<h2 class="anchored" data-anchor-id="in-core-and-done-by-us">In Core and Done by Us?</h2>
<p>The generation of more worlds is within the core capabilities of our team at V-Sekai. We have experienced 3D designers, developers, and testers who are skilled in creating immersive VR environments. Therefore, we are confident in our ability to execute this proposed solution effectively and efficiently.</p>
</section>
<section id="further-reading" class="level2">
<h2 class="anchored" data-anchor-id="further-reading">Further Reading</h2>
<ul>
<li><a href="https://v-sekai.org/">V-Sekai</a></li>
<li>This article is assisted by AI.</li>
</ul>
<p>If you have any further questions or need clarification on any aspect of this proposal, please feel free to ask.</p>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20230830-generating-v-sekai-worlds.html</guid>
  <pubDate>Wed, 25 Oct 2023 19:05:30 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20230830-better-object-pick.html</link>
  <description><![CDATA[ 



<section id="improving-vr-experience" class="level1">
<h1>Improving VR Experience</h1>
<section id="metadata" class="level2">
<h2 class="anchored" data-anchor-id="metadata">Metadata</h2>
<ul>
<li>Status: proposed</li>
<li>Deciders: V-Sekai</li>
<li>Tags: V-Sekai</li>
</ul>
</section>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>V-Sekai is a virtual reality (VR) platform that offers users the opportunity to immerse themselves in virtual worlds. However, there are certain limitations that hinder the overall user experience. This documentation aims to address these limitations by proposing specific areas for improvement within V-Sekai.</p>
</section>
<section id="the-challenge" class="level2">
<h2 class="anchored" data-anchor-id="the-challenge">The Challenge</h2>
<p>V-Sekai currently faces several limitations, including non-functional menus in VR mode and a limited number of available worlds. To overcome these challenges and enhance the user experience, we must prioritize and focus on one area for improvement.</p>
<section id="proposed-solutions" class="level3">
<h3 class="anchored" data-anchor-id="proposed-solutions">Proposed Solutions</h3>
<p><strong>Improving Object Pickup and Menus</strong>: Enhancing object pickup mechanics and menus can make interactions within V-Sekai more intuitive and user-friendly. This may include refining controls, feedback mechanisms for object pickup, and finding alternative methods to access menus while in VR mode.</p>
</section>
</section>
<section id="the-strategy" class="level2">
<h2 class="anchored" data-anchor-id="the-strategy">The Strategy</h2>
<p>To ensure efficient use of time and resources, it is advisable to choose one area to focus on and strive to complete it within a two-week timeframe. This focused approach allows for significant progress in improving V-Sekai.</p>
</section>
<section id="upsides" class="level2">
<h2 class="anchored" data-anchor-id="upsides">Upsides</h2>
<p>By addressing these limitations, V-Sekai can offer a more seamless and immersive VR experience. Improving object pickup and menus will enhance user interactions, making them more intuitive and user-friendly. This will ultimately result in a more engaging and enjoyable experience for V-Sekai users.</p>
</section>
<section id="downsides" class="level2">
<h2 class="anchored" data-anchor-id="downsides">Downsides</h2>
<p>Given the limited timeframe, it may not be possible to address all the identified limitations simultaneously. Additionally, the complexity of refining object pickup mechanics and menus may present challenges in achieving substantial improvements within the two-week timeframe. It’s important to carefully assess the scope and feasibility of the proposed enhancements before committing to the timeframe.</p>
</section>
<section id="the-road-not-taken" class="level2">
<h2 class="anchored" data-anchor-id="the-road-not-taken">The Road Not Taken</h2>
<p>While focusing on improving object pickup and menus is recommended for the given timeframe, it’s important to acknowledge that there are other potential areas for improvement. Exploring options such as expanding the variety of worlds, integrating backend services, or optimizing performance can be considered in future iterations of V-Sekai.</p>
</section>
<section id="in-core-and-done-by-us" class="level2">
<h2 class="anchored" data-anchor-id="in-core-and-done-by-us">In Core and Done by Us?</h2>
<p>The development team at V-Sekai should primarily handle the implementation and integration of the chosen improvement. However, collaborative efforts involving developers, designers, and user experience experts may be necessary to ensure the improvements align with the overall vision and goals of V-Sekai.</p>
</section>
<section id="further-reading" class="level2">
<h2 class="anchored" data-anchor-id="further-reading">Further Reading</h2>
<ul>
<li><a href="https://v-sekai.org/">V-Sekai</a></li>
<li>This article is assisted by AI.</li>
</ul>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20230830-better-object-pick.html</guid>
  <pubDate>Wed, 25 Oct 2023 19:05:30 GMT</pubDate>
</item>
</channel>
</rss>
