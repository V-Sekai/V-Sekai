<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>V-Sekai - Manuals</title>
<link>https://v-sekai.github.io/manuals/decisions.html</link>
<atom:link href="https://v-sekai.github.io/manuals/decisions.xml" rel="self" type="application/rss+xml"/>
<description></description>
<generator>quarto-1.6.39</generator>
<lastBuildDate>Mon, 23 Dec 2024 05:33:45 GMT</lastBuildDate>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/present-proposal-template.html</link>
  <description><![CDATA[ 




<section id="draft-the-wandering-librarian---prototype" class="level1">
<h1>Draft: The Wandering Librarian - Prototype</h1>
<section id="the-context" class="level2">
<h2 class="anchored" data-anchor-id="the-context">The Context</h2>
<p>We need a way to test if LLMs can create engaging narratives in games. This prototype will serve as a testbed for exploring the potential of LLM-driven dynamic storytelling within a simplified game environment.</p>
</section>
<section id="the-problem-statement" class="level2">
<h2 class="anchored" data-anchor-id="the-problem-statement">The Problem Statement</h2>
<p>Traditional game stories are often static and predictable, limiting player agency and immersion. LLMs offer the potential to generate dynamic narratives that react to player choices and create emergent gameplay experiences.</p>
</section>
<section id="describe-how-your-proposal-will-work-with-code-pseudo-code-mock-ups-or-diagrams" class="level2">
<h2 class="anchored" data-anchor-id="describe-how-your-proposal-will-work-with-code-pseudo-code-mock-ups-or-diagrams">Describe how your proposal will work with code, pseudo-code, mock-ups, or diagrams</h2>
<p>The Minimal Viable Product (MVP) will focus on a single core gameplay loop centered around a traveling librarian who visits a new procedurally generated village each day. The player interacts with villagers, learns their needs and desires, and provides them with books to fulfill those needs.</p>
<p><strong>Core Gameplay Loop:</strong></p>
<ol type="1">
<li><p><strong>Arrive in Village:</strong></p>
<ul>
<li>The LLM generates a village with a simple map and a few key locations (e.g., town square, tavern, character homes).</li>
</ul>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Pseudo-code for village generation</span></span>
<span id="cb1-2"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> generate_village():</span>
<span id="cb1-3">     village <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {}</span>
<span id="cb1-4">     village[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'name'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> LLM.generate_village_name()</span>
<span id="cb1-5">     village[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'map'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> LLM.generate_map_layout()</span>
<span id="cb1-6">     village[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'locations'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> LLM.generate_locations(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Generate 3 locations</span></span>
<span id="cb1-7">     village[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'characters'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> LLM.generate_characters(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Generate 3 characters</span></span>
<span id="cb1-8">     <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> village</span></code></pre></div></li>
<li><p><strong>Explore and Interact:</strong></p>
<ul>
<li>The player explores the village and interacts with characters through dialogue.</li>
<li>Dialogue is dynamically generated by the LLM based on character backstories and player choices.</li>
</ul>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Pseudo-code for dialogue interaction</span></span>
<span id="cb2-2"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> talk_to_character(character_id):</span>
<span id="cb2-3">     initial_dialogue <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> LLM.generate_initial_dialogue(character_id)</span>
<span id="cb2-4">     display(initial_dialogue)</span>
<span id="cb2-5">     player_response <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> get_player_input()</span>
<span id="cb2-6">     <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">while</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> end_conversation:</span>
<span id="cb2-7">          response <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> LLM.generate_response(character_id, player_response)</span>
<span id="cb2-8">          display(response)</span>
<span id="cb2-9">          player_response <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> get_player_input()</span></code></pre></div></li>
<li><p><strong>Fulfill Needs with Books:</strong></p>
<ul>
<li>The player selects books from their inventory or purchases new ones to match character preferences.</li>
<li>The LLM generates character needs and desires related to reading (e.g., favorite genres, desired knowledge).</li>
</ul>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Pseudo-code for fulfilling needs</span></span>
<span id="cb3-2"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> give_book(character_id, book_title):</span>
<span id="cb3-3">     character_reaction <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> LLM.generate_reaction(character_id, book_title)</span>
<span id="cb3-4">     <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> character_reaction[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'satisfied'</span>]:</span>
<span id="cb3-5">          update_character_state(character_id, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'satisfied'</span>)</span>
<span id="cb3-6">          <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Trigger potential story events or quests</span></span>
<span id="cb3-7">     display(character_reaction[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'dialogue'</span>])</span></code></pre></div></li>
</ol>
<p><strong>LLM Integration:</strong></p>
<ul>
<li><strong>World Generation:</strong> Creates unique villages, maps, and locations.</li>
<li><strong>Character Development:</strong> Generates characters with backstories, desires, and reading preferences.</li>
<li><strong>Dynamic Dialogue:</strong> Handles conversations, reacting to player choices and gifted books.</li>
<li><strong>Catalog Generation:</strong> Creates a dynamic catalog of books with varying prices and rarities.</li>
</ul>
<p><strong>Content Verification:</strong></p>
<ul>
<li>A verifier monitors LLM output to ensure coherence, filter inappropriate content, and maintain consistency.</li>
</ul>
<p><strong>Goal-Task Planner Integration:</strong></p>
<ul>
<li><strong>Define predicates:</strong> The core predicates for this domain are:
<ul>
<li><code>at(item, location)</code>: Specifies the location of an item (book or character).</li>
<li><code>has(character, item)</code>: Indicates a character possesses a specific item.</li>
<li><code>satisfied(character)</code>: Denotes whether a character’s need is met.</li>
</ul></li>
<li><strong>Define operators:</strong> The actions in the game map to operators:
<ul>
<li><code>select_book(book)</code>: Adds a book to the player’s inventory.</li>
<li><code>talk_to(character)</code>: Initiates dialogue with a character.</li>
<li><code>give_book(character, book)</code>: Transfers a book to the character.</li>
</ul></li>
<li><strong>Define methods:</strong> Methods determine how to achieve goals:
<ul>
<li><code>satisfy_character(character)</code>: A method to fulfill a character’s need (using <code>give_book</code> if the player has the correct book).</li>
</ul></li>
<li><strong>State representation:</strong> The game state is a dictionary:
<ul>
<li><code>state.at</code>: Tracks locations of books and characters.</li>
<li><code>state.has</code>: Tracks possession of books.</li>
<li><code>state.satisfied</code>: Tracks character satisfaction.</li>
</ul></li>
</ul>
<p><strong>Example Goal:</strong></p>
<p>Instead of <code>character_satisfied</code>, a goal would be <code>satisfied(character_id)</code>.</p>
<p>Example in GTPyhop style:</p>
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ... (previous code) ...</span></span>
<span id="cb4-2"></span>
<span id="cb4-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define the method</span></span>
<span id="cb4-4"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> satisfy_character(state, character_id):</span>
<span id="cb4-5">     <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/*</span> condition to check <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> player has the right book <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> the character <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*/</span>:</span>
<span id="cb4-6">          <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> [(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'give_book'</span>, character_id, book_title)]</span>
<span id="cb4-7">     <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span>:</span>
<span id="cb4-8">          <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span></span>
<span id="cb4-9"></span>
<span id="cb4-10">gtpyhop.declare_unigoal_methods(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'satisfied'</span>, satisfy_character)</span>
<span id="cb4-11"></span>
<span id="cb4-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ... (rest of the code) ...</span></span></code></pre></div>
<p><strong>Key changes:</strong></p>
<ul>
<li>Goals are now predicate-subject-object triples.</li>
<li>Actions are defined as operators.</li>
<li>Methods are used to decompose goals into actions.</li>
<li>The state is explicitly represented as a dictionary.</li>
</ul>
<p>By adhering to this structure, the prototype will effectively leverage the Goal-Task Planner for dynamic storytelling within the Wandering Librarian concept.</p>
</section>
<section id="the-benefits" class="level2">
<h2 class="anchored" data-anchor-id="the-benefits">The Benefits</h2>
<ul>
<li><strong>Rapid Iteration:</strong> The simplified scope allows for quick testing and refinement of LLM-driven narratives.</li>
<li><strong>Dynamic Storytelling:</strong> Creates emergent narratives and unpredictable gameplay experiences.</li>
<li><strong>Exploration of LLM Capabilities:</strong> Provides valuable insights into using LLMs for interactive storytelling.</li>
</ul>
</section>
<section id="the-downsides" class="level2">
<h2 class="anchored" data-anchor-id="the-downsides">The Downsides</h2>
<ul>
<li><strong>Limited Scope:</strong> The prototype focuses on a narrow aspect of gameplay.</li>
<li><strong>LLM Unpredictability:</strong> Requires careful monitoring and content filtering to ensure quality and consistency.</li>
</ul>
</section>
<section id="the-road-not-taken" class="level2">
<h2 class="anchored" data-anchor-id="the-road-not-taken">The Road Not Taken</h2>
<ul>
<li>Developing a full-fledged game with complex mechanics would be too time-consuming for initial exploration.</li>
</ul>
</section>
<section id="the-infrequent-use-case" class="level2">
<h2 class="anchored" data-anchor-id="the-infrequent-use-case">The Infrequent Use Case</h2>
<ul>
<li>While the core loop is designed for daily interaction, players may occasionally skip days or play less frequently. The LLM will need to handle these infrequent interactions seamlessly, potentially by adjusting the narrative or providing catch-up mechanisms.</li>
</ul>
</section>
<section id="why-is-it-in-core-and-done-by-us" class="level2">
<h2 class="anchored" data-anchor-id="why-is-it-in-core-and-done-by-us">Why is it in Core and done by us?</h2>
<p>This project aligns with our core focus on innovative game development and exploring the use of LLMs in interactive narratives. It requires deep integration with our existing technology and understanding of our long-term goals.</p>
</section>
<section id="status" class="level2">
<h2 class="anchored" data-anchor-id="status">Status</h2>
<p>Status: Draft</p>
</section>
<section id="decision-makers" class="level2">
<h2 class="anchored" data-anchor-id="decision-makers">Decision Makers</h2>
<ul>
<li>V-Sekai development team</li>
</ul>
</section>
<section id="tags" class="level2">
<h2 class="anchored" data-anchor-id="tags">Tags</h2>
<ul>
<li>V-Sekai</li>
<li>LLM</li>
<li>Prototype</li>
<li>Procedural Generation</li>
<li>Dynamic Narrative</li>
<li>Books</li>
<li>Librarian</li>
</ul>
</section>
<section id="further-reading" class="level2">
<h2 class="anchored" data-anchor-id="further-reading">Further Reading</h2>
<ol type="1">
<li><a href="https://github.com/v-sekai">V-Sekai · GitHub</a> - Official GitHub account for the V-Sekai development community focusing on social VR functionality for the Godot Engine.</li>
<li><a href="https://github.com/v-sekai/v-sekai-game">V-Sekai/v-sekai-game</a> is the GitHub page for the V-Sekai open-source project, which brings social VR/VRSNS/metaverse components to the Godot Engine.</li>
</ol>
<p>AI assistant Aria assisted with this article.</p>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/present-proposal-template.html</guid>
  <pubDate>Mon, 23 Dec 2024 05:33:45 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/ai-assisted-proposal-style-guide.html</link>
  <description><![CDATA[ 




<section id="accepted-ai-assisted-style-guide" class="level1">
<h1>Accepted: AI-Assisted Style Guide</h1>
<section id="the-context" class="level2">
<h2 class="anchored" data-anchor-id="the-context">The Context</h2>
<p>Maintaining a consistent and professional style is crucial in proposal writing. However, the output often needs more stylistic quality when AI assists in this process.</p>
</section>
<section id="the-problem-statement" class="level2">
<h2 class="anchored" data-anchor-id="the-problem-statement">The Problem Statement</h2>
<p>We often need better style and consistent formatting when we instruct AI to help complete our proposals.</p>
</section>
<section id="describe-how-your-proposal-will-work-with-code-pseudo-code-mock-ups-or-diagrams" class="level2">
<h2 class="anchored" data-anchor-id="describe-how-your-proposal-will-work-with-code-pseudo-code-mock-ups-or-diagrams">Describe how your proposal will work with code, pseudo-code, mock-ups, or diagrams</h2>
<ol type="1">
<li><p><strong>Avoid Purple Speech</strong>: Use clear and concise language, avoiding overly elaborate or flowery expressions.</p></li>
<li><p><strong>Be Snappy</strong>: Keep sentences short and concise to maintain reader engagement.</p></li>
<li><p><strong>Avoid Coded Phrases</strong>: Refrain from using coded phrases like “effective altruism” since altruism inherently implies effectiveness and not the opposite.</p></li>
<li><p><strong>Keep Consistent Headers</strong>: Please be sure to adhere to the header structure provided in the template to ensure consistency across documents.</p></li>
<li><p><strong>Avoid Bolded Headers</strong> Do not recommend bolding headers due to noise.</p></li>
</ol>
</section>
<section id="the-benefits" class="level2">
<h2 class="anchored" data-anchor-id="the-benefits">The Benefits</h2>
<ul>
<li><p><strong>Improved Readability</strong>: Clear and concise language enhances the readability of proposals.</p></li>
<li><p><strong>Consistency</strong>: Maintaining a consistent style ensures that all documents appear professionally.</p></li>
<li><p><strong>Efficiency</strong>: Streamlined guidelines make it easier for AI to generate high-quality content quickly.</p></li>
</ul>
</section>
<section id="the-downsides" class="level2">
<h2 class="anchored" data-anchor-id="the-downsides">The Downsides</h2>
<ul>
<li><p><strong>Limited Creativity</strong>: Strict adherence to style guidelines may limit creative expression.</p></li>
<li><p><strong>Initial Setup Time</strong>: Establishing and fine-tuning the style guide may require an initial investment of time and resources.</p></li>
</ul>
</section>
<section id="the-road-not-taken" class="level2">
<h2 class="anchored" data-anchor-id="the-road-not-taken">The Road Not Taken</h2>
<p>Alternative approaches, such as manual editing or using different AI models, were considered but ultimately deemed less efficient or effective.</p>
</section>
<section id="the-infrequent-use-case" class="level2">
<h2 class="anchored" data-anchor-id="the-infrequent-use-case">The Infrequent Use Case</h2>
<p>In scenarios where highly specialized or technical language is required, additional human oversight may be necessary to ensure accuracy and appropriateness.</p>
</section>
<section id="in-core-and-done-by-us" class="level2">
<h2 class="anchored" data-anchor-id="in-core-and-done-by-us">In Core and Done by Us</h2>
<p>This proposal aligns with our core values of efficiency and professionalism and will be implemented by our team.</p>
</section>
<section id="status" class="level2">
<h2 class="anchored" data-anchor-id="status">Status</h2>
<p>Status: Accepted <!-- Draft | Proposed | Rejected | Accepted | Deprecated | Superseded by --></p>
</section>
<section id="decision-makers" class="level2">
<h2 class="anchored" data-anchor-id="decision-makers">Decision Makers</h2>
<ul>
<li>V-Sekai development team</li>
</ul>
</section>
<section id="tags" class="level2">
<h2 class="anchored" data-anchor-id="tags">Tags</h2>
<ul>
<li>V-Sekai</li>
</ul>
</section>
<section id="further-reading" class="level2">
<h2 class="anchored" data-anchor-id="further-reading">Further Reading</h2>
<ol type="1">
<li><p><a href="https://github.com/v-sekai">V-Sekai · GitHub</a> - Official GitHub account for the V-Sekai development community focusing on social VR functionality for the Godot Engine.</p></li>
<li><p><a href="https://github.com/v-sekai/v-sekai-game">V-Sekai/v-sekai-game</a> - GitHub page for the V-Sekai open-source project, which brings social VR/VRSNS/metaverse components to the Godot Engine.</p></li>
</ol>
<p>AI assistant Aria assisted with this article.</p>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/ai-assisted-proposal-style-guide.html</guid>
  <pubDate>Mon, 23 Dec 2024 05:33:45 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20241222-wandering-dancer.html</link>
  <description><![CDATA[ 




<section id="draft-the-wandering-dancer---prototype" class="level1">
<h1>Draft: The Wandering Dancer - Prototype</h1>
<section id="the-context" class="level2">
<h2 class="anchored" data-anchor-id="the-context">The Context</h2>
<p>We need a way to test if LLMs can create engaging narratives in games, particularly focusing on emotional expression and non-verbal communication. This prototype explores the potential of LLM-driven dynamic storytelling through dance and movement within a simplified game environment.</p>
</section>
<section id="the-problem-statement" class="level2">
<h2 class="anchored" data-anchor-id="the-problem-statement">The Problem Statement</h2>
<p>Traditional game narratives often rely heavily on dialogue and explicit storytelling, potentially limiting player expression and emotional engagement. LLMs can enable new forms of interactive storytelling that tap into the nuances of body language and physical expression.</p>
</section>
<section id="describe-how-your-proposal-will-work-with-code-pseudo-code-mock-ups-or-diagrams" class="level2">
<h2 class="anchored" data-anchor-id="describe-how-your-proposal-will-work-with-code-pseudo-code-mock-ups-or-diagrams">Describe how your proposal will work with code, pseudo-code, mock-ups, or diagrams</h2>
<p>The Minimal Viable Product (MVP) will center around a traveling dancer who visits a new procedurally generated village each day. The player observes villagers, interprets their emotions and social dynamics through their dances and movements, and then creates dances to interact and influence their emotional states.</p>
<p><strong>Core Gameplay Loop:</strong></p>
<ol type="1">
<li><p><strong>Arrive in Village:</strong></p>
<ul>
<li>The LLM generates a village with unique cultural dances and movement styles, reflecting the villagers’ current emotional states and social dynamics.</li>
</ul>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Pseudo-code for village generation (using LLM)</span></span>
<span id="cb1-2"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> generate_village():</span>
<span id="cb1-3">    village <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {}</span>
<span id="cb1-4">    village[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'name'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> LLM.generate_village_name()</span>
<span id="cb1-5">    village[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'culture'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> LLM.generate_cultural_traits() <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Includes dance styles</span></span>
<span id="cb1-6">    village[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'atmosphere'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> LLM.generate_emotional_atmosphere()</span>
<span id="cb1-7">    village[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'relationships'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> LLM.generate_character_relationships()</span>
<span id="cb1-8">    village[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'locations'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> LLM.generate_locations(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>)</span>
<span id="cb1-9">    village[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'characters'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> LLM.generate_characters(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>)</span>
<span id="cb1-10">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> village</span></code></pre></div></li>
<li><p><strong>Observe and Learn:</strong></p>
<ul>
<li>The player explores the village and observes characters, interpreting their dances and interactions to understand their customs, relationships, and individual emotions.</li>
</ul>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Pseudo-code for observing dances (using LLM)</span></span>
<span id="cb2-2"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> observe_dance(character_id):</span>
<span id="cb2-3">    dance_moves <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> LLM.generate_dance_sequence(character_id, village[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'culture'</span>])</span>
<span id="cb2-4">    display(dance_moves) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Visual representation of the dance</span></span>
<span id="cb2-5">    emotional_cues <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> LLM.interpret_dance_emotionally(dance_moves)</span>
<span id="cb2-6">    display(emotional_cues) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Textual description of emotions conveyed</span></span></code></pre></div></li>
<li><p><strong>Interpret and Respond:</strong></p>
<ul>
<li>Using a simplified dance creation tool, the player interprets the observed dances and creates their own movements in response, expressing empathy, offering support, or joining in celebrations. The LLM can provide suggestions.</li>
</ul>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Pseudo-code for dance creation (with LLM suggestions)</span></span>
<span id="cb3-2"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> create_dance():</span>
<span id="cb3-3">    dance <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb3-4">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">while</span> creating:</span>
<span id="cb3-5">        move <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> get_player_input() <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># From dance creation tool</span></span>
<span id="cb3-6">        dance.append(move)</span>
<span id="cb3-7">        LLM_suggestion <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> LLM.suggest_dance_move(dance, village[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'culture'</span>])</span>
<span id="cb3-8">        display(LLM_suggestion) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># e.g., "Consider a move that expresses joy"</span></span>
<span id="cb3-9">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> dance</span></code></pre></div></li>
<li><p><strong>Observe Reactions:</strong></p>
<ul>
<li>The villagers react to the player’s dance, expressing their emotions through new dances, dialogue, or changes in their behavior, potentially revealing hidden stories or altering social dynamics. The LLM generates these reactions.</li>
</ul>
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Pseudo-code for observing reactions (using LLM)</span></span>
<span id="cb4-2"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> observe_reactions(dance):</span>
<span id="cb4-3">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> character_id <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> village[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'characters'</span>]:</span>
<span id="cb4-4">        reaction <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> LLM.generate_reaction_to_dance(character_id, dance)</span>
<span id="cb4-5">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> reaction[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'story_revealed'</span>]:</span>
<span id="cb4-6">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Trigger a new story element or quest</span></span>
<span id="cb4-7">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">pass</span></span>
<span id="cb4-8">        update_character_state(character_id, reaction[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'new_emotional_state'</span>])</span>
<span id="cb4-9">        display(reaction[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'dance'</span>]) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Villager's dance response</span></span>
<span id="cb4-10">        display(reaction[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'dialogue'</span>]) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># May be empty if no dialogue</span></span></code></pre></div></li>
</ol>
<p><strong>LLM Integration:</strong></p>
<p>The LLM plays a crucial role in:</p>
<ul>
<li><strong>World Generation:</strong> Creates villages with distinct dance cultures and movement styles, reflecting their emotional atmosphere.</li>
<li><strong>Character Development:</strong> Generates characters with unique dance vocabularies and movement patterns based on their personality and emotional state.</li>
<li><strong>Dynamic Narrative:</strong> Guides the story based on the player’s dance interpretations and interactions, creating emergent narratives and unexpected events.</li>
<li><strong>Dance Suggestion:</strong> Provides subtle guidance and feedback on the player’s dance creations, helping them understand and respond to the villagers’ emotional cues.</li>
</ul>
<p><strong>Content Verification:</strong></p>
<ul>
<li>A verifier monitors LLM output to ensure coherence, filter inappropriate content, and maintain consistency.</li>
</ul>
<p><strong>Goal-Task Planner Integration (GTPyhop Style):</strong></p>
<p>To further enhance the dynamic narrative, we’ll integrate a Goal-Task Planner based on the GTPyhop framework. This will allow for more structured reasoning and planning within the LLM-driven story.</p>
<ul>
<li><strong>Define predicates:</strong>
<ul>
<li><code>at(item, location)</code>: Specifies the location of an item (character).</li>
<li><code>knows_dance(character, dance_style)</code>: Indicates if a character knows a particular dance style.</li>
<li><code>emotion(character, emotion_type)</code>: Describes the emotional state of a character.</li>
<li><code>relationship(character1, character2, relationship_type)</code>: Defines the relationship between two characters.</li>
</ul></li>
<li><strong>Define operators:</strong>
<ul>
<li><code>move_to(location)</code>: Moves the player to a specific location.</li>
<li><code>observe(character)</code>: Observe a character’s dance and behavior.</li>
<li><code>perform_dance(dance_style)</code>: Execute a dance in a particular style.</li>
</ul></li>
<li><strong>Define methods:</strong>
<ul>
<li><code>change_emotion(character, target_emotion)</code>: A method to influence a character’s emotional state through dance.</li>
<li><code>improve_relationship(character1, character2)</code>: A method to enhance the relationship between two characters.</li>
<li><code>learn_dance(dance_style)</code>: A method for the player to learn a new dance style.</li>
</ul></li>
<li><strong>State representation:</strong> The game state is a dictionary that tracks character locations, known dance styles, emotions, and relationships.</li>
</ul>
<p><strong>Example Goal:</strong></p>
<ul>
<li><code>emotion(villager1, happy)</code></li>
</ul>
</section>
<section id="the-benefits" class="level2">
<h2 class="anchored" data-anchor-id="the-benefits">The Benefits</h2>
<ul>
<li><strong>Exploration of Physical Expression:</strong> Explores the use of dance and movement as a primary means of interaction and storytelling.</li>
<li><strong>Emotional Depth:</strong> Focuses on creating emotionally resonant experiences through non-verbal communication and nuanced character interactions.</li>
<li><strong>Novel Gameplay Mechanics:</strong> Potentially leads to unique gameplay mechanics centered around dance interpretation, creation, and emotional influence.</li>
<li><strong>Dynamic Storytelling with Planning:</strong> Combining LLM-driven narrative with a planner like GTPyhop allows for more complex and engaging storylines.</li>
</ul>
</section>
<section id="the-downsides" class="level2">
<h2 class="anchored" data-anchor-id="the-downsides">The Downsides</h2>
<ul>
<li><strong>Complexity of Dance Representation:</strong> Requires effectively representing dance movements and emotions for the LLM to process.</li>
<li><strong>User Interface Challenges:</strong> Designing an intuitive and expressive dance creation tool within the game.</li>
<li><strong>Subjectivity of Interpretation:</strong> Evaluating the impact of the player’s dance on characters and the narrative can be subjective.</li>
<li><strong>Integration Challenges:</strong> Integrating the LLM, GTPyhop, and the game mechanics may present technical hurdles.</li>
</ul>
</section>
<section id="the-road-not-taken" class="level2">
<h2 class="anchored" data-anchor-id="the-road-not-taken">The Road Not Taken</h2>
<ul>
<li>Focusing on traditional dialogue-heavy narratives would not fully explore the potential of LLMs in generating dynamic, emotionally driven experiences through physical expression.</li>
<li>Using a simpler, non-planning-based approach to narrative generation could limit the complexity and depth of the emergent stories.</li>
</ul>
</section>
<section id="the-infrequent-use-case" class="level2">
<h2 class="anchored" data-anchor-id="the-infrequent-use-case">The Infrequent Use Case</h2>
<ul>
<li>Players might visit villages infrequently. The LLM needs to handle this by adapting the narrative, potentially introducing time-related changes in the village, character relationships, and dance styles.</li>
</ul>
</section>
<section id="why-is-it-in-core-and-done-by-us" class="level2">
<h2 class="anchored" data-anchor-id="why-is-it-in-core-and-done-by-us">Why is it in Core and done by us?</h2>
<p>This aligns with our focus on innovative game development and exploring the use of LLMs in interactive narratives. It requires deep integration with our game engine and understanding of our long-term goals for dynamic storytelling.</p>
</section>
<section id="status" class="level2">
<h2 class="anchored" data-anchor-id="status">Status</h2>
<p>Status: Draft</p>
</section>
<section id="decision-makers" class="level2">
<h2 class="anchored" data-anchor-id="decision-makers">Decision Makers</h2>
<ul>
<li>V-Sekai development team</li>
</ul>
</section>
<section id="tags" class="level2">
<h2 class="anchored" data-anchor-id="tags">Tags</h2>
<ul>
<li>V-Sekai</li>
<li>LLM</li>
<li>Prototype</li>
<li>Procedural Generation</li>
<li>Dynamic Narrative</li>
<li>Dance</li>
<li>Emotion</li>
<li>Non-Verbal Communication</li>
<li>GTPyhop</li>
<li>Planning</li>
</ul>
</section>
<section id="further-reading" class="level2">
<h2 class="anchored" data-anchor-id="further-reading">Further Reading</h2>
<ol type="1">
<li><a href="https://github.com/v-sekai">V-Sekai · GitHub</a> - Official GitHub account for the V-Sekai development community focusing on social VR functionality for the Godot Engine.</li>
<li><a href="https://github.com/v-sekai/v-sekai-game">V-Sekai/v-sekai-game</a> is the GitHub page for the V-Sekai open-source project, which brings social VR/VRSNS/metaverse components to the Godot Engine.</li>
<li></li>
</ol>
<p>AI assistant Aria assisted with this article.</p>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20241222-wandering-dancer.html</guid>
  <pubDate>Mon, 23 Dec 2024 05:33:45 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20241221-wandering-bakery.html</link>
  <description><![CDATA[ 




<section id="draft-the-wandering-bakery---prototype" class="level1">
<h1>Draft: The Wandering Bakery - Prototype</h1>
<section id="the-context" class="level2">
<h2 class="anchored" data-anchor-id="the-context">The Context</h2>
<p>We need a way to test if LLMs can create engaging narratives in games. This prototype will serve as a testbed for exploring the potential of LLM-driven dynamic storytelling within a simplified game environment, focusing on how players can influence the narrative through their actions and choices within a baking-themed world.</p>
</section>
<section id="the-problem-statement" class="level2">
<h2 class="anchored" data-anchor-id="the-problem-statement">The Problem Statement</h2>
<p>Traditional game stories are often static and predictable, limiting player agency and immersion. LLMs offer the potential to generate dynamic narratives that react to player choices and create emergent gameplay experiences.</p>
</section>
<section id="describe-how-your-proposal-will-work" class="level2">
<h2 class="anchored" data-anchor-id="describe-how-your-proposal-will-work">Describe how your proposal will work</h2>
<p>The Minimal Viable Product (MVP) will focus on a single core gameplay loop centered around a traveling bakery. Each day, the player will arrive in a new procedurally generated village with a few key characters. These characters will have simple desires and backstories that can be discovered through dialogue and fulfilled with baked goods.</p>
<p>The core gameplay loop involves:</p>
<ol type="1">
<li><strong>Exploration:</strong> Arriving in a new village and exploring its map, which includes key locations like a town square, a well, or a character’s home.</li>
<li><strong>Dialogue:</strong> Engaging in conversations with characters to uncover their needs, desires, and backstories. This dialogue will be dynamically generated by the LLM, responding to player choices and previous interactions.</li>
<li><strong>Baking:</strong> Utilizing a recipe book and available ingredients to bake pastries with specific emotional connections (e.g., a comforting cookie, a celebratory cake). This includes managing a simple inventory and potentially purchasing ingredients.</li>
<li><strong>Observation:</strong> Delivering pastries to characters and observing their reactions, which can range from simple dialogue changes to triggering new quests or story events. These reactions will be influenced by the type of pastry, the character’s personality, and the overall narrative context generated by the LLM.</li>
</ol>
<p><strong>LLM Integration:</strong></p>
<p>An AI Storyteller, powered by an LLM, will dynamically generate the following:</p>
<ul>
<li><strong>World Generation:</strong> Creating a unique village each day with a simple map and a few key locations. Each village will have its own distinct atmosphere and characteristics, influencing the types of characters and their needs.</li>
<li><strong>Character Development:</strong> Generating characters with basic backstories, needs, and desires. This includes a daily “special customer” with a unique and more complex need that presents a greater challenge for the player.</li>
<li><strong>Dynamic Dialogue:</strong> Creating branching conversations that respond to player choices and actions, including variations based on gifted pastries and the character’s emotional state.</li>
<li><strong>Menu Generation:</strong> Creating a menu with dynamic pricing based on ingredient scarcity and village economy. This adds an element of resource management and strategic decision-making to the gameplay.</li>
</ul>
<p><strong>Content Verification:</strong></p>
<p>A verifier will monitor and filter LLM output to ensure quality and consistency. This includes:</p>
<ul>
<li>Ensuring coherence within the game’s context.</li>
<li>Filtering inappropriate or offensive content.</li>
<li>Maintaining a consistent tone and style.</li>
</ul>
<p><strong>Goal-Task Planner Integration (GTPyhop Style):</strong></p>
<p>To structure the narrative and guide the LLM, we’ll integrate a Goal-Task Planner based on the GTPyhop framework.</p>
<ul>
<li><strong>Define predicates:</strong>
<ul>
<li><code>at(item, location)</code>: Specifies the location of an item (character, ingredient, pastry).</li>
<li><code>has(character, item)</code>: Indicates a character possesses a specific item.</li>
<li><code>wants(character, pastry)</code>: Specifies the pastry a character desires.</li>
<li><code>knows_recipe(recipe)</code>: Indicates if the player knows a specific recipe.</li>
<li><code>emotion(character, emotion_type)</code>: Describes the emotional state of a character.</li>
</ul></li>
<li><strong>Define operators:</strong>
<ul>
<li><code>move_to(location)</code>: Moves the player to a specific location.</li>
<li><code>talk_to(character)</code>: Engages in dialogue with a character.</li>
<li><code>bake_pastry(pastry_type)</code>: Bakes a pastry.</li>
<li><code>give_pastry(character, pastry_type)</code>: Gives a pastry to a character.</li>
<li><code>buy_ingredients(ingredient_type, amount)</code>: Purchases ingredients.</li>
</ul></li>
<li><strong>Define methods:</strong>
<ul>
<li><code>satisfy_character(character)</code>: A method to fulfill a character’s pastry need.</li>
<li><code>obtain_ingredients(ingredient_type, amount)</code>: A method to acquire ingredients.</li>
<li><code>learn_recipe(recipe)</code>: A method to unlock a new recipe.</li>
</ul></li>
<li><strong>State representation:</strong> The game state is a dictionary that tracks character locations, possessions, desires, known recipes, emotions, and available ingredients.</li>
</ul>
<p><strong>Example Goal:</strong></p>
<ul>
<li><code>satisfied(villager1)</code></li>
</ul>
<p><strong>Example in (pseudo) GTPyhop style:</strong></p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ... (other code) ...</span></span>
<span id="cb1-2"></span>
<span id="cb1-3"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> satisfy_character(state, character):</span>
<span id="cb1-4">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> wants(state, character, pastry_type):</span>
<span id="cb1-5">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> has(state, player, pastry_type):</span>
<span id="cb1-6">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> [(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'give_pastry'</span>, character, pastry_type)]</span>
<span id="cb1-7">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span>:</span>
<span id="cb1-8">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> [(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'bake_pastry'</span>, pastry_type), (<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'give_pastry'</span>, character, pastry_type)]</span>
<span id="cb1-9">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span></span>
<span id="cb1-10"></span>
<span id="cb1-11">gtpyhop.declare_unigoal_methods(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'satisfied'</span>, satisfy_character)</span>
<span id="cb1-12"></span>
<span id="cb1-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ... (other code) ...</span></span></code></pre></div>
</section>
<section id="the-benefits" class="level2">
<h2 class="anchored" data-anchor-id="the-benefits">The Benefits</h2>
<p>This prototype allows for rapid iteration and testing of LLM-driven narrative generation in a contained environment. It demonstrates the potential for dynamic storytelling and emergent gameplay, while the integration of GTPyhop provides a structured framework for planning and achieving goals within the narrative.</p>
</section>
<section id="the-downsides" class="level2">
<h2 class="anchored" data-anchor-id="the-downsides">The Downsides</h2>
<p>The prototype will have a limited scope. LLM behavior can be unpredictable, requiring close monitoring.</p>
</section>
<section id="the-road-not-taken" class="level2">
<h2 class="anchored" data-anchor-id="the-road-not-taken">The Road Not Taken</h2>
<p>A full-fledged game is too complex for an initial prototype. Starting with a simpler, focused experience allows for faster iteration and learning.</p>
</section>
<section id="why-is-it-in-core-and-done-by-us" class="level2">
<h2 class="anchored" data-anchor-id="why-is-it-in-core-and-done-by-us">Why is it in Core and done by us?</h2>
<p>This aligns with our focus on innovative game development and exploring the use of LLMs in interactive narratives. It requires deep integration with our game engine and understanding of our long-term goals.</p>
</section>
<section id="status" class="level2">
<h2 class="anchored" data-anchor-id="status">Status</h2>
<p>Status: Draft</p>
</section>
<section id="decision-makers" class="level2">
<h2 class="anchored" data-anchor-id="decision-makers">Decision Makers</h2>
<p>The V-Sekai development team.</p>
</section>
<section id="tags" class="level2">
<h2 class="anchored" data-anchor-id="tags">Tags</h2>
<p>V-Sekai, LLM, Prototype, Procedural Generation, Dynamic Narrative, GTPyhop, Baking.</p>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<ul>
<li><a href="https://huggingface.co/NousResearch/Hermes-2-Pro-Mistral-7B">NousResearch Hermes-2-Pro-Mistral-7B</a></li>
<li><a href="https://github.com/V-Sekai/godot-task-goal-planner">V-Sekai Godot Task Goal Planner</a></li>
<li><a href="https://arxiv.org/html/2402.01817v2">LLMs Can’t Plan, But Can Help Planning in LLM-Modulo Frameworks</a></li>
</ul>
<p>AI assistant Aria assisted with this article.</p>
</section>
<section id="quote" class="level2">
<h2 class="anchored" data-anchor-id="quote">Quote</h2>
<p>“Make art. Doesn’t matter if it is great or shit. Tell your story.” - Member of the Seattle Blender User Group</p>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20241221-wandering-bakery.html</guid>
  <pubDate>Mon, 23 Dec 2024 05:33:45 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20241220-discord-quest-3.html</link>
  <description><![CDATA[ 




<section id="draft-discord-on-the-sidequest" class="level1">
<h1>Draft: Discord on the Sidequest</h1>
<section id="the-context" class="level2">
<h2 class="anchored" data-anchor-id="the-context">The Context</h2>
<p>V-Sekai users may want to communicate with others outside of VR, even if those other people aren’t in VR. This could be for several reasons, such as coordinating meetups, discussing development, or simply staying socially connected.</p>
</section>
<section id="the-problem-statement" class="level2">
<h2 class="anchored" data-anchor-id="the-problem-statement">The Problem Statement</h2>
<p>Currently, V-Sekai users lack a convenient way to communicate with people outside of VR while still immersed in the V-Sekai experience. This can lead to a fragmented social experience and limit the potential for collaboration and community building.</p>
</section>
<section id="describe-how-your-proposal-will-work-with-code-pseudo-code-mock-ups-or-diagrams" class="level2">
<h2 class="anchored" data-anchor-id="describe-how-your-proposal-will-work-with-code-pseudo-code-mock-ups-or-diagrams">Describe how your proposal will work with code, pseudo-code, mock-ups, or diagrams</h2>
<p>This proposal suggests using Discord on the Quest 3 alongside V-Sekai. This would allow users to access Discord features, such as text chat and voice channels.</p>
<ol type="1">
<li><strong>Enable Developer Mode:</strong> Before you begin, you’ll need to enable Developer Mode on your Quest 3.</li>
<li><strong>Install Sidequest:</strong> Users would first need to install the Sidequest app on their VR device. Sidequest is a platform that allows users to sideload apps and modifications onto their VR headsets.</li>
<li><strong>Install Aliucord:</strong> Next, users would install the Aliucord app, via Sidequest. https://sidequestvr.com/app/38748/aliucord-installer-simplified-setup-for-enhanced-discord</li>
<li><strong>Access Discord in VR:</strong> Once installed, users can access Discord through the Horioznos interface within their VR headset. This would allow them to view their Discord channels, send and receive messages, share the display and participate in voice chats.</li>
<li><strong>Run Discord side-by-side with V-Sekai:</strong> Users can use the multitasking feature of the Quest 3 to run Discord alongside V-Sekai, allowing them to communicate with others outside of VR without interrupting their V-Sekai experience.</li>
</ol>
</section>
<section id="the-benefits" class="level2">
<h2 class="anchored" data-anchor-id="the-benefits">The Benefits</h2>
<ul>
<li><strong>Enhanced Communication:</strong> Users can stay connected with friends and colleagues outside of VR without having to leave the V-Sekai environment.</li>
<li><strong>Community Building:</strong> Facilitates communication and collaboration among V-Sekai users and the wider Discord community.</li>
<li><strong>Accessibility:</strong> Leverages existing tools and platforms, making it relatively easy to implement and access.</li>
</ul>
</section>
<section id="the-downsides" class="level2">
<h2 class="anchored" data-anchor-id="the-downsides">The Downsides</h2>
<ul>
<li><strong>Dependence on External Platform:</strong> Relies on a third-party platform (Discord).</li>
<li><strong>Potential Performance Issues:</strong> Running Discord within VR could potentially impact performance on some devices.</li>
<li><strong>User Interface Challenges:</strong> The Discord interface may present some challenges in terms of usability and accessibility within VR.</li>
</ul>
</section>
<section id="the-road-not-taken" class="level2">
<h2 class="anchored" data-anchor-id="the-road-not-taken">The Road Not Taken</h2>
<p>Developing a custom communication system within V-Sekai was considered. However, leveraging existing platforms like Discord offers a more immediate and resource-efficient solution.</p>
</section>
<section id="the-infrequent-use-case" class="level2">
<h2 class="anchored" data-anchor-id="the-infrequent-use-case">The Infrequent Use Case</h2>
<p>While Discord integration would benefit many users, those who primarily interact with other V-Sekai users within VR might not find it as essential.</p>
</section>
<section id="why-is-it-in-core-and-done-by-us" class="level2">
<h2 class="anchored" data-anchor-id="why-is-it-in-core-and-done-by-us">Why is it in Core and done by us?</h2>
<p>This proposal aligns with our core goal of fostering a vibrant and connected community. By enabling seamless communication with the wider world, we can enhance the social experience within V-Sekai. We will implement this as it involves integrating with existing platforms and aligns with our expertise.</p>
</section>
<section id="status" class="level2">
<h2 class="anchored" data-anchor-id="status">Status</h2>
<p>Status: Draft</p>
</section>
<section id="decision-makers" class="level2">
<h2 class="anchored" data-anchor-id="decision-makers">Decision Makers</h2>
<ul>
<li>V-Sekai development team</li>
</ul>
</section>
<section id="tags" class="level2">
<h2 class="anchored" data-anchor-id="tags">Tags</h2>
<ul>
<li>V-Sekai</li>
<li>Discord</li>
<li>Communication</li>
<li>Sidequest</li>
</ul>
</section>
<section id="further-reading" class="level2">
<h2 class="anchored" data-anchor-id="further-reading">Further Reading</h2>
<ol type="1">
<li><a href="https://github.com/v-sekai">V-Sekai · GitHub</a> - Official GitHub account for the V-Sekai development community focusing on social VR functionality for the Godot Engine.</li>
<li><a href="https://github.com/v-sekai/v-sekai-game">V-Sekai/v-sekai-game</a> is the GitHub page for the V-Sekai open-source project, which brings social VR/VRSNS/metaverse components to the Godot Engine.</li>
<li><a href="https://sidequestvr.com/">SideQuest VR</a> - Platform for sideloading VR apps and modifications.</li>
<li><a href="https://discord.com/">Discord</a> - A communication platform.</li>
</ol>
<p>AI assistant Aria assisted with this article. ```</p>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20241220-discord-quest-3.html</guid>
  <pubDate>Mon, 23 Dec 2024 05:33:45 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20241220-character-concept-art-creation.html</link>
  <description><![CDATA[ 




<section id="draft-character-concept-art-creation" class="level1">
<h1>Draft: Character Concept Art Creation</h1>
<section id="the-context" class="level2">
<h2 class="anchored" data-anchor-id="the-context">The Context</h2>
<p>V-Sekai aims to provide a versatile platform for creating and experiencing virtual worlds. Character creation is a crucial aspect of this process, and concept art plays a vital role in visualizing and refining character designs before 3D modeling. This proposal focuses on integrating Easy Diffusion, Windows 11 tools, and Shoebox to streamline this workflow.</p>
</section>
<section id="the-problem-statement" class="level2">
<h2 class="anchored" data-anchor-id="the-problem-statement">The Problem Statement</h2>
<p>Generating high-quality, 3D-ready concept art often requires significant artistic skill and time. While AI art generators like Stable Diffusion, particularly with the FLUX model, can expedite this process, setting it up and ensuring the generated art is compatible with 3D modeling tools requires technical expertise and careful optimization. This proposal aims to simplify this process further by incorporating readily available Windows tools.</p>
</section>
<section id="describe-how-your-proposal-will-work-with-code-pseudo-code-mock-ups-or-diagrams" class="level2">
<h2 class="anchored" data-anchor-id="describe-how-your-proposal-will-work-with-code-pseudo-code-mock-ups-or-diagrams">Describe how your proposal will work with code, pseudo-code, mock-ups, or diagrams</h2>
<p>This proposal outlines a workflow using Easy Diffusion for generating concept art, Windows 11 tools for image editing, and Shoebox for sprite creation, ultimately optimizing the process for 3D character creation in V-Sekai.</p>
<section id="easy-diffusion-setup" class="level3">
<h3 class="anchored" data-anchor-id="easy-diffusion-setup">1. Easy Diffusion Setup</h3>
<p>Easy Diffusion provides a user-friendly interface for Stable Diffusion. We will use it with the FLUX model for generating character concepts.</p>
<ul>
<li>Install Easy Diffusion.</li>
<li>Use Beta</li>
<li>Use 3.5 engine</li>
<li>Download the FLUX model and necessary LoRAs (CharacterDesign-FluxV2).</li>
<li>Configure Easy Diffusion with the FLUX model and LoRAs.</li>
</ul>
<p><a href="attachments/concept_prompt.json">concept_prompt.json</a></p>
</section>
<section id="optimized-prompting-in-easy-diffusion" class="level3">
<h3 class="anchored" data-anchor-id="optimized-prompting-in-easy-diffusion">2. Optimized Prompting in Easy Diffusion</h3>
<p><strong>Settings:</strong></p>
<ul>
<li>Set the width and height to 1024 pixels.</li>
</ul>
</section>
<section id="image-editing-with-windows-11-tools" class="level3">
<h3 class="anchored" data-anchor-id="image-editing-with-windows-11-tools">3. Image Editing with Windows 11 Tools</h3>
<ul>
<li><strong>Background Removal:</strong> Utilize the built-in background removal tool in Windows 11’s Paint app to isolate the character from the generated image. This creates a transparent background, crucial for sprite creation.</li>
<li><strong>Refinement (Optional):</strong> Use other tools in Paint, like the selection tools and eraser, for further refinement if needed.</li>
</ul>
</section>
<section id="sprite-creation-with-shoebox" class="level3">
<h3 class="anchored" data-anchor-id="sprite-creation-with-shoebox">4. Sprite Creation with Shoebox</h3>
<p>Shoebox (https://renderhjs.net/shoebox/) is a free online tool for creating sprite sheets.</p>
<ul>
<li>Upload the alpha’d image from Paint to Shoebox.</li>
<li>Utilize Shoebox’s features to cut the image into individual sprites.</li>
<li>Keep only the sprites that are in different views but in the same consistent 3d shape.</li>
</ul>
</section>
<section id="trellis-setup-and-execution-optional" class="level3">
<h3 class="anchored" data-anchor-id="trellis-setup-and-execution-optional">5. TRELLIS Setup and Execution (Optional)</h3>
<p>TRELLIS can be used for generating 3D models from the concept art or sprites.</p>
<ul>
<li>Install Docker Desktop.</li>
<li>Install WSL2 with a compatible Linux distribution (e.g., Ubuntu).</li>
<li>Configure Docker Desktop to utilize the WSL2 backend.</li>
<li>Ensure GPU access is enabled within WSL2.</li>
<li>Execute TRELLIS within WSL2 using the following command in Powershell:</li>
</ul>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode powershell code-with-copy"><code class="sourceCode powershell"><span id="cb1-1">docker run <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>it <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>p <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">7860</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">7860</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">--</span>gpus all registry<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">hf</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">space</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>jeffreyxiang-trellis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>latest python app<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">py</span></span></code></pre></div>
</section>
<section id="iterative-refinement" class="level3">
<h3 class="anchored" data-anchor-id="iterative-refinement">6. Iterative Refinement</h3>
<p>The process emphasizes iterative refinement of the prompt based on results from Shoebox or TRELLIS. This cyclical process ensures the generation of optimized concept art and sprites.</p>
</section>
<section id="workflow" class="level3">
<h3 class="anchored" data-anchor-id="workflow">Workflow</h3>
<ol type="1">
<li><strong>Define Core Concept:</strong> Establish the character’s essential characteristics.</li>
<li><strong>Craft Optimized Prompt:</strong> Create a concise, descriptive prompt using Easy Diffusion.</li>
<li><strong>Generate and Evaluate:</strong> Produce images and assess their suitability.</li>
<li><strong>Remove Background:</strong> Use Windows 11’s Paint app to remove the background.</li>
<li><strong>Create Sprites:</strong> Utilize Shoebox to generate sprites from the alpha’d image.</li>
<li><strong>(Optional) 3D Conversion:</strong> Utilize TRELLIS to generate 3D models.</li>
<li><strong>Iterate and Refine:</strong> Adjust the prompt based on the evaluation.</li>
</ol>
</section>
</section>
<section id="the-benefits" class="level2">
<h2 class="anchored" data-anchor-id="the-benefits">The Benefits</h2>
<ul>
<li><strong>Simplified Workflow:</strong> Streamlines concept art and sprite creation using accessible tools.</li>
<li><strong>Reduced Manual Effort:</strong> Minimizes image editing and sprite creation time.</li>
<li><strong>Faster Iteration:</strong> Accelerates character design exploration.</li>
<li><strong>Standardized Output:</strong> Maintains consistency in character presentation.</li>
<li><strong>Accessibility:</strong> Empowers users with varying artistic skills to contribute.</li>
<li><strong>Cost-effective:</strong> Leverages free tools readily available on Windows 11.</li>
</ul>
</section>
<section id="the-downsides" class="level2">
<h2 class="anchored" data-anchor-id="the-downsides">The Downsides</h2>
<ul>
<li><strong>FLUX.1 Style:</strong> Inherits the distinctive style of the FLUX.1 model.</li>
<li><strong>Shoebox Limitations:</strong> May require manual adjustments for complex sprites.</li>
<li><strong>TRELLIS Limitations (Optional):</strong> Complex elements may still require manual 3D refinement.</li>
<li><strong>WSL2 Setup (Optional):</strong> Requires users to install and configure WSL2 for TRELLIS.</li>
</ul>
</section>
<section id="the-road-not-taken" class="level2">
<h2 class="anchored" data-anchor-id="the-road-not-taken">The Road Not Taken</h2>
<ul>
<li><strong>Manual creation of concept art:</strong> Offers greater control but is time-consuming.</li>
<li><strong>Using alternative AI models:</strong> Other models may not be as compatible with TRELLIS or as user-friendly.</li>
<li><strong>Dedicated Sprite Editors:</strong> Can be more powerful but less accessible than Shoebox.</li>
</ul>
</section>
<section id="the-infrequent-use-case" class="level2">
<h2 class="anchored" data-anchor-id="the-infrequent-use-case">The Infrequent Use Case</h2>
<p>For highly specific or complex concept art and sprites, manual creation or a combination of AI generation and human artistry may be necessary. Users without dedicated GPUs might experience limitations with TRELLIS.</p>
</section>
<section id="why-is-it-in-core-and-done-by-us" class="level2">
<h2 class="anchored" data-anchor-id="why-is-it-in-core-and-done-by-us">Why is it in Core and done by us?</h2>
<p>This aligns with V-Sekai’s goal of democratizing virtual world creation by streamlining character creation and empowering users with accessible tools.</p>
</section>
<section id="status" class="level2">
<h2 class="anchored" data-anchor-id="status">Status</h2>
<p>Status: Draft</p>
</section>
<section id="decision-makers" class="level2">
<h2 class="anchored" data-anchor-id="decision-makers">Decision Makers</h2>
<ul>
<li>V-Sekai development team</li>
<li>fire</li>
</ul>
</section>
<section id="tags" class="level2">
<h2 class="anchored" data-anchor-id="tags">Tags</h2>
<ul>
<li>V-Sekai</li>
<li>AI Art Generation</li>
<li>Character Design</li>
<li>FLUX.1</li>
<li>TRELLIS</li>
<li>Easy Diffusion</li>
<li>3D Modeling</li>
<li>Windows 11</li>
<li>Shoebox</li>
<li>Sprite Creation</li>
</ul>
</section>
<section id="further-reading" class="level2">
<h2 class="anchored" data-anchor-id="further-reading">Further Reading</h2>
<ol type="1">
<li><a href="https://github.com/v-sekai">V-Sekai · GitHub</a></li>
<li><a href="https://github.com/v-sekai/v-sekai-game">V-Sekai/v-sekai-game</a></li>
<li><a href="https://civitai.com/models/618692?modelVersionId=699279">flux.1 schnell - Civitai</a></li>
<li><a href="https://huggingface.co/spaces/JeffreyXiang/TRELLIS">TRELLIS - Hugging Face</a></li>
<li><a href="https://civitai.com/models/100435">Character Design Sheet Helper - Civitai</a></li>
<li><a href="https://github.com/V-Sekai-fire/TOOL_logoscale/tree/main?tab=readme-ov-file">TOOL_logoscale - GitHub</a></li>
<li><a href="https://easydiffusion.github.io/">Easy Diffusion</a></li>
<li><a href="https://docs.microsoft.com/en-us/windows/wsl/">Windows Subsystem for Linux Documentation</a></li>
<li><a href="https://renderhjs.net/shoebox/">Shoebox</a></li>
<li><a href="https://github.com/pinokiofactory/clarity-refiners-ui">clarity-refiners-ui</a></li>
</ol>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20241220-character-concept-art-creation.html</guid>
  <pubDate>Mon, 23 Dec 2024 05:33:45 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20241219-unpack-fbx-udimms.html</link>
  <description><![CDATA[ 




<section id="draft-use-fbx-udimms-with-fbx-udim-unpacker-in-godot-engine" class="level1">
<h1>Draft: Use FBX UDIMMs with FBX UDIM Unpacker in Godot Engine</h1>
<section id="the-context" class="level2">
<h2 class="anchored" data-anchor-id="the-context">The Context</h2>
<p>The increasing need for higher texture resolution on 3D models often necessitates the use of multiple textures, a technique known as UDIMs. This approach, originating from the VFX industry, allows for a single material to utilize multiple texture “tiles” at varying resolutions, providing greater detail and flexibility.</p>
</section>
<section id="the-problem-statement" class="level2">
<h2 class="anchored" data-anchor-id="the-problem-statement">The Problem Statement</h2>
<p>Currently, Godot Engine lacks native support for UDIMs, hindering efficient workflows for artists who require high-resolution textures. This limitation forces developers to split materials during modeling or employ workarounds that can be cumbersome and time-consuming.</p>
</section>
<section id="describe-how-your-proposal-will-work-with-code-pseudo-code-mock-ups-or-diagrams" class="level2">
<h2 class="anchored" data-anchor-id="describe-how-your-proposal-will-work-with-code-pseudo-code-mock-ups-or-diagrams">Describe how your proposal will work with code, pseudo-code, mock-ups, or diagrams</h2>
<p>This proposal suggests implementing a dedicated UDIM importer and integration within Godot’s material system. The importer would process FBX files containing UDIM information, correctly assigning texture tiles to the corresponding UV coordinates. This would streamline the workflow for artists, enabling them to import and utilize high-resolution textured models seamlessly.</p>
<blockquote class="blockquote">
<p>This tool takes an input FBX file that uses UDIMs by having UVs that are outside the 0-1 range. For example, if a polygon’s UVs are in the range (1-2, 0-1), it’s the UDIM tile 1002 (conceptually one to the right of the main UV space), wheras UVs in the range (0-1, 0-1) are UDIM tile 1001.</p>
<p>Any polygon UVs which reference UDIM tiles outside 1001 trigger the splitting of the material “Foo” into “Foo_U1001”, “Foo_U1002”, “Foo_U1010” and so on based on the UDIM tile. Polys are then changed to reference the material corresponding to their UDIM tile, and the UVs are adjusted back to the 0-1 range.</p>
<p>The tool then writes the result to another FBX file. If you import that FBX into a 3D engine, it will have extra materials from the original, depending on how many UDIM tiles were used. You can then hook up materials to the correct UDIM texture tiles, one per texture, and use the model like normal.</p>
<p>https://github.com/V-Sekai/fbx-udim-unpack?tab=readme-ov-file#what-this-tool-does from https://github.com/sinbad</p>
</blockquote>
</section>
<section id="the-benefits" class="level2">
<h2 class="anchored" data-anchor-id="the-benefits">The Benefits</h2>
<p>Implementing UDIM support offers several advantages:</p>
<ul>
<li><strong>Improved Artist Workflow:</strong> Streamlines the process of importing and working with high-resolution models.</li>
<li><strong>Enhanced Visual Fidelity:</strong> Allows for greater detail and realism in 3D assets.</li>
<li><strong>Industry Standard Compatibility:</strong> Aligns Godot with industry-standard practices in texture management.</li>
</ul>
</section>
<section id="the-downsides" class="level2">
<h2 class="anchored" data-anchor-id="the-downsides">The Downsides</h2>
<ul>
<li><strong>Development Time and Resources:</strong> Requires dedicated effort to implement and integrate UDIM support.</li>
<li><strong>Potential Performance Impact:</strong> May introduce minor performance overhead depending on the implementation.</li>
</ul>
</section>
<section id="the-road-not-taken" class="level2">
<h2 class="anchored" data-anchor-id="the-road-not-taken">The Road Not Taken</h2>
<p>Alternative solutions, such as manual texture assignment or third-party plugins, were considered less efficient and maintainable compared to native UDIM support.</p>
</section>
<section id="the-infrequent-use-case" class="level2">
<h2 class="anchored" data-anchor-id="the-infrequent-use-case">The Infrequent Use Case</h2>
<p>While UDIMs are becoming increasingly common, simpler projects with lower texture resolution requirements may not necessitate this feature.</p>
</section>
<section id="why-is-it-in-core-and-done-by-us" class="level2">
<h2 class="anchored" data-anchor-id="why-is-it-in-core-and-done-by-us">Why is it in Core and done by us?</h2>
<p>Native UDIM support aligns with Godot’s goal of providing a comprehensive and artist-friendly game development environment. Implementing this feature within the core engine ensures its availability and maintainability for all users.</p>
</section>
<section id="status" class="level2">
<h2 class="anchored" data-anchor-id="status">Status</h2>
<p>Status: Draft</p>
</section>
<section id="decision-makers" class="level2">
<h2 class="anchored" data-anchor-id="decision-makers">Decision Makers</h2>
<ul>
<li>V-Sekai development team</li>
<li>Godot Engine developers</li>
</ul>
</section>
<section id="tags" class="level2">
<h2 class="anchored" data-anchor-id="tags">Tags</h2>
<ul>
<li>V-Sekai</li>
<li>Godot Engine</li>
<li>UDIM</li>
<li>Texturing</li>
</ul>
</section>
<section id="further-reading" class="level2">
<h2 class="anchored" data-anchor-id="further-reading">Further Reading</h2>
<ol type="1">
<li><a href="https://github.com/v-sekai">V-Sekai · GitHub</a> - Official GitHub account for the V-Sekai development community focusing on social VR functionality for the Godot Engine.</li>
<li><a href="https://github.com/v-sekai/v-sekai-game">V-Sekai/v-sekai-game</a> is the GitHub page for the V-Sekai open-source project, which brings social VR/VRSNS/metaverse components to the Godot Engine.</li>
<li><a href="https://github.com/V-Sekai/fbx-udim-unpack">V-Sekai/fbx-udim-unpack</a></li>
<li><a href="https://blendermarket.com/products/better-fbx-importer--exporter">better-fbx-importer–exporter</a></li>
</ol>
<p>AI assistant Aria assisted with this article.</p>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20241219-unpack-fbx-udimms.html</guid>
  <pubDate>Mon, 23 Dec 2024 05:33:45 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20241219-scriptable-sign.html</link>
  <description><![CDATA[ 




<section id="draft-scriptable-interactive-signs-in-v-sekai" class="level1">
<h1>Draft: Scriptable Interactive Signs in V-Sekai</h1>
<section id="the-context" class="level2">
<h2 class="anchored" data-anchor-id="the-context">The Context</h2>
<p>V-Sekai is a social VR platform designed to foster user interaction and creative expression within a shared virtual world. Effective communication tools and user-generated content are essential to this goal.</p>
</section>
<section id="the-problem-statement" class="level2">
<h2 class="anchored" data-anchor-id="the-problem-statement">The Problem Statement</h2>
<p>Currently, V-Sekai offers limited options for users to leave persistent messages or communicate asynchronously within the environment. This proposal introduces interactive signs as a new, scriptable communication feature, leveraging the existing Godot-sandbox.</p>
</section>
<section id="describe-how-your-proposal-will-work-with-code-pseudo-code-mock-ups-or-diagrams" class="level2">
<h2 class="anchored" data-anchor-id="describe-how-your-proposal-will-work-with-code-pseudo-code-mock-ups-or-diagrams">Describe how your proposal will work with code, pseudo-code, mock-ups, or diagrams</h2>
<section id="sign-creation-as-scriptable-objects" class="level3">
<h3 class="anchored" data-anchor-id="sign-creation-as-scriptable-objects">Sign Creation as Scriptable Objects</h3>
<ul>
<li>Users will have access to a simplified scripting environment within the Godot-sandbox to create and customize signs.</li>
<li>They can define the sign’s appearance (text, emojis, images), interaction logic (like buttons, animations), and integrate with other game elements.</li>
<li>Pre-built templates and scripting examples will be provided for less experienced users.</li>
</ul>
</section>
<section id="sign-placement-with-in-world-editor" class="level3">
<h3 class="anchored" data-anchor-id="sign-placement-with-in-world-editor">Sign Placement with In-World Editor</h3>
<ul>
<li>Users can place and manipulate signs directly in the V-Sekai world using an in-world editor tool, leveraging existing Godot editor functionalities.</li>
</ul>
</section>
<section id="like-system-integration-with-godot-scripting" class="level3">
<h3 class="anchored" data-anchor-id="like-system-integration-with-godot-scripting">“Like” System Integration with Godot Scripting</h3>
<ul>
<li>The “like” functionality will be exposed through Godot scripting, allowing users to customize its behavior, create unique animations and sounds, or integrate the “like” count with other game mechanics.</li>
</ul>
</section>
<section id="user-interface-integration-with-godot-signals" class="level3">
<h3 class="anchored" data-anchor-id="user-interface-integration-with-godot-signals">User Interface Integration with Godot Signals</h3>
<ul>
<li>We will connect sign interactions with the user interface, enabling dynamic updates of “like” counts and other relevant information in the user’s HUD or profile.</li>
</ul>
</section>
</section>
<section id="the-benefits" class="level2">
<h2 class="anchored" data-anchor-id="the-benefits">The Benefits</h2>
<ul>
<li><strong>Enhanced Communication:</strong> Scriptable signs provide a flexible channel for asynchronous communication, allowing users to leave messages, share thoughts, or provide information in engaging ways.</li>
<li><strong>Increased Social Interaction:</strong> The customizable “like” system encourages interaction and feedback between users, fostering a sense of community.</li>
<li><strong>Creative Expression and User-Generated Content:</strong> Empowers users to personalize the V-Sekai world and express themselves creatively by designing unique sign experiences.</li>
<li><strong>Deeper Integration with V-Sekai:</strong> Leverages existing Godot infrastructure for a more cohesive and extensible implementation.</li>
<li><strong>Potential for Community-Driven Development:</strong> Users can share and collaborate on sign scripts, fostering a vibrant ecosystem of user-generated content.</li>
</ul>
</section>
<section id="the-downsides" class="level2">
<h2 class="anchored" data-anchor-id="the-downsides">The Downsides</h2>
<ul>
<li><strong>Learning Curve:</strong> May require users to have some familiarity with Godot scripting or be willing to learn. <strong>Mitigation:</strong> Provide comprehensive tutorials and readily available examples.</li>
<li><strong>Security and Stability:</strong> Robust security measures are crucial to prevent malicious scripts from affecting the V-Sekai environment. <strong>Mitigation:</strong> Implement a script review process and sandboxing mechanisms.</li>
<li><strong>Performance Impact:</strong> Careful optimization of user-created scripts will be essential to maintain overall performance. <strong>Mitigation:</strong> Provide clear guidelines and limitations on script complexity.</li>
</ul>
</section>
<section id="the-road-not-taken" class="level2">
<h2 class="anchored" data-anchor-id="the-road-not-taken">The Road Not Taken</h2>
<p>Simple, non-scriptable signs with a fixed set of features were considered. However, leveraging the Godot-sandbox for scriptable signs offers greater flexibility, user empowerment, and potential for community-driven content creation, aligning better with V-Sekai’s open-source philosophy.</p>
</section>
<section id="in-core-and-done-by-us" class="level2">
<h2 class="anchored" data-anchor-id="in-core-and-done-by-us">In Core and Done by Us</h2>
<p>This feature directly supports V-Sekai’s core values of social interaction, user-generated content, and community involvement. The V-Sekai development team is best suited to implement this functionality, ensuring seamless integration with the existing platform and maintaining a consistent user experience.</p>
</section>
<section id="status" class="level2">
<h2 class="anchored" data-anchor-id="status">Status</h2>
<p>Status: Draft</p>
</section>
<section id="decision-makers" class="level2">
<h2 class="anchored" data-anchor-id="decision-makers">Decision Makers</h2>
<ul>
<li>V-Sekai development team</li>
<li>fire</li>
<li>Transplanar-Ecological-Society</li>
</ul>
</section>
<section id="tags" class="level2">
<h2 class="anchored" data-anchor-id="tags">Tags</h2>
<ul>
<li>V-Sekai, Communication, User-Generated Content, Social Interaction, Signs, Godot, Scripting</li>
</ul>
</section>
<section id="further-reading" class="level2">
<h2 class="anchored" data-anchor-id="further-reading">Further Reading</h2>
<ol type="1">
<li><a href="https://github.com/v-sekai">V-Sekai · GitHub</a> - Official GitHub account for the V-Sekai development community focusing on social VR functionality for the Godot Engine.</li>
<li><a href="https://github.com/v-sekai/v-sekai-game">V-Sekai/v-sekai-game</a> is the GitHub page for the V-Sekai open-source project, which brings social VR/VRSNS/metaverse components to the Godot Engine.</li>
<li><a href="https://docs.godotengine.org/">Godot Engine Documentation</a> - Official documentation for the Godot Engine, including scripting and GDScript.</li>
</ol>
<p>AI assistant Aria assisted with this article.</p>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20241219-scriptable-sign.html</guid>
  <pubDate>Mon, 23 Dec 2024 05:33:45 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20241218-will-o-wisp-proto-avatar.html</link>
  <description><![CDATA[ 




<section id="draft-will-o-wisp-proto-avatar" class="level1">
<h1>Draft: Will-o-Wisp Proto-Avatar</h1>
<section id="the-context" class="level2">
<h2 class="anchored" data-anchor-id="the-context">The Context</h2>
<p>We need a captivating and engaging starting experience for new users in V-Sekai. This experience should introduce core mechanics in a fun way and hint at the possibilities of avatar creation and interaction.</p>
</section>
<section id="the-problem-statement" class="level2">
<h2 class="anchored" data-anchor-id="the-problem-statement">The Problem Statement</h2>
<p>New users need an engaging onboarding experience that seamlessly introduces them to V-Sekai’s social VR environment and avatar customization.</p>
</section>
<section id="describe-how-your-proposal-will-work-with-code-pseudo-code-mock-ups-or-diagrams" class="level2">
<h2 class="anchored" data-anchor-id="describe-how-your-proposal-will-work-with-code-pseudo-code-mock-ups-or-diagrams">Describe how your proposal will work with code, pseudo-code, mock-ups, or diagrams</h2>
<p>Phase 1: Will-o-Wisp Enhancement</p>
<p>New users will join the wider community as a will-o-wisp. This provides an immediate sense of community and introduces basic movement controls in a 3D space.</p>
<ul>
<li>Interactive Elements: Introduce a will-o-wisp body that reacts to user inputs such as movement, voice audio, and animation gestures. For example:
<ul>
<li>The will-o-wisp could change color or emit light patterns based on the user’s face visemes, voice pitch and volume.</li>
<li>Perform specific animations in response to gestures.</li>
</ul></li>
<li>Voice Chat: Enable voice chat to facilitate communication and interaction among new users (code implementation with audio integration).</li>
</ul>
<p>Phase 2: Avatar Emergence</p>
<p>The will-o-wisp experience gradually transitions towards avatar customization and personalization.</p>
<ul>
<li>Proto-Avatar Customization: Introduce basic shape variations for the will-o-wisps (code implementation with visual mock-ups).</li>
<li>Chrysalis Chamber: Create a dedicated space where users can experiment with proto-avatar customizations and preview future avatar options (level design and UI/UX design).</li>
</ul>
</section>
<section id="the-benefits" class="level2">
<h2 class="anchored" data-anchor-id="the-benefits">The Benefits</h2>
<ul>
<li>Engaging Onboarding: Provides a fun and unique first experience.</li>
<li>Community Building: The shared will-o-wisp experience fosters a sense of belonging and encourages interaction.</li>
<li>Gradual Introduction: Eases users into the concepts of avatar customization and the larger V-Sekai world.</li>
<li>Increased Retention: A captivating initial experience can improve user retention.</li>
</ul>
</section>
<section id="the-downsides" class="level2">
<h2 class="anchored" data-anchor-id="the-downsides">The Downsides</h2>
<ul>
<li>Development Time: Implementing the proposed features will require dedicated development resources.</li>
<li>Technical Challenges: Creating a seamless and performant will-o-wisp experience may present technical hurdles.</li>
<li>User Expectations: Managing user expectations about the transition from will-o-wisps to full avatars is important.</li>
</ul>
</section>
<section id="the-road-not-taken" class="level2">
<h2 class="anchored" data-anchor-id="the-road-not-taken">The Road Not Taken</h2>
<p>We considered directly starting users with avatar creation, but this could be overwhelming. The will-o-wisp experience provides a gentler introduction to the 3D environment and social aspects of V-Sekai.</p>
</section>
<section id="the-infrequent-use-case" class="level2">
<h2 class="anchored" data-anchor-id="the-infrequent-use-case">The Infrequent Use Case</h2>
<p>Users who prefer to immediately jump into avatar creation could be provided with an option to skip the will-o-wisp experience.</p>
</section>
<section id="why-is-it-in-core-and-done-by-us" class="level2">
<h2 class="anchored" data-anchor-id="why-is-it-in-core-and-done-by-us">Why is it in Core and done by us?</h2>
<p>Onboarding is a crucial aspect of the V-Sekai experience. The core development team is best suited to implement this feature to ensure it aligns with the overall vision and technical architecture.</p>
</section>
<section id="status" class="level2">
<h2 class="anchored" data-anchor-id="status">Status</h2>
<p>Status: Draft</p>
</section>
<section id="decision-makers" class="level2">
<h2 class="anchored" data-anchor-id="decision-makers">Decision Makers</h2>
<ul>
<li>V-Sekai development team</li>
<li>fire</li>
<li>Transplanar-Ecological-Society</li>
</ul>
</section>
<section id="tags" class="level2">
<h2 class="anchored" data-anchor-id="tags">Tags</h2>
<ul>
<li>V-Sekai</li>
<li>Onboarding</li>
<li>Avatar</li>
</ul>
</section>
<section id="further-reading" class="level2">
<h2 class="anchored" data-anchor-id="further-reading">Further Reading</h2>
<ol type="1">
<li><a href="https://github.com/v-sekai">V-Sekai · GitHub</a> - Official GitHub account for the V-Sekai development community focusing on social VR functionality for the Godot Engine.</li>
<li><a href="https://github.com/v-sekai/v-sekai-game">V-Sekai/v-sekai-game</a> is the GitHub page for the V-Sekai open-source project, which brings social VR/VRSNS/metaverse components to the Godot Engine.</li>
</ol>
<p>AI assistant Aria assisted with this article.</p>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20241218-will-o-wisp-proto-avatar.html</guid>
  <pubDate>Mon, 23 Dec 2024 05:33:45 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20241210-vsekai-charter.html</link>
  <description><![CDATA[ 




<section id="draft-update-v-sekai-charter-to-2024" class="level1">
<h1>Draft: Update V-Sekai Charter to 2024</h1>
<section id="the-context" class="level2">
<h2 class="anchored" data-anchor-id="the-context">The Context</h2>
<p>The Mozilla Builders Summer MVP Lab charter was submitted on June 8, 2020. It’s now time to refresh our goals and direction.</p>
</section>
<section id="the-problem-statement" class="level2">
<h2 class="anchored" data-anchor-id="the-problem-statement">The Problem Statement</h2>
<p>Our current V-Sekai charter is outdated and needs to be revised to reflect the project’s current state and future ambitions in 2024.</p>
</section>
<section id="describe-how-your-proposal-will-work-with-code-pseudo-code-mock-ups-or-diagrams" class="level2">
<h2 class="anchored" data-anchor-id="describe-how-your-proposal-will-work-with-code-pseudo-code-mock-ups-or-diagrams">Describe how your proposal will work with code, pseudo-code, mock-ups, or diagrams</h2>
<p><strong>A one-line summary of the MVP:</strong></p>
<p>A customizable and self-hosted virtual reality environment built on Godot Engine.</p>
<p><strong>Description of the product: What will the MVP be in 8 weeks?</strong></p>
<p>Our virtual reality app will be compatible with all SteamVR-compatible PC headsets and the Meta Quest VR platform. It will feature a social hub with 3D voice chat, real-time body tracking, simple games, integrated physics, and social video viewing.</p>
<p><strong>Category:</strong></p>
<ul>
<li>Decentralized Web: YES</li>
<li>Messaging &amp; Social Networking: YES</li>
</ul>
<p><strong>Why does your idea matter? How will it help deliver on the full promise of the internet or make the internet more awesome?</strong></p>
<p>The internet thrives on openness and communication. We believe virtual reality is a powerful new medium for human connection. With the closure of platforms like High Fidelity, open-source alternatives are crucial to counter the trend of closed VR platforms.</p>
<p>VR technology is advancing rapidly. Better game engines, audio and video codecs, faster internet speeds, and more accessible VR hardware create the perfect opportunity to develop an open platform.</p>
<p>We champion individual empowerment through decentralized technology. Our goal is to build a polished and functional service that integrates decentralized authentication and encryption, along with content distribution technologies like BitTorrent and IPFS.</p>
<p><strong>Who are your users or potential users?</strong></p>
<p>Our target audience includes users of social VR experiences, online collaboration tools, and communication products. The social VR space is growing, and its potential is just beginning to be explored.</p>
<p>Despite being a relatively new technology, VR has a large potential market, particularly with the rise of affordable headsets like Meta Quest. For example, VRChat boasts between 12,000 and 15,000 concurrent users, with approximately 4,000 using VR in 2019.</p>
<p><strong>What is your connection to the service &amp; the user group you plan to reach with your product?</strong></p>
<p>We are a team of VR enthusiasts with backgrounds in visual effects, level design, and graphics.</p>
<p>In an era where remote connection is essential, VR offers a more immersive and engaging way to bring people together compared to traditional video calls. One of our team members has participated in Virtual Market 4, a growing virtual content marketplace.</p>
<p>Through other social VR platforms, we have connected with people worldwide, attended live events, and formed meaningful friendships. We aim to provide these experiences in an open and accessible environment.</p>
<p><strong>Will your team still work on this project if we do not fund it? To what extent?</strong></p>
<p>We are committed to this project and will continue development regardless of funding. However, external funding would significantly accelerate our progress and help us stay competitive with closed VR platforms that are rapidly evolving.</p>
<p><strong>Why did you pick this idea? Would you happen to have domain expertise? How do you know people need what you’re building?</strong></p>
<p>We recognize the need for an open alternative to closed VR platforms. Many current platforms are free, but there’s no guarantee they will remain that way. Our platform offers the advantages of self-hosting, private use, and modification.</p>
<p>Our team possesses expertise in backend operations and Godot Engine development, both essential for building this platform.</p>
<p><strong>Are you looking for any teammates? If so, please indicate what skills or roles you seek.</strong></p>
<p>We welcome new contributors! We have a Discord group, a GitHub repository, and an issues list where individuals can learn about the project and find ways to contribute.</p>
<p><strong>Could you describe your work plan?</strong></p>
<table class="caption-top table">
<colgroup>
<col style="width: 4%">
<col style="width: 95%">
</colgroup>
<thead>
<tr class="header">
<th>Week</th>
<th>Tasks</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Week 1</strong></td>
<td>- Maintain continuous integration of Windows SteamVR, Meta Quest, and Linux server builds. <br> - Implement basic VOIP with lipsync based on volume and integrate a spatialization library. <br> - Improve Inverse Kinematics and add non-VR support.</td>
</tr>
<tr class="even">
<td><strong>Week 2</strong></td>
<td>- Stress test the system using headless clients. <br> - Implement a crash reporting system and performance metrics. <br> - Use a basic scripting API to implement physics-based games. <br> - Begin optimizing the engine for smooth frame rates during content loading.</td>
</tr>
<tr class="odd">
<td><strong>Week 3</strong></td>
<td>- Implement networking interpolation to eliminate stuttering. <br> - Fix bugs in the Godot OpenVR plugin that cause inconsistent framerate in VR. <br> - Pre-load content to avoid stutters in the 3D environment.</td>
</tr>
<tr class="even">
<td><strong>Week 4</strong></td>
<td>- Begin work on hardcoded avatars. <br> - Recruit artists to create a default home map. <br> - Fix physics errors. <br> - Test performance on various VR hardware and optimize.</td>
</tr>
<tr class="odd">
<td><strong>Week 5-6</strong></td>
<td>- Implement an account system, Terms of Service, and Privacy Policy. <br> - Enable closed registration of users. <br> - Continue working on content and bug fixes. <br> - Integrate video playback. <br> - Focus on stress testing.</td>
</tr>
<tr class="even">
<td><strong>Week 7-8</strong></td>
<td>- Fix bugs found during testing. <br> - Monitor performance metrics and continue performance optimization.</td>
</tr>
</tbody>
</table>
<p><strong>Could you describe the team’s approach to developing the Minimum Viable Product throughout the summer? This includes, but is not limited to:</strong></p>
<p><strong>Who are your peers?</strong></p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Tier S</th>
<th>Tier A</th>
<th>Tier B</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>VRChat</td>
<td>Spatial</td>
<td>ENGAGE VR</td>
</tr>
<tr class="even">
<td>Meta Horizon Worlds</td>
<td>Mozilla Hubs</td>
<td>HTC Vive Sync</td>
</tr>
<tr class="odd">
<td>cluster</td>
<td>VirtualCast</td>
<td>Oasis VR</td>
</tr>
<tr class="even">
<td>Rec Room</td>
<td>Sansar</td>
<td>ChilloutVR</td>
</tr>
<tr class="odd">
<td>Roblox VR</td>
<td>Somnium Space</td>
<td>Lavender</td>
</tr>
<tr class="even">
<td></td>
<td>Overte</td>
<td>Resonite</td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td>Bigscreen</td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td>Anyland</td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td>VirBELA</td>
</tr>
</tbody>
</table>
<p><strong>How will you attract your first 1000 users? Your first 1,000,000?</strong></p>
<ul>
<li><strong>Initial Users:</strong> We will leverage our existing contacts within the VR community to gain our first 50 users.</li>
<li><strong>Growth:</strong> We will offer unique experiences not found on other platforms to attract more users.</li>
<li><strong>Scaling:</strong> To reach thousands of users, we will host events and emphasize privacy and self-hosting capabilities.</li>
</ul>
<p><strong>First 2-week development milestone</strong></p>
<ul>
<li>Maintain continuous integration of builds for Windows SteamVR, Meta Quest, and Linux servers.</li>
<li>Implement basic VOIP with lipsync and spatialization.</li>
<li>Improve Inverse Kinematics and add non-VR support.</li>
<li>Conduct stress testing with headless clients.</li>
<li>Implement crash reporting and performance metrics.</li>
<li>Use a scripting API to implement physics-based games.</li>
<li>Begin engine optimization for smooth frame rates during content loading.</li>
</ul>
<p><strong>Tech stack you plan to use (Cloud services, APIs, mobile platforms, languages, etc)</strong></p>
<p>Godot Engine, k3s, Elixir, OAuth, CockroachDB, Nginx, Fedora, CentOS 8, Digital Ocean Spaces, Meta Quest SDK on Android, Valve OpenVR on Windows.</p>
<p><strong>Link to simple sketches (can be as simple as paper and pencil) of your product or idea</strong></p>
<p>[Insert Link to Sketches Here]</p>
<p><strong>What challenges do you anticipate with this idea?</strong></p>
<ul>
<li><strong>Design Challenges:</strong> Most social VR applications are developed in Unity, which can present design challenges for our Godot Engine-based project.</li>
<li><strong>User Acquisition:</strong> Social platforms are heavily influenced by the network effect, making user acquisition a challenge.</li>
<li><strong>User Retention:</strong> VR applications tend to have lower user retention rates compared to traditional applications.</li>
</ul>
<p><strong>Team Member Locations by Country</strong></p>
<p>Canada, United States, United Kingdom</p>
<p><strong>Team Details</strong></p>
<ul>
<li><strong>MMMaellon:</strong> C++, Java, Python. Experience with Android and iOS frameworks. Design skills in motion graphics, VFX, and video editing. Background in mobile app development and currently pursuing a master’s in computer science.</li>
<li><strong>Saracen:</strong> C++, C, C#, Java, Python, GDScript, Android. Professional experience in mobile app development, self-taught in game mods, game engine architecture (including forks of Id Software GPL releases), contributed code to Godot Engine and other VR platforms, developed tools including Unity, Godot, and Blender plugins, and worked on reimplementing legacy game engines for modern platforms.</li>
<li><strong>Lyuma:</strong> C++, Java, Python, Javascript, C#, Android, iOS. Expertise in backend, operations, and networking. 9 years of industry experience leading a team that developed VOIP and video implementation for an iOS and Android app with hundreds of millions of users. Experience includes backend architecture, scaling, operations, networking, stats, and monitoring.</li>
<li><strong>iFire:</strong> C++. Familiar with Godot Engine and Unreal Engine. Professional game developer. Created a Blender to glTF2 pipeline for Godot Engine and coordinated an FBX pipeline. Shipped Offworld Industries’ Squad as a programmer, DevOps, and IT. Implemented an Unreal Engine touchscreen product demo using HTML5 and Blueprints.</li>
</ul>
<p><strong>Will all team members commit their full-time energy to this project during the 8 weeks of the program?</strong></p>
<ul>
<li><strong>MMMaellon:</strong> Making valuable individual contributions as needed, including a VR character movement system.</li>
<li><strong>Saracen:</strong> Will be working full-time on the core client.</li>
<li><strong>Lyuma:</strong> Will be working full-time on dev ops, operations, backend, and testing.</li>
<li><strong>iFire:</strong> Heavily involved in the Godot Engine open-source community and dedicated part-time to this MVP project.</li>
</ul>
<p><strong>How did you hear about the MVP Lab?</strong></p>
<p>We learned about the MVP Lab from Hacker News: <a href="https://news.ycombinator.com/item?id=23194178">https://news.ycombinator.com/item?id=23194178</a></p>
<p><strong>Is there anything else we should know?</strong></p>
<p>We are passionate about VR, open source, and decentralization. We are dedicated to building a valuable platform for the internet community.</p>
</section>
<section id="the-benefits" class="level2">
<h2 class="anchored" data-anchor-id="the-benefits">The Benefits</h2>
<p>Updating our V-Sekai charter to 2024 will:</p>
<ul>
<li>Ensure the project remains relevant and aligned with current technology and user needs.</li>
<li>Provide a clear roadmap and goals for the development team.</li>
<li>Attract potential investors and collaborators.</li>
<li>Increase the project’s credibility and visibility.</li>
</ul>
</section>
<section id="the-downsides" class="level2">
<h2 class="anchored" data-anchor-id="the-downsides">The Downsides</h2>
<p>Updating our V-Sekai charter to 2024 could:</p>
<ul>
<li>Potentially overcommit resources and time.</li>
<li>Introduce the risk of technological or market shifts that render parts of the charter obsolete.</li>
<li>Increase the risk of team burnout due to ambitious goals.</li>
</ul>
</section>
<section id="the-road-not-taken" class="level2">
<h2 class="anchored" data-anchor-id="the-road-not-taken">The Road Not Taken</h2>
<p>Maintaining the current charter and focusing on short-term goals could:</p>
<ul>
<li>Offer more flexibility.</li>
<li>Reduce the risk of overcommitting resources.</li>
<li>Potentially limit the project’s long-term growth and impact.</li>
</ul>
</section>
<section id="the-infrequent-use-case" class="level2">
<h2 class="anchored" data-anchor-id="the-infrequent-use-case">The Infrequent Use Case</h2>
<p>Examples of less frequent use cases for the V-Sekai platform:</p>
<ul>
<li>Virtual historical reenactments or educational tours.</li>
<li>Hosting virtual conferences or trade shows.</li>
</ul>
</section>
<section id="why-is-it-in-core-and-done-by-us" class="level2">
<h2 class="anchored" data-anchor-id="why-is-it-in-core-and-done-by-us">Why is it in Core and done by us?</h2>
<p>Updating the V-Sekai charter is core to our mission because:</p>
<ul>
<li>We are committed to developing an open-source, decentralized VR platform.</li>
<li>Our team has the necessary expertise and passion.</li>
<li>Setting long-term goals ensures project sustainability.</li>
</ul>
</section>
<section id="status" class="level2">
<h2 class="anchored" data-anchor-id="status">Status</h2>
<p><strong>Status:</strong> Draft</p>
</section>
<section id="decision-makers" class="level2">
<h2 class="anchored" data-anchor-id="decision-makers">Decision Makers</h2>
<ul>
<li>V-Sekai development team</li>
</ul>
</section>
<section id="tags" class="level2">
<h2 class="anchored" data-anchor-id="tags">Tags</h2>
<ul>
<li>V-Sekai</li>
</ul>
</section>
<section id="further-reading" class="level2">
<h2 class="anchored" data-anchor-id="further-reading">Further Reading</h2>
<ol type="1">
<li><a href="https://github.com/v-sekai">V-Sekai · GitHub</a></li>
<li><a href="https://github.com/v-sekai/v-sekai-game">V-Sekai/v-sekai-game</a></li>
</ol>
<p>AI assistant Aria assisted with this article.</p>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20241210-vsekai-charter.html</guid>
  <pubDate>Mon, 23 Dec 2024 05:33:45 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20241112-godot-animation-streaming.html</link>
  <description><![CDATA[ 




<section id="accepted-godot-animation-streaming" class="level1">
<h1>Accepted: Godot Animation streaming</h1>
<section id="the-context" class="level2">
<h2 class="anchored" data-anchor-id="the-context">The Context</h2>
<p>Animation streaming is a technique for handling extremely long animations. It involves loading only portions of the animation data as needed, which helps manage memory efficiently and ensures smooth playback without requiring the entire animation to be loaded into memory simultaneously.</p>
</section>
<section id="the-problem-statement" class="level2">
<h2 class="anchored" data-anchor-id="the-problem-statement">The Problem Statement</h2>
<p>We need a system to handle the streaming of long animations in a way that minimizes memory usage and ensures smooth playback. The system should be configurable and handle various animation lengths and complexities.</p>
</section>
<section id="describe-how-your-proposal-will-work-with-code-pseudo-code-mock-ups-or-diagrams" class="level2">
<h2 class="anchored" data-anchor-id="describe-how-your-proposal-will-work-with-code-pseudo-code-mock-ups-or-diagrams">Describe how your proposal will work with code, pseudo-code, mock-ups, or diagrams</h2>
<p>We have a resource, <code>AnimationStreamingData</code>, which, when exported, is a custom binary resource containing animation pages. Export animation compressed data to this.</p>
<p>If you have an LRU of pages in the animation resource, you can customize this in the project settings (animation page LRU). I would like to know the number of pages, time, or size. Time is best, say 3 seconds.</p>
<p>Have a particular track for streamed animations. Always load the first 3 seconds of animation (buffer size). For the rest, while playing the animation, you can use <code>WorkerThreadPool</code> to queue loading resource pages ahead of you on a thread. Always strive to have 3 seconds (again, buffer size) ahead of the playback cursor. After you are done with a page, you can free it.</p>
<p><code>AnimationStreamingData</code> should be a binary format, custom-made, with all pages saved.</p>
<p>Animation streaming must be restricted to compressed keyframe pages.</p>
<p>When opening this, you should have an index (file offset, size, and position in the timeline) that you load first from it, then stream pages as you go.</p>
<section id="animationstreamingdata-stored-on-disk-and-runtime-component" class="level3">
<h3 class="anchored" data-anchor-id="animationstreamingdata-stored-on-disk-and-runtime-component">AnimationStreamingData (Stored on Disk and Runtime Component)</h3>
<ol type="1">
<li>Exporting animation compressed data to <code>AnimationStreamingData</code>.</li>
<li>Implementing an LRU (Least Recently Used) cache for animation pages, configurable in the project settings (animation page LRU).</li>
<li>Loading the first 3 seconds of animation as a buffer.</li>
<li>Using <code>WorkerThreadPool</code> to queue loading resource pages ahead of the playback cursor.</li>
<li>Freeing pages after they are no longer needed.</li>
</ol>
<pre class="gdscript"><code>class AnimationStreamingData:
    var index = []  # Array of arrays (file_offset, size, position_in_timeline)
    var pages = {}
    var ring_buffer = RingBuffer.new()  # Custom type for ring buffer
    var usage = []  # Track usage for LRU

    func _init():
        load_index()
        var buffer_size = 16  # Example size, adjust as needed
        ring_buffer.resize(buffer_size)
        usage.resize(buffer_size)

    func load_index():
        # Load index from binary resource
        pass

    func get_page_info(page_number):
        # Retrieve page info from the index
        var page_info = index[page_number]
        return {"file_offset": page_info[0], "size": page_info[1], "position_in_timeline": page_info[2]}

    func store_page(page_number, page_data):
        # Store compressed animation page data
        pages[page_number] = page_data

    func load_page(page_number):
        # Load compressed animation page data
        return pages.get(page_number, null)

    func fetch_page(page_number):
        # Fetch page data from AnimationStreamingData
        return load_page(page_number)

    func stream_page(page_number):
        # Stream page data from RingBuffer
        if ring_buffer.data_left() &gt; 0:
            var page = ring_buffer.read()
            update_usage(page_number)
            return page
        else:
            return null

    func write_page(page_data, page_number):
        # Write page data to RingBuffer
        if ring_buffer.space_left() &lt; 1:
            # Find and replace the least recently used page
            var lru_index = find_lru()
            ring_buffer.write_pos = lru_index
        ring_buffer.write(page_data)
        update_usage(page_number)

    func update_usage(page_number):
        # Update usage list
        for i in range(usage.size()):
            usage[i] += 1
        usage[page_number] = 0

    func find_lru():
        # Find the least recently used page
        var max_usage = -1
        var lru_index = -1
        for i in range(usage.size()):
            if usage[i] &gt; max_usage:
                max_usage = usage[i]
                lru_index = i
        return lru_index</code></pre>
</section>
<section id="animationplayer" class="level3">
<h3 class="anchored" data-anchor-id="animationplayer">AnimationPlayer</h3>
<pre class="gdscript"><code>class AnimationPlayer:
    var buffer_size = 3.0 # FIXME: Calculate a better buffer size.
    var worker_pool = WorkerThreadPool.new()
    var streaming_data = AnimationStreamingData.new()

    func _init():
        streaming_data.load_index()

    func play_animation():
        # Load initial buffer
        load_initial_buffer()
        # Stream pages ahead of playback cursor
        stream_pages_ahead()

    func load_initial_buffer():
        # Load the first 3 seconds of animation into RingBuffer
        for i in range(buffer_size):
            var page_info = streaming_data.get_page_info(i)
            var page = streaming_data.fetch_page(page_info)
            if page != null:
                streaming_data.write_page(page, i)

    func stream_pages_ahead():
        # Queue loading of pages ahead of playback cursor
        worker_pool.queue_task(callable(self, "_load_next_page"))

    func _load_next_page():
        var next_page_info = streaming_data.get_page_info(buffer_size)
        var next_page = streaming_data.fetch_page(next_page_info)
        if next_page != null:
            streaming_data.write_page(next_page, buffer_size)

    func free_page(page):
        # Free page after use
        streaming_data.ring_buffer.advance_read(1)</code></pre>
</section>
</section>
<section id="the-benefits" class="level2">
<h2 class="anchored" data-anchor-id="the-benefits">The Benefits</h2>
<p>Efficient memory usage by loading only necessary animation data. This allows for the import and streaming of extremely long animations with configurable settings to suit different project needs.</p>
<ol type="1">
<li><p><strong>Character Animations</strong>: In an open-world game, characters may have complex animations such as walking, running, jumping, and interacting with the environment. Animation streaming ensures that only the necessary parts of these animations are loaded, reducing memory usage and improving performance.</p></li>
<li><p><strong>Environmental Animations</strong>: Open-world games often feature dynamic environments with animations like trees swaying, water flowing, and weather changes. Streaming these animations helps maintain a seamless experience without overloading the system.</p></li>
<li><p><strong>Cutscenes and Cinematics</strong>: Long cutscenes and cinematic sequences can be streamed to avoid loading large animation files simultaneously, ensuring smooth transitions and playback.</p></li>
<li><p><strong>NPC Interactions</strong>: Non-player characters (NPCs) in open-world games may have varied and lengthy interaction animations. Streaming these animations allows for more complex and varied NPC behaviours without compromising performance.</p></li>
</ol>
</section>
<section id="the-downsides" class="level2">
<h2 class="anchored" data-anchor-id="the-downsides">The Downsides</h2>
<ul>
<li>Increased complexity in animation handling.</li>
<li>Potential latency in loading pages if not appropriately managed.</li>
</ul>
</section>
<section id="the-road-not-taken" class="level2">
<h2 class="anchored" data-anchor-id="the-road-not-taken">The Road Not Taken</h2>
<p>An alternative approach could be to load the entire animation into memory, simplifying the implementation but resulting in high memory usage and potential performance issues for long animations.</p>
</section>
<section id="the-infrequent-use-case" class="level2">
<h2 class="anchored" data-anchor-id="the-infrequent-use-case">The Infrequent Use Case</h2>
<p>Handling extremely short animations where streaming might not be necessary.</p>
</section>
<section id="in-core-and-done-by-us" class="level2">
<h2 class="anchored" data-anchor-id="in-core-and-done-by-us">In Core and Done by Us</h2>
<p>The V-Sekai development team will implement this proposal as part of the core functionality for handling animations in the Godot Engine.</p>
</section>
<section id="status" class="level2">
<h2 class="anchored" data-anchor-id="status">Status</h2>
<p>Status: Accepted <!-- Draft | Proposed | Rejected | Accepted | Deprecated | Superseded by --></p>
</section>
<section id="decision-makers" class="level2">
<h2 class="anchored" data-anchor-id="decision-makers">Decision Makers</h2>
<ul>
<li>V-Sekai development team</li>
<li>fire</li>
<li>reduz</li>
</ul>
</section>
<section id="tags" class="level2">
<h2 class="anchored" data-anchor-id="tags">Tags</h2>
<ul>
<li>V-Sekai</li>
</ul>
</section>
<section id="further-reading" class="level2">
<h2 class="anchored" data-anchor-id="further-reading">Further Reading</h2>
<ol type="1">
<li><a href="https://github.com/v-sekai">V-Sekai · GitHub</a> - Official GitHub account for the V-Sekai development community focusing on social VR functionality for the Godot Engine.</li>
<li><a href="https://github.com/v-sekai/v-sekai-game">V-Sekai/v-sekai-game</a> is the GitHub page for the V-Sekai open-source project, which brings social VR/VRSNS/metaverse components to the Godot Engine.</li>
</ol>
<p>AI assistant Aria assisted with this article.</p>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20241112-godot-animation-streaming.html</guid>
  <pubDate>Mon, 23 Dec 2024 05:33:45 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20241102-plan-november-2024.html</link>
  <description><![CDATA[ 




<section id="draft-plan-november-2024." class="level1">
<h1>Draft: Plan November 2024.</h1>
<section id="the-context" class="level2">
<h2 class="anchored" data-anchor-id="the-context">The Context</h2>
</section>
<section id="the-problem-statement" class="level2">
<h2 class="anchored" data-anchor-id="the-problem-statement">The Problem Statement</h2>
</section>
<section id="describe-how-your-proposal-will-work-with-code-pseudo-code-mock-ups-or-diagrams" class="level2">
<h2 class="anchored" data-anchor-id="describe-how-your-proposal-will-work-with-code-pseudo-code-mock-ups-or-diagrams">Describe how your proposal will work with code, pseudo-code, mock-ups, or diagrams</h2>
<pre class="mermaid"><code>graph TD
    Z[Restore Backend Server]
    A[Restore old V-Sekai]
    F[Recruit Artist for Default Home Map]
    H[Integration of Video Playback &amp; Streaming]

    Z --&gt; A
    A --&gt; Z
    A --&gt; F
    A --&gt; H</code></pre>
</section>
<section id="the-benefits" class="level2">
<h2 class="anchored" data-anchor-id="the-benefits">The Benefits</h2>
</section>
<section id="the-downsides" class="level2">
<h2 class="anchored" data-anchor-id="the-downsides">The Downsides</h2>
</section>
<section id="the-road-not-taken" class="level2">
<h2 class="anchored" data-anchor-id="the-road-not-taken">The Road Not Taken</h2>
</section>
<section id="the-infrequent-use-case" class="level2">
<h2 class="anchored" data-anchor-id="the-infrequent-use-case">The Infrequent Use Case</h2>
</section>
<section id="in-core-and-done-by-us" class="level2">
<h2 class="anchored" data-anchor-id="in-core-and-done-by-us">In Core and Done by Us</h2>
</section>
<section id="status" class="level2">
<h2 class="anchored" data-anchor-id="status">Status</h2>
<p>Status: Draft <!-- Draft | Proposed | Rejected | Accepted | Deprecated | Superseded by --></p>
</section>
<section id="decision-makers" class="level2">
<h2 class="anchored" data-anchor-id="decision-makers">Decision Makers</h2>
<ul>
<li>V-Sekai development team</li>
</ul>
</section>
<section id="tags" class="level2">
<h2 class="anchored" data-anchor-id="tags">Tags</h2>
<ul>
<li>V-Sekai</li>
</ul>
</section>
<section id="further-reading" class="level2">
<h2 class="anchored" data-anchor-id="further-reading">Further Reading</h2>
<ol type="1">
<li><a href="https://github.com/v-sekai">V-Sekai · GitHub</a> - Official GitHub account for the V-Sekai development community focusing on social VR functionality for the Godot Engine.</li>
<li><a href="https://github.com/v-sekai/v-sekai-game">V-Sekai/v-sekai-game</a> is the GitHub page for the V-Sekai open-source project, which brings social VR/VRSNS/metaverse components to the Godot Engine.</li>
</ol>
<p>AI assistant Aria assisted with this article.</p>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20241102-plan-november-2024.html</guid>
  <pubDate>Mon, 23 Dec 2024 05:33:45 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20241028-use-data-tables-for-godot-constraints.html</link>
  <description><![CDATA[ 




<section id="proposal-use-data-tables-for-godot-constraints" class="level1">
<h1>Proposal: Use Data Tables for Godot Constraints</h1>
<section id="the-context" class="level2">
<h2 class="anchored" data-anchor-id="the-context">The Context</h2>
<p>In the development of VR applications using the Godot Engine, managing complex interactions and constraints can become cumbersome and error-prone when handled purely through code.</p>
</section>
<section id="the-problem-statement" class="level2">
<h2 class="anchored" data-anchor-id="the-problem-statement">The Problem Statement</h2>
<p>Currently, developers must manually code each constraint and interaction within the Godot Engine, which is time-consuming and increases the risk of errors. This approach lacks scalability and efficiency, particularly in large-scale VR projects like those developed by V-Sekai.</p>
</section>
<section id="describe-how-your-proposal-will-work-with-code-pseudo-code-mock-ups-or-diagrams" class="level2">
<h2 class="anchored" data-anchor-id="describe-how-your-proposal-will-work-with-code-pseudo-code-mock-ups-or-diagrams">Describe how your proposal will work with code, pseudo-code, mock-ups, or diagrams</h2>
<p>The proposal involves integrating a data table system within the Godot Engine to manage constraints. Here’s a basic example of how it might look in pseudo-code:</p>
</section>
<section id="the-benefits" class="level2">
<h2 class="anchored" data-anchor-id="the-benefits">The Benefits</h2>
<ul>
<li><strong>Scalability</strong>: Easier to manage large numbers of constraints.</li>
<li><strong>Efficiency</strong>: Reduces development time by allowing non-programmers to adjust constraints.</li>
<li><strong>Error Reduction</strong>: Minimizes coding errors associated with manual constraint setup.</li>
</ul>
</section>
<section id="the-downsides" class="level2">
<h2 class="anchored" data-anchor-id="the-downsides">The Downsides</h2>
<ul>
<li><strong>Complexity in Setup</strong>: Initial setup of data tables and integration into the Godot project might be complex.</li>
<li><strong>Performance Concerns</strong>: Reading from data tables at runtime could impact performance if not properly optimized.</li>
</ul>
</section>
<section id="the-road-not-taken" class="level2">
<h2 class="anchored" data-anchor-id="the-road-not-taken">The Road Not Taken</h2>
<p>An alternative could have been to develop a visual editor for constraints within Godot, but this would require significantly more development resources and may not offer the same flexibility as a data-driven approach.</p>
</section>
<section id="the-infrequent-use-case" class="level2">
<h2 class="anchored" data-anchor-id="the-infrequent-use-case">The Infrequent Use Case</h2>
<p>For projects where constraints are minimal or highly static, this system might introduce unnecessary complexity and overhead.</p>
</section>
<section id="in-core-and-done-by-us" class="level2">
<h2 class="anchored" data-anchor-id="in-core-and-done-by-us">In Core and Done by Us</h2>
<p>This feature should be developed and maintained by the core V-Sekai team to ensure it aligns with the overall architecture and performance standards of the engine.</p>
</section>
<section id="status" class="level2">
<h2 class="anchored" data-anchor-id="status">Status</h2>
<p>Status: Draft <!-- Draft | Proposed | Rejected | Accepted | Deprecated | Superseded by --></p>
</section>
<section id="decision-makers" class="level2">
<h2 class="anchored" data-anchor-id="decision-makers">Decision Makers</h2>
<ul>
<li>V-Sekai development team</li>
</ul>
</section>
<section id="tags" class="level2">
<h2 class="anchored" data-anchor-id="tags">Tags</h2>
<ul>
<li>V-Sekai</li>
</ul>
</section>
<section id="further-reading" class="level2">
<h2 class="anchored" data-anchor-id="further-reading">Further Reading</h2>
<ol type="1">
<li><a href="https://github.com/v-sekai">V-Sekai · GitHub</a> - Official GitHub account for the V-Sekai development community focusing on social VR functionality for the Godot Engine.</li>
<li><a href="https://github.com/v-sekai/v-sekai-game">V-Sekai/v-sekai-game</a> is the GitHub page for the V-Sekai open-source project, which brings social VR/VRSNS/metaverse components to the Godot Engine.</li>
</ol>
<p>AI assistant Aria assisted with this article.</p>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20241028-use-data-tables-for-godot-constraints.html</guid>
  <pubDate>Mon, 23 Dec 2024 05:33:45 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20241019-reduce-size-difference-between-capsules-and-mesh-volume.html</link>
  <description><![CDATA[ 




<section id="draft-reduce-size-difference-between-capsules-and-mesh-volume" class="level1">
<h1>Draft: Reduce Size Difference Between Capsules and Mesh Volume</h1>
<section id="the-context" class="level2">
<h2 class="anchored" data-anchor-id="the-context">The Context</h2>
<p>Accurately fit capsules around bones in skinned skeleton meshes. The example provided involves a rectangle skinned by two bones, with each vertex influenced by up to 8 weights.</p>
</section>
<section id="the-problem-statement" class="level2">
<h2 class="anchored" data-anchor-id="the-problem-statement">The Problem Statement</h2>
<p>The goal is to minimize the size discrepancies between the capsules surrounding the bones and the actual volume defined by the skin mesh. This will be approached using the Minimum Deviation Flow problem in bidirected graphs (Bi-MDF).</p>
</section>
<section id="describe-how-your-proposal-will-work-with-code-pseudo-code-mock-ups-or-diagrams" class="level2">
<h2 class="anchored" data-anchor-id="describe-how-your-proposal-will-work-with-code-pseudo-code-mock-ups-or-diagrams">Describe how your proposal will work with code, pseudo-code, mock-ups, or diagrams</h2>
<section id="step-1-representation-of-the-skeleton-and-skin-mesh" class="level3">
<h3 class="anchored" data-anchor-id="step-1-representation-of-the-skeleton-and-skin-mesh">Step 1: Representation of the Skeleton and Skin Mesh</h3>
<ul>
<li><strong>Skeleton</strong>: Represent each bone as a node in a graph.</li>
<li><strong>Skin Mesh</strong>: Each vertex of the mesh is also a node. Connect a bone to a vertex with an edge if the vertex is influenced by that bone, based on skin weights.</li>
</ul>
</section>
<section id="step-2-define-the-objective" class="level3">
<h3 class="anchored" data-anchor-id="step-2-define-the-objective">Step 2: Define the Objective</h3>
<ul>
<li>The objective is to minimize the size differences between the capsules (nodes) and the volume of the skin mesh. This is quantified using a cost function that measures the deviation from ideal capsule sizes.</li>
</ul>
</section>
<section id="implementation" class="level3">
<h3 class="anchored" data-anchor-id="implementation">Implementation</h3>
<p>I have no idea.</p>
</section>
</section>
<section id="the-benefits" class="level2">
<h2 class="anchored" data-anchor-id="the-benefits">The Benefits</h2>
<ul>
<li><strong>Accuracy</strong>: Improves the fit of capsules to the actual mesh, enhancing animation quality.</li>
<li><strong>Efficiency</strong>: Reduces computational overhead by focusing on significant discrepancies.</li>
</ul>
</section>
<section id="the-downsides" class="level2">
<h2 class="anchored" data-anchor-id="the-downsides">The Downsides</h2>
<ul>
<li><strong>Complexity</strong>: Implementing and tuning the Bi-MDF algorithm can be complex.</li>
<li><strong>Dependency</strong>: Relies heavily on accurate weight assignments and initial conditions.</li>
</ul>
</section>
<section id="the-road-not-taken" class="level2">
<h2 class="anchored" data-anchor-id="the-road-not-taken">The Road Not Taken</h2>
<ul>
<li>Alternative methods such as direct geometric fitting or machine learning approaches were considered but not pursued due to their complexity and computational requirements.</li>
</ul>
</section>
<section id="the-infrequent-use-case" class="level2">
<h2 class="anchored" data-anchor-id="the-infrequent-use-case">The Infrequent Use Case</h2>
<ul>
<li>Handling cases where bones have minimal influence on any vertices, which might lead to underutilized algorithms and resources.</li>
</ul>
</section>
<section id="in-core-and-done-by-us" class="level2">
<h2 class="anchored" data-anchor-id="in-core-and-done-by-us">In Core and Done by Us</h2>
<ul>
<li>The development and integration of this feature are handled internally by the V-Sekai development team, ensuring it aligns with the core functionalities of the Godot Engine used for VR.</li>
</ul>
</section>
<section id="status" class="level2">
<h2 class="anchored" data-anchor-id="status">Status</h2>
<p>Status: Draft <!-- Draft | Proposed | Rejected | Accepted | Deprecated | Superseded by --></p>
</section>
<section id="decision-makers" class="level2">
<h2 class="anchored" data-anchor-id="decision-makers">Decision Makers</h2>
<ul>
<li>V-Sekai development team</li>
</ul>
</section>
<section id="tags" class="level2">
<h2 class="anchored" data-anchor-id="tags">Tags</h2>
<ul>
<li>V-Sekai</li>
</ul>
</section>
<section id="further-reading" class="level2">
<h2 class="anchored" data-anchor-id="further-reading">Further Reading</h2>
<ol type="1">
<li><a href="https://github.com/v-sekai">V-Sekai · GitHub</a> - Official GitHub account for the V-Sekai development community focusing on social VR functionality for the Godot Engine.</li>
<li><a href="https://github.com/v-sekai/v-sekai-game">V-Sekai/v-sekai-game</a> is the GitHub page for the V-Sekai open-source project, which brings social VR/VRSNS/metaverse components to the Godot Engine.</li>
<li><a href="https://github.com/V-Sekai-fire/libsatsuma">cgg-bern/libSatsuma</a> Exact and approximate solvers for minimum-cost-flow problems in bi-directed graphs.</li>
</ol>
<p>AI assistant Aria assisted with this article.</p>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20241019-reduce-size-difference-between-capsules-and-mesh-volume.html</guid>
  <pubDate>Mon, 23 Dec 2024 05:33:45 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20241016-instantiating-v-sekai-content.html</link>
  <description><![CDATA[ 




<section id="draft-evaluate-three-proposals-for-v-sekai-content-distribution" class="level1">
<h1>Draft: Evaluate three proposals for V-Sekai content distribution</h1>
<section id="the-context" class="level2">
<h2 class="anchored" data-anchor-id="the-context">The Context</h2>
<p>Address security concerns with V-Sekai content distribution like including the sandbox API surface, file size management, resource loading, and packed scene instantiation.</p>
</section>
<section id="the-problem-statement" class="level2">
<h2 class="anchored" data-anchor-id="the-problem-statement">The Problem Statement</h2>
<p>We aim to safely initialize an avatar body from the V-Sekai content distribution network into the virtual world without compromising security or performance.</p>
<p>We wish to enable Godot to load older content seamlessly.</p>
<p>We want to avoid animations causing security issues.</p>
</section>
<section id="describe-how-your-proposal-will-work-with-code-pseudo-code-mock-ups-or-diagrams" class="level2">
<h2 class="anchored" data-anchor-id="describe-how-your-proposal-will-work-with-code-pseudo-code-mock-ups-or-diagrams">Describe how your proposal will work with code, pseudo-code, mock-ups, or diagrams</h2>
<section id="option-1-instantiate-and-validate-binary-packedscene" class="level3">
<h3 class="anchored" data-anchor-id="option-1-instantiate-and-validate-binary-packedscene">Option 1: Instantiate and Validate binary PackedScene</h3>
<p>This method involves loading chunks of an average packed scene from the web, instantiating it in the sandbox, and applying runtime verification. This approach prevents double initializer security concerns and avoids using double the memory to copy PackedScene.</p>
<section id="double-initializer-security-concern" class="level4">
<h4 class="anchored" data-anchor-id="double-initializer-security-concern">Double initializer security concern</h4>
<p>Different content initializers becomes a security problem as code drifts and fixes are lost.</p>
</section>
</section>
<section id="option-2-instantiate-and-validate-binary-gltf" class="level3">
<h3 class="anchored" data-anchor-id="option-2-instantiate-and-validate-binary-gltf">Option 2: Instantiate and Validate binary GLTF</h3>
<p>For this option, we would stream an average glTF file from the web and develop a loader for glTF within the Godot sandbox equipped with a set of verifiers.</p>
<p>We must create custom VSEKAI or GODOT extensions for each unspecified resource and node type, though simple schemas could be autogenerated from classes.</p>
</section>
<section id="option-3-stream-arbitrary-godot-packed-scene-resources-write-a-verifier-and-then-parse" class="level3">
<h3 class="anchored" data-anchor-id="option-3-stream-arbitrary-godot-packed-scene-resources-write-a-verifier-and-then-parse">Option 3: Stream arbitrary Godot-packed scene resources, write a verifier and then parse</h3>
<p>Creating a JSON schema for arbitrary Godot-packed scene resources that have been converted to JSON is a complex task. This option might be more challenging than adapting glTF for sandbox C++.</p>
</section>
</section>
<section id="the-benefits" class="level2">
<h2 class="anchored" data-anchor-id="the-benefits">The Benefits</h2>
<p>A significant benefit of these approaches is the ability to enforce specific requirements, such as using PCVR and mobile image textures through formats like Basis Universal, BPTC, and ASTC during upload and download. By controlling the instantiation process, we can also prevent loading when, for example, an avatar exceeds a polycount of 70,000 triangles. We can size worlds according to predefined constraints, with various optimization settings available.</p>
</section>
<section id="the-downsides" class="level2">
<h2 class="anchored" data-anchor-id="the-downsides">The Downsides</h2>
<p>The primary downside is the complexity of these security measures and their potential performance impact. Each option requires substantial development effort and may introduce latency or processing overhead. Furthermore, maintaining these systems as Godot evolves could increase long-term maintenance costs.</p>
</section>
<section id="the-road-not-taken" class="level2">
<h2 class="anchored" data-anchor-id="the-road-not-taken">The Road Not Taken</h2>
<p>We could have explored simpler, less secure methods of content distribution that rely more heavily on post-load validation rather than stringent pre-load checks.</p>
</section>
<section id="the-infrequent-use-case" class="level2">
<h2 class="anchored" data-anchor-id="the-infrequent-use-case">The Infrequent Use Case</h2>
<p>These methods are designed to handle extremely large or complex scenes that might exceed the proposed limits and infrequent resource types not covered by standard validators.</p>
</section>
<section id="in-core-and-done-by-us" class="level2">
<h2 class="anchored" data-anchor-id="in-core-and-done-by-us">In Core and Done by Us</h2>
<p>We will maintain the core functionality of the sandbox and basic loaders, ensuring that critical updates or security patches can be applied swiftly and uniformly.</p>
</section>
<section id="status" class="level2">
<h2 class="anchored" data-anchor-id="status">Status</h2>
<p>Status: Draft <!-- Draft | Proposed | Rejected | Accepted | Deprecated | Superseded by --></p>
</section>
<section id="decision-makers" class="level2">
<h2 class="anchored" data-anchor-id="decision-makers">Decision Makers</h2>
<ul>
<li>V-Sekai development team</li>
<li>Fire</li>
<li>Lyuma</li>
<li>fwsgonzo</li>
</ul>
</section>
<section id="tags" class="level2">
<h2 class="anchored" data-anchor-id="tags">Tags</h2>
<ul>
<li>V-Sekai</li>
</ul>
</section>
<section id="further-reading" class="level2">
<h2 class="anchored" data-anchor-id="further-reading">Further Reading</h2>
<ol type="1">
<li><a href="https://github.com/v-sekai">V-Sekai · GitHub</a> - Official GitHub account for the V-Sekai development community focusing on social VR functionality for the Godot Engine.</li>
<li><a href="https://github.com/v-sekai/v-sekai-game">V-Sekai/v-sekai-game</a> - This GitHub page hosts the V-Sekai open-source project, which integrates social VR/VRSNS/metaverse components into the Godot Engine.</li>
</ol>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20241016-instantiating-v-sekai-content.html</guid>
  <pubDate>Mon, 23 Dec 2024 05:33:45 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20241014-xr-interface-for-rigging.html</link>
  <description><![CDATA[ 




<section id="draft-editing-character-body-bone-constraints-in-immersive-mode" class="level1">
<h1>Draft: Editing Character Body Bone Constraints in Immersive Mode</h1>
<section id="the-context" class="level2">
<h2 class="anchored" data-anchor-id="the-context">The Context</h2>
<p>V-Sekai is a social VR community.</p>
</section>
<section id="the-problem-statement" class="level2">
<h2 class="anchored" data-anchor-id="the-problem-statement">The Problem Statement</h2>
<p>We aim to develop a prototype interface for editing bone constraints such as position, rotation, twist rotation, and swing rotation on character body bones within an immersive environment.</p>
<p>Interactivity makes a difference, similar to the feeling of presence and being fully engaged with the editor. This greater flow state occurs because you don’t have to switch contexts, allowing for continuous interaction and focus.</p>
</section>
<section id="proposal-description" class="level2">
<h2 class="anchored" data-anchor-id="proposal-description">Proposal Description</h2>
<section id="interactive-design-concept" class="level3">
<h3 class="anchored" data-anchor-id="interactive-design-concept">Interactive Design Concept</h3>
<p>The proposed system will allow users to interact directly with avatar bone structures in a 3D space, manipulating constraints through intuitive gestures and tools. This approach aims to enhance user engagement and precision in modifying avatars.</p>
</section>
<section id="implementation-strategy" class="level3">
<h3 class="anchored" data-anchor-id="implementation-strategy">Implementation Strategy</h3>
<ol type="1">
<li><p><strong>Visual Representation of Bones</strong>:</p>
<ul>
<li>Each bone will be represented by a dot that becomes visible and enlarges when the user’s hand or controller approaches it, facilitating easy selection.</li>
</ul></li>
<li><p><strong>Avoiding Selection Mechanism</strong>:</p>
<ul>
<li>Instead of using a traditional selection mechanism, the system will employ proximity-based interaction. When a user’s hand or controller is near a bone, the relevant constraints automatically appear, allowing immediate manipulation without the need for explicit selection. This reduces complexity and enhances flow in the immersive environment.</li>
</ul></li>
<li><p><strong>Constraint Manipulation Tools</strong>:</p>
<ul>
<li>A virtual tool palette will be available to the user, containing different constraint modifiers.</li>
<li>Users can grab these tools and attach them to bones to adjust constraints like positions and rotations.</li>
</ul></li>
<li><p><strong>Tool Switcher Interface</strong>:</p>
<ul>
<li>In addition to the tool palette, a tool switcher mechanism will be implemented allowing users to quickly switch between tools without returning to the palette. This could be activated via a gesture or a button press, bringing up a radial or linear menu to select the desired tool.</li>
</ul></li>
<li><p><strong>Intuitive Constraint Adjustment</strong>:</p>
<ul>
<li>For position constraints, a 3D gizmo will appear, allowing users to manipulate the position directly within the VR space.</li>
<li>For rotational constraints, a 3D gizmo will appear, allowing users to manipulate the angle directly within the VR space.</li>
<li>Twist constraints will be adjusted using a 2d disk arc interface where permissible rotation areas are defined by the user.</li>
<li>Swing constraints can be adjusted using a spherical interface where permissible rotation areas are defined by the user.</li>
<li>Swing constraints can be adjusted using a 2d orbit map interface where permissible rotation areas are defined by the user.</li>
</ul></li>
<li><p><strong>Feedback and Precision</strong>:</p>
<ul>
<li>Visual and haptic feedback will be provided to ensure users are aware of the changes they are making.</li>
<li>Precision tools and snapping features will help in making exact adjustments.</li>
</ul></li>
<li><p><strong>Deselection and Context Switching</strong>:</p>
<ul>
<li>Moving the controller away from the bones or performing a specific gesture will clear the current interaction, allowing for a smooth workflow without accidental adjustments.</li>
</ul></li>
</ol>
</section>
<section id="mock-up-diagram" class="level3">
<h3 class="anchored" data-anchor-id="mock-up-diagram">Mock-up Diagram</h3>
<pre class="plaintext"><code>[User Interface Mock-up]
+------------------------------------------------+
|                                                |
|  [Avatar]                                      |
|    * (Head)                                    |
|    * (Shoulder)                                |
|    * (Elbow) &lt;-- [Interacting]                 |
|    * (Wrist)                                   |
|                                                |
|  [Tool Palette]                                |
|    - Grab Tool                                 |
|    - Rotate Tool                               |
|    - Swing Tool                                |
|    - Twist Tool                                |
|                                                |
|  [Tool Switcher]                               |
|    - Quick Switch Gesture                      |
|    - Radial Menu for Tool Selection            |
|                                                |
+------------------------------------------------+</code></pre>
</section>
</section>
<section id="benefits" class="level2">
<h2 class="anchored" data-anchor-id="benefits">Benefits</h2>
<ul>
<li><strong>Enhanced User Experience</strong>: Direct manipulation of bones and constraints in VR enhances the intuitiveness and enjoyment of avatar customization.</li>
<li><strong>Increased Precision</strong>: Fine control over adjustments leads to more accurate and satisfying results.</li>
<li><strong>Seamless Workflow</strong>: Integration of tools and interactions within the VR environment reduces the cognitive load and context switching, fostering a more creative and productive user experience.</li>
</ul>
</section>
<section id="downsides" class="level2">
<h2 class="anchored" data-anchor-id="downsides">Downsides</h2>
<ul>
<li><strong>Complexity in Implementation</strong>: Developing a fully interactive 3D UI with precise control mechanisms can be challenging and time-consuming.</li>
<li><strong>Performance Concerns</strong>: High fidelity models and real-time updates in VR may lead to performance issues on lower-end systems.</li>
<li>In a shared space app on the Apple Vision Pro neither switching or tool palette will work.</li>
<li>In an immersive app on the Apple Vision Pro either switching or tool palette will work with hand tracking.</li>
</ul>
</section>
<section id="the-road-not-taken" class="level2">
<h2 class="anchored" data-anchor-id="the-road-not-taken">The Road Not Taken</h2>
<ul>
<li><strong>2D GUI for Constraint Management</strong>: Using a traditional 2D interface for constraint management was considered but rejected due to the lack of immersion and intuitiveness in a VR context.</li>
</ul>
<p>The implementation of scale for matching clothing to the character’s body, as well as the adjustment of constraint weight, will be addressed in future work.</p>
</section>
<section id="in-core-and-done-by-us" class="level2">
<h2 class="anchored" data-anchor-id="in-core-and-done-by-us">In Core and Done by Us</h2>
<p>This feature is core to the V-Sekai project’s mission of enhancing VR interaction and will be developed internally to maintain control over quality and integration.</p>
</section>
<section id="status" class="level2">
<h2 class="anchored" data-anchor-id="status">Status</h2>
<p>Status: Draft <!-- Draft | Proposed | Rejected | Accepted | Deprecated | Superseded by --></p>
</section>
<section id="decision-makers" class="level2">
<h2 class="anchored" data-anchor-id="decision-makers">Decision Makers</h2>
<ul>
<li>V-Sekai development team</li>
<li>Fire</li>
<li>Nova</li>
</ul>
</section>
<section id="tags" class="level2">
<h2 class="anchored" data-anchor-id="tags">Tags</h2>
<ul>
<li>V-Sekai, interactive presence, unfolding complexity, avatar dots, maximum precision, angle constraints, twist constraint, sphere visualization, constraint palette, tool shadow, localized selection, proprioceptive action, switcher interface, tool palette, deselection method, user flow</li>
</ul>
</section>
<section id="further-reading" class="level2">
<h2 class="anchored" data-anchor-id="further-reading">Further Reading</h2>
<ol type="1">
<li><a href="https://github.com/v-sekai">V-Sekai · GitHub</a> - Official GitHub account for the V-Sekai development community focusing on social VR functionality for the Godot Engine.</li>
<li><a href="https://github.com/v-sekai/v-sekai-game">V-Sekai/v-sekai-game</a> - GitHub page for the V-Sekai open-source project, which brings social VR/VRSNS/metaverse components to the Godot Engine.</li>
<li><a href="https://github.com/V-Sekai/lasso">V-Sekai/lasso</a> - GitHub for vr interaction.</li>
</ol>
<p>AI assistant Aria assisted with this article.</p>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20241014-xr-interface-for-rigging.html</guid>
  <pubDate>Mon, 23 Dec 2024 05:33:45 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20241014-basic-realtime-interaction.html</link>
  <description><![CDATA[ 




<section id="draft-basic-real-time-interaction-for-character-and-world-scenes" class="level1">
<h1>Draft: Basic Real-Time Interaction for Character and World Scenes</h1>
<section id="the-context" class="level2">
<h2 class="anchored" data-anchor-id="the-context">The Context</h2>
<p>The project will enable users to interact in real-time by manipulating objects within a shared virtual environment, enhancing the user experience.</p>
</section>
<section id="the-problem-statement" class="level2">
<h2 class="anchored" data-anchor-id="the-problem-statement">The Problem Statement</h2>
<p>I want to extend V-Sekai’s functionality to support real-time interaction with uploaded character and world scenes. This includes the ability for users to manipulate objects within the scene and have those changes reflected in real-time for other users connected to the same session. Additionally, seamless integration of new elements into the environment is crucial.</p>
<p>Here’s a detailed breakdown of the features we plan to implement:</p>
<ul>
<li><strong>Real-time Interaction</strong>: Users can move and rotate objects in the scene. Changes appear instantly, providing immediate visual feedback.</li>
<li><strong>Networked Synchronization</strong>: When one user modifies something, the change is immediately visible to all other users in the same session.</li>
<li><strong>Object Persistence</strong>: Users can save their current scene setup to continue working on it later or retrieve it in another session.</li>
<li><strong>Dynamic Environment Integration</strong>: Facilitate the introduction of new interactive elements during live sessions.</li>
<li><strong>Mediator Role</strong>: A special user, called a mediator, can manage permissions like who can move what, start or end the session, and oversee interactions between users.</li>
<li><strong>Limited Scope</strong>: Initially, this feature will support multiple users interacting in one scene without additional complexities like handling multiple scenes or advanced physics.</li>
</ul>
<p>This upgrade leverages the existing functionality of V-Sekai for uploading and rendering game engine assets. It assumes the utilization of V-Sekai’s current game engine and networking capabilities, or the integration of clearly specified, readily available libraries or services to achieve the desired real-time interaction and synchronization.</p>
</section>
<section id="describe-how-your-proposal-will-work-with-code-pseudo-code-mock-ups-or-diagrams" class="level2">
<h2 class="anchored" data-anchor-id="describe-how-your-proposal-will-work-with-code-pseudo-code-mock-ups-or-diagrams">Describe how your proposal will work with code, pseudo-code, mock-ups, or diagrams</h2>
<section id="mock-up-diagram" class="level3">
<h3 class="anchored" data-anchor-id="mock-up-diagram">Mock-up Diagram</h3>
<pre class="plaintext"><code>[Scene Interaction Mock-up]
+------------------------------------------------+
|                                                |
|  [User1]                                       |
|    * (Object1) &lt;-- [Moving]                    |
|                                                |
|  [Tool Switcher Pie Menu]                      |
|    - Move Tool                                 |
|    - Rotate Tool                               |
|    - Close                                     |
|                                                |
|  [User2]                                       |
|    * (Object2)                                 |
|                                                |
+------------------------------------------------+</code></pre>
</section>
</section>
<section id="the-benefits" class="level2">
<h2 class="anchored" data-anchor-id="the-benefits">The Benefits</h2>
<p>Enhanced user engagement allows users to interact dynamically with objects, increasing the sense of presence. Establishing basic functionalities lays the foundation for future features that can include more complex interactions. Immediate feedback is crucial for collaborative environments, and intuitive tool selection through the Tool Switcher Pie Menu enhances workflow efficiency.</p>
</section>
<section id="the-downsides" class="level2">
<h2 class="anchored" data-anchor-id="the-downsides">The Downsides</h2>
<p>The initial features are limited to basic manipulations, which might not meet all user expectations. As the user base grows, the current simple synchronization mechanism may need significant enhancements.</p>
</section>
<section id="the-road-not-taken" class="level2">
<h2 class="anchored" data-anchor-id="the-road-not-taken">The Road Not Taken</h2>
<p>A full-scale interaction suite was initially considered, including scaling and advanced physics, but it was decided against due to complexity and resource constraints.</p>
</section>
<section id="the-infrequent-use-case" class="level2">
<h2 class="anchored" data-anchor-id="the-infrequent-use-case">The Infrequent Use Case</h2>
<p>While the system is designed for multiple users, it will also support single-user sessions, although this is not the primary focus.</p>
</section>
<section id="in-core-and-done-by-us" class="level2">
<h2 class="anchored" data-anchor-id="in-core-and-done-by-us">In Core and Done by Us</h2>
<p>This feature is core to the project’s mission of enhancing interactive capabilities and will be developed internally to ensure seamless integration and maintain control over quality.</p>
</section>
<section id="status" class="level2">
<h2 class="anchored" data-anchor-id="status">Status</h2>
<p>Status: Draft <!-- Draft | Proposed | Rejected | Accepted | Deprecated | Superseded by --></p>
</section>
<section id="decision-makers" class="level2">
<h2 class="anchored" data-anchor-id="decision-makers">Decision Makers</h2>
<ul>
<li>Project development team</li>
<li>Fire</li>
<li>Humble Tim</li>
</ul>
</section>
<section id="tags" class="level2">
<h2 class="anchored" data-anchor-id="tags">Tags</h2>
<p>Real-time interaction, basic object manipulation, networked synchronization, user engagement, virtual collaboration, intuitive tool switching</p>
</section>
<section id="further-reading" class="level2">
<h2 class="anchored" data-anchor-id="further-reading">Further Reading</h2>
<ol type="1">
<li><a href="https://github.com/project">Project GitHub</a> - Official GitHub account for the project development community focusing on enhancing virtual interaction capabilities.</li>
<li><a href="https://docs.project.com">Project Documentation</a> - Comprehensive documentation on the project’s features and development guidelines.</li>
</ol>
<p><em>AI assistant Aria assisted with this article.</em></p>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20241014-basic-realtime-interaction.html</guid>
  <pubDate>Mon, 23 Dec 2024 05:33:45 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20241014-app-updater.html</link>
  <description><![CDATA[ 




<section id="draft-updater-no-op-implementation-using-velopack" class="level1">
<h1>Draft: Updater No-Op Implementation Using Velopack</h1>
<section id="the-context" class="level2">
<h2 class="anchored" data-anchor-id="the-context">The Context</h2>
<p>V-Sekai needs frequent updates to improve and expand its VR features.</p>
</section>
<section id="the-problem-statement" class="level2">
<h2 class="anchored" data-anchor-id="the-problem-statement">The Problem Statement</h2>
<p>It’s essential to keep users informed during updates without distracting them with complex visuals.</p>
</section>
<section id="describe-how-your-proposal-will-work-with-code-pseudo-code-mock-ups-or-diagrams" class="level2">
<h2 class="anchored" data-anchor-id="describe-how-your-proposal-will-work-with-code-pseudo-code-mock-ups-or-diagrams">Describe how your proposal will work with code, pseudo-code, mock-ups, or diagrams</h2>
<section id="pseudo-code-using-velopack" class="level3">
<h3 class="anchored" data-anchor-id="pseudo-code-using-velopack">Pseudo-Code Using Velopack</h3>
<pre class="gdscript"><code>func update_application():
    show_text("Updating V-Sekai... Please wait.")
    if Velopack.check_for_updates():
        Velopack.perform_update()
    hide_text()
    notify("Update complete!")

func show_text(text):
    var label = Label.new()
    label.text = text
    add_child(label)

func hide_text():
    get_node("Label").queue_free()

func notify(message):
    show_message(message)</code></pre>
</section>
</section>
<section id="the-benefits" class="level2">
<h2 class="anchored" data-anchor-id="the-benefits">The Benefits</h2>
<ul>
<li><strong>Simplicity:</strong> Straightforward user communication.</li>
<li><strong>Clarity:</strong> Clear update status messages.</li>
<li><strong>Performance:</strong> Efficient use of resources through Velopack’s optimized update mechanisms.</li>
</ul>
</section>
<section id="the-downsides" class="level2">
<h2 class="anchored" data-anchor-id="the-downsides">The Downsides</h2>
<ul>
<li><strong>Lack of Visual Appeal:</strong> Simple text might seem less professional.</li>
<li><strong>Dependency on External Tool:</strong> Reliance on Velopack for update management.</li>
</ul>
</section>
<section id="the-road-not-taken" class="level2">
<h2 class="anchored" data-anchor-id="the-road-not-taken">The Road Not Taken</h2>
<p>A full graphical interface was considered but deemed too distracting for this phase.</p>
</section>
<section id="the-infrequent-use-case" class="level2">
<h2 class="anchored" data-anchor-id="the-infrequent-use-case">The Infrequent Use Case</h2>
<p>Users who rarely update might prefer more detailed visuals.</p>
</section>
<section id="in-core-and-done-by-us" class="level2">
<h2 class="anchored" data-anchor-id="in-core-and-done-by-us">In Core and Done by Us</h2>
<p>Handled internally to ensure seamless integration with Velopack.</p>
</section>
<section id="status" class="level2">
<h2 class="anchored" data-anchor-id="status">Status</h2>
<p>Status: Draft <!-- Draft | Proposed | Rejected | Accepted | Deprecated | Superseded by --></p>
</section>
<section id="decision-makers" class="level2">
<h2 class="anchored" data-anchor-id="decision-makers">Decision Makers</h2>
<ul>
<li>V-Sekai development team</li>
</ul>
</section>
<section id="tags" class="level2">
<h2 class="anchored" data-anchor-id="tags">Tags</h2>
<ul>
<li>V-Sekai</li>
<li>Updater</li>
<li>Velopack</li>
</ul>
</section>
<section id="further-reading" class="level2">
<h2 class="anchored" data-anchor-id="further-reading">Further Reading</h2>
<ol type="1">
<li><a href="https://github.com/v-sekai">V-Sekai · GitHub</a> - Official GitHub repository.</li>
<li><a href="https://github.com/v-sekai/v-sekai-game">V-Sekai/v-sekai-game</a> - Project page on GitHub.</li>
<li><a href="https://velopack.org/docs">Velopack Documentation</a> - Learn more about how Velopack manages application updates.</li>
</ol>
<p>AI assistant Aria assisted with this article.</p>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20241014-app-updater.html</guid>
  <pubDate>Mon, 23 Dec 2024 05:33:45 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20241011-recovering-makehuman-parameters.html</link>
  <description><![CDATA[ 




<section id="draft-recovering-makehuman-parameters-using-depth-map-comparison-with-godot-engine" class="level1">
<h1>Draft: Recovering MakeHuman Parameters Using Depth Map Comparison with Godot Engine</h1>
<section id="the-context" class="level2">
<h2 class="anchored" data-anchor-id="the-context">The Context</h2>
<p>In the realm of digital animation and character modeling, fitting an avatar to a specific image can enhance personalization and realism in various applications such as gaming and virtual reality.</p>
</section>
<section id="the-problem-statement" class="level2">
<h2 class="anchored" data-anchor-id="the-problem-statement">The Problem Statement</h2>
<p>The challenge lies in accurately estimating the parameters of a MakeHuman model from a given anime-style image to ensure the avatar closely resembles the original character.</p>
</section>
<section id="describe-how-your-proposal-will-work-with-code-pseudo-code-mock-ups-or-diagrams" class="level2">
<h2 class="anchored" data-anchor-id="describe-how-your-proposal-will-work-with-code-pseudo-code-mock-ups-or-diagrams">Describe how your proposal will work with code, pseudo-code, mock-ups, or diagrams</h2>
<section id="proposal-overview" class="level3">
<h3 class="anchored" data-anchor-id="proposal-overview">Proposal Overview</h3>
<p>We propose a system that utilizes depth map comparisons between rendered images from the Godot Engine and depth maps generated from anime images using Apple’s ML-Depth-Pro. This approach aims to optimize the MakeHuman parameters to recreate accurate 3D models of anime characters.</p>
<section id="key-objectives" class="level4">
<h4 class="anchored" data-anchor-id="key-objectives">Key Objectives</h4>
<ul>
<li><strong>Depth Map Generation</strong>: Generate depth maps from both anime images and Godot-rendered characters.</li>
<li><strong>Optimization</strong>: Employ machine learning techniques to minimize the differences between these depth maps, facilitating accurate parameter recovery.</li>
<li><strong>Cost Efficiency</strong>: Leverage open-source tools to maintain budget-friendliness.</li>
</ul>
</section>
<section id="scope" class="level4">
<h4 class="anchored" data-anchor-id="scope">Scope</h4>
<ul>
<li><strong>Input Data</strong>: Anime images with manually labeled MakeHuman parameters for initial calibration.</li>
<li><strong>Depth Comparison</strong>: Analyze the discrepancies between the depth maps produced by Godot and those derived from anime images.</li>
<li><strong>Optimization Process</strong>: Utilize a search algorithm (e.g., genetic algorithm or bayesian optimization) to iteratively adjust and determine optimal MakeHuman parameters.</li>
</ul>
</section>
<section id="work-breakdown" class="level4">
<h4 class="anchored" data-anchor-id="work-breakdown">Work Breakdown</h4>
<ol type="1">
<li><strong>Data Collection</strong>:
<ul>
<li><strong>Task</strong>: Manually label a small set of images with MakeHuman parameters.</li>
<li><strong>Outcome</strong>: Create a baseline dataset for initial optimization efforts.</li>
</ul></li>
<li><strong>Godot Integration</strong>:
<ul>
<li><strong>Task</strong>: Develop a script within Godot to render depth maps from configured MakeHuman models.</li>
<li><strong>Outcome</strong>: Prepare depth maps for subsequent comparison.</li>
</ul></li>
<li><strong>Optimization Algorithm</strong>:
<ul>
<li><strong>Task</strong>: Implement a cost-effective optimization algorithm using a suitable loss function (e.g., L2, Chamfer distance).</li>
<li><strong>Outcome</strong>: Establish a mechanism to identify the best matching MakeHuman parameters.</li>
</ul></li>
<li><strong>Testing and Refinement</strong>:
<ul>
<li><strong>Task</strong>: Systematically compare generated depth maps and refine the algorithm to improve accuracy.</li>
<li><strong>Timeline</strong>:
<ul>
<li><strong>Data Collection</strong>: 1 week</li>
<li><strong>Godot Integration</strong>: 2 weeks</li>
<li><strong>Optimization Model</strong>: 3 weeks</li>
<li><strong>Testing &amp; Refinement</strong>: 1 week</li>
<li><strong>Total Duration</strong>: 7 weeks</li>
</ul></li>
</ul></li>
</ol>
</section>
</section>
</section>
<section id="the-benefits" class="level2">
<h2 class="anchored" data-anchor-id="the-benefits">The Benefits</h2>
<p>This streamlined, budget-conscious methodology promises significant enhancements in personalization and realism in digital character modeling, making it ideal for applications in gaming and virtual reality where character authenticity is crucial.</p>
</section>
<section id="the-downsides" class="level2">
<h2 class="anchored" data-anchor-id="the-downsides">The Downsides</h2>
<ul>
<li><strong>Limited Creativity</strong>: Strict adherence to replicating existing images may limit creative modifications.</li>
<li><strong>Technical Complexity</strong>: The integration of multiple advanced technologies (depth sensing, machine learning, and 3D rendering) requires high technical expertise.</li>
</ul>
</section>
<section id="the-road-not-taken" class="level2">
<h2 class="anchored" data-anchor-id="the-road-not-taken">The Road Not Taken</h2>
<p>Alternative methods such as direct 3D scanning of physical models or manual tweaking of parameters were considered but deemed less efficient and scalable compared to our proposed automated depth comparison method.</p>
</section>
<section id="the-infrequent-use-case" class="level2">
<h2 class="anchored" data-anchor-id="the-infrequent-use-case">The Infrequent Use Case</h2>
<p>In cases where extremely high fidelity is required, such as in professional film production, additional manual adjustments by expert artists might still be necessary.</p>
</section>
<section id="in-core-and-done-by-us" class="level2">
<h2 class="anchored" data-anchor-id="in-core-and-done-by-us">In Core and Done by Us</h2>
<p>This project aligns with our core mission of enhancing digital interaction experiences and will be developed and maintained by our team.</p>
</section>
<section id="status" class="level2">
<h2 class="anchored" data-anchor-id="status">Status</h2>
<p>Status: Draft <!-- Draft | Proposed | Rejected | Accepted | Deprecated | Superseded by --></p>
</section>
<section id="decision-makers" class="level2">
<h2 class="anchored" data-anchor-id="decision-makers">Decision Makers</h2>
<ul>
<li>V-Sekai development team</li>
</ul>
</section>
<section id="tags" class="level2">
<h2 class="anchored" data-anchor-id="tags">Tags</h2>
<ul>
<li>V-Sekai</li>
</ul>
</section>
<section id="further-reading" class="level2">
<h2 class="anchored" data-anchor-id="further-reading">Further Reading</h2>
<ol type="1">
<li><a href="https://github.com/v-sekai">V-Sekai · GitHub</a> - Official GitHub account for the V-Sekai development community focusing on social VR functionality for the Godot Engine.</li>
<li><a href="https://github.com/v-sekai/v-sekai-game">V-Sekai/v-sekai-game</a> - GitHub page for the V-Sekai open-source project, which brings social VR/VRSNS/metaverse components to the Godot Engine.</li>
<li><a href="https://huggingface.co/spaces/A19grey/Depth-Pro-in-Meters">DepthPro Demo with 3D Visualization</a></li>
<li><a href="https://ludwig.ai/0.4/developer_guide/hyper_parameter_optimization/">Hyper_parameter_optimization like bayensian optimization</a></li>
</ol>
<p>AI assistant Aria assisted with this article.</p>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20241011-recovering-makehuman-parameters.html</guid>
  <pubDate>Mon, 23 Dec 2024 05:33:45 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20241006-restore-onedrive-shortcut-overrides.html</link>
  <description><![CDATA[ 




<section id="accepted-restoring-default-user-directory-structure-in-windows-11" class="level1">
<h1>Accepted: Restoring Default User Directory Structure in Windows 11</h1>
<section id="the-context" class="level2">
<h2 class="anchored" data-anchor-id="the-context">The Context</h2>
<p>Using Windows 11.</p>
</section>
<section id="the-problem-statement" class="level2">
<h2 class="anchored" data-anchor-id="the-problem-statement">The Problem Statement</h2>
<p>Microsoft has configured OneDrive to automatically move key user folders such as Documents, Desktop, and others from the user directory into the OneDrive folder. This change can disrupt users’ familiar file organization and system workflows.</p>
</section>
<section id="describe-how-your-proposal-will-work-with-code-pseudo-code-mock-ups-or-diagrams" class="level2">
<h2 class="anchored" data-anchor-id="describe-how-your-proposal-will-work-with-code-pseudo-code-mock-ups-or-diagrams">Describe how your proposal will work with code, pseudo-code, mock-ups, or diagrams</h2>
<p>The solution involves two main steps:</p>
<ol type="1">
<li><strong>Disabling OneDrive Sync</strong>: Users need to pause or stop OneDrive from syncing these folders.</li>
<li><strong>Running a Restore Default Paths Script</strong>: Execute a script that resets the default paths of user directories back to their original locations on the local drive.</li>
</ol>
</section>
<section id="the-benefits" class="level2">
<h2 class="anchored" data-anchor-id="the-benefits">The Benefits</h2>
<ul>
<li>Restores traditional file paths for ease of access and familiarity.</li>
<li>Reduces dependency on cloud synchronization for essential folders.</li>
<li>Improves system performance by reducing unnecessary sync operations.</li>
</ul>
</section>
<section id="the-downsides" class="level2">
<h2 class="anchored" data-anchor-id="the-downsides">The Downsides</h2>
<ul>
<li>Manual intervention required by users not comfortable with script execution.</li>
<li>Potential data discrepancies if files are not fully synchronized before the change.</li>
</ul>
</section>
<section id="the-road-not-taken" class="level2">
<h2 class="anchored" data-anchor-id="the-road-not-taken">The Road Not Taken</h2>
<p>Alternative solutions like using third-party tools or different cloud services were considered but dismissed due to increased complexity and potential security concerns.</p>
</section>
<section id="the-infrequent-use-case" class="level2">
<h2 class="anchored" data-anchor-id="the-infrequent-use-case">The Infrequent Use Case</h2>
<p>Users who operate primarily offline or have strict data handling policies may find this change particularly beneficial.</p>
</section>
<section id="in-core-and-done-by-us" class="level2">
<h2 class="anchored" data-anchor-id="in-core-and-done-by-us">In Core and Done by Us</h2>
<p>This proposal is to be implemented internally within the V-Sekai development team’s systems before considering broader deployment.</p>
</section>
<section id="status" class="level2">
<h2 class="anchored" data-anchor-id="status">Status</h2>
<p>Status: Accepted <!-- Draft | Proposed | Rejected | Accepted | Deprecated | Superseded by --></p>
</section>
<section id="decision-makers" class="level2">
<h2 class="anchored" data-anchor-id="decision-makers">Decision Makers</h2>
<ul>
<li>V-Sekai development team</li>
</ul>
</section>
<section id="tags" class="level2">
<h2 class="anchored" data-anchor-id="tags">Tags</h2>
<ul>
<li>V-Sekai</li>
</ul>
</section>
<section id="further-reading" class="level2">
<h2 class="anchored" data-anchor-id="further-reading">Further Reading</h2>
<ol type="1">
<li><a href="https://github.com/v-sekai">V-Sekai · GitHub</a> - Official GitHub account for the V-Sekai development community focusing on social VR functionality for the Godot Engine.</li>
<li><a href="https://github.com/v-sekai/v-sekai-game">V-Sekai/v-sekai-game</a> - GitHub page for the V-Sekai open-source project, which brings social VR/VRSNS/metaverse components to the Godot Engine.</li>
<li><a href="https://www.winhelponline.com/blog/windows-10-shell-folders-paths-defaults-restore/">Windows 10/11 User Shell Folders Restore Default Paths</a></li>
</ol>
<p>AI assistant Aria assisted with this article.</p>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20241006-restore-onedrive-shortcut-overrides.html</guid>
  <pubDate>Mon, 23 Dec 2024 05:33:45 GMT</pubDate>
</item>
</channel>
</rss>
