<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>V-Sekai - Manuals</title>
<link>https://v-sekai.github.io/manuals/decisions.html</link>
<atom:link href="https://v-sekai.github.io/manuals/decisions.xml" rel="self" type="application/rss+xml"/>
<description></description>
<generator>quarto-1.3.450</generator>
<lastBuildDate>Sun, 06 Aug 2023 22:12:37 GMT</lastBuildDate>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/present-proposal-template.html</link>
  <description><![CDATA[ 



<section id="this-decision-solves-a-v-sekai-limitation" class="level1">
<h1>This decision solves a V-Sekai limitation</h1>
<section id="metadata" class="level2">
<h2 class="anchored" data-anchor-id="metadata">Metadata</h2>
<ul>
<li>Status: proposed <!-- draft | proposed | rejected | accepted | deprecated | superseded by --></li>
<li>Deciders: V-Sekai</li>
<li>Tags: V-Sekai</li>
</ul>
</section>
<section id="the-backdrop" class="level2">
<h2 class="anchored" data-anchor-id="the-backdrop">The Backdrop</h2>
</section>
<section id="the-challenge" class="level2">
<h2 class="anchored" data-anchor-id="the-challenge">The Challenge</h2>
</section>
<section id="the-strategy" class="level2">
<h2 class="anchored" data-anchor-id="the-strategy">The Strategy</h2>
</section>
<section id="the-upside" class="level2">
<h2 class="anchored" data-anchor-id="the-upside">The Upside</h2>
</section>
<section id="the-downside" class="level2">
<h2 class="anchored" data-anchor-id="the-downside">The Downside</h2>
</section>
<section id="the-road-not-taken" class="level2">
<h2 class="anchored" data-anchor-id="the-road-not-taken">The Road Not Taken</h2>
</section>
<section id="the-infrequent-use-case" class="level2">
<h2 class="anchored" data-anchor-id="the-infrequent-use-case">The Infrequent Use Case</h2>
</section>
<section id="the-core-reason" class="level2">
<h2 class="anchored" data-anchor-id="the-core-reason">The Core Reason</h2>
</section>
<section id="further-reading" class="level2">
<h2 class="anchored" data-anchor-id="further-reading">Further Reading</h2>
<ul>
<li><a href="https://v-sekai.org/">V-Sekai</a></li>
<li>This article is assisted by AI.</li>
</ul>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/present-proposal-template.html</guid>
  <pubDate>Sun, 06 Aug 2023 22:12:37 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20230806-v-sekai-ipad-projection-compatibility.html</link>
  <description><![CDATA[ 



<section id="v-sekai-ipad-and-presentation-screen-compatibility-with-vr" class="level1">
<h1>V-Sekai iPad and Presentation Screen Compatibility with VR</h1>
<section id="metadata" class="level2">
<h2 class="anchored" data-anchor-id="metadata">Metadata</h2>
<ul>
<li><strong>Status:</strong> Proposed</li>
<li><strong>Deciders:</strong> V-Sekai</li>
<li><strong>Tags:</strong> V-Sekai, iPad, Presentation Screen, Compatibility</li>
</ul>
</section>
<section id="the-backdrop" class="level2">
<h2 class="anchored" data-anchor-id="the-backdrop">The Backdrop</h2>
<p>We are developing a VR game that needs to be compatible with both iPads and large projector screens for presentations.</p>
</section>
<section id="the-challenge" class="level2">
<h2 class="anchored" data-anchor-id="the-challenge">The Challenge</h2>
<p>The challenge is to ensure the game’s user interface and controls work seamlessly across these different display sizes and touch interfaces.</p>
</section>
<section id="the-strategy" class="level2">
<h2 class="anchored" data-anchor-id="the-strategy">The Strategy</h2>
<p>We considered two options: Virtual joystick for touchscreen devices and Navmesh and 3D navigation points. We chose the “Virtual joystick for touchscreen devices” because it addresses the core issue of ensuring compatibility with iPads and large projector screens, and it is more cost-effective.</p>
</section>
<section id="the-upside" class="level2">
<h2 class="anchored" data-anchor-id="the-upside">The Upside</h2>
<ul>
<li>Improved user experience across different devices and screen sizes.</li>
<li>Increased versatility of the game, making it suitable for various applications.</li>
<li>Enhanced navigation in 3D spaces.</li>
<li>More cost-effective solution.</li>
</ul>
</section>
<section id="the-downside" class="level2">
<h2 class="anchored" data-anchor-id="the-downside">The Downside</h2>
<ul>
<li>Potential increase in development time and costs.</li>
<li>Possible need for additional resources for testing on different devices and screens.</li>
</ul>
</section>
<section id="the-road-not-taken" class="level2">
<h2 class="anchored" data-anchor-id="the-road-not-taken">The Road Not Taken</h2>
<p>Navmesh and 3D Navigation Points were considered but not chosen due to their inability to address the core issue of ensuring compatibility with iPads and large projector screens.</p>
</section>
<section id="the-infrequent-use-case" class="level2">
<h2 class="anchored" data-anchor-id="the-infrequent-use-case">The Infrequent Use Case</h2>
<p>While Navmesh and 3D Navigation Points provide an intuitive user interface for navigating 3D spaces, they might not translate well to continuous interaction on touchscreens, which is often expected by users on such devices.</p>
</section>
<section id="the-core-reason" class="level2">
<h2 class="anchored" data-anchor-id="the-core-reason">The Core Reason</h2>
<p>The core reason for choosing the virtual joystick option is its ability to ensure compatibility with iPads and large projector screens, and its cost-effectiveness.</p>
</section>
<section id="further-reading" class="level2">
<h2 class="anchored" data-anchor-id="further-reading">Further Reading</h2>
<ul>
<li><a href="https://v-sekai.org/">V-Sekai</a></li>
<li>This article is assisted by AI.</li>
</ul>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20230806-v-sekai-ipad-projection-compatibility.html</guid>
  <pubDate>Sun, 06 Aug 2023 22:12:37 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20230806-music-gen.html</link>
  <description><![CDATA[ 



<section id="sonic-symphony-crafting-melodies-with-machine-intelligence" class="level1">
<h1>Sonic Symphony: Crafting Melodies with Machine Intelligence</h1>
<section id="the-blueprint" class="level2">
<h2 class="anchored" data-anchor-id="the-blueprint">The Blueprint</h2>
<ul>
<li><strong>Status:</strong> In the works</li>
<li><strong>Masterminds:</strong> V-Sekai, fire</li>
<li><strong>Keywords:</strong> Music, AI, GPT-3, Python, Generation</li>
</ul>
</section>
<section id="the-backdrop" class="level2">
<h2 class="anchored" data-anchor-id="the-backdrop">The Backdrop</h2>
<p>As we navigate the 21st century, technology has become an inseparable part of our existence. It’s been making waves in the realm of music too. One such wave is the use of artificial intelligence (AI) to craft melodies. This blueprint proposes a method for creating music using computer algorithms.</p>
</section>
<section id="the-challenge" class="level2">
<h2 class="anchored" data-anchor-id="the-challenge">The Challenge</h2>
<p>The mission is to create music using computer programs.</p>
</section>
<section id="the-strategy" class="level2">
<h2 class="anchored" data-anchor-id="the-strategy">The Strategy</h2>
<p>One promising strategy is to employ .ABC files. These files have proven effective in generating outputs with AI models like GPT-3. The .ABC files carry data in the header section, such as the key signature, tempo, and time signature, which can be incorporated into the prompt.</p>
<p>Alternatively, we could leverage AI models to script for us. For instance, we could ask for a Python script that composes the chromatic 7th intervals from C to B in eighth notes. The output format could be something user-friendly like Lilypond or MusicXML.</p>
<p>Here’s a sneak peek at a Python script:</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> generate_chromatic_seventh_intervals():</span>
<span id="cb1-2">    notes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'C'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'C#'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'D'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'D#'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'E'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'F'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'F#'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'G'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'G#'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'A'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'A#'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'B'</span>]</span>
<span id="cb1-3">    intervals <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb1-4"></span>
<span id="cb1-5">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(notes)):</span>
<span id="cb1-6">        seventh_interval <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (i <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(notes)</span>
<span id="cb1-7">        intervals.append((notes[i], notes[seventh_interval]))</span>
<span id="cb1-8"></span>
<span id="cb1-9">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> intervals</span>
<span id="cb1-10"></span>
<span id="cb1-11"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(generate_chromatic_seventh_intervals())</span></code></pre></div>
<p>Another feasible strategy might be to use AI models to generate Lilypond syntax. Lilypond is a robust and adaptable tool for engraving tasks of all kinds, including sheet music, complex notation, vocal music, etc. Here is an example of a simple Lilypond syntax:</p>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode lilypond code-with-copy"><code class="sourceCode lilypond"><span id="cb2-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">\relative c'</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb2-2">  c<span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span> d e f <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">|</span></span>
<span id="cb2-3">  g a b c <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">|</span></span>
<span id="cb2-4"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">}</span></span></code></pre></div>
<p>This code will compose a sequence of eighth notes from C to C.</p>
</section>
<section id="the-road-not-taken" class="level2">
<h2 class="anchored" data-anchor-id="the-road-not-taken">The Road Not Taken</h2>
<p>During the journey to find a solution, several paths were explored and abandoned for various reasons:</p>
<ol type="1">
<li><p><strong>Using MIDI files:</strong> While MIDI files are a common choice for music creation, they were left behind due to their complexity and the challenge in crafting them programmatically.</p></li>
<li><p><strong>Using MusicXML:</strong> Despite MusicXML being a comprehensive and widely supported format, it was abandoned due to its lengthy and intricate structure, which makes it tough to craft programmatically.</p></li>
<li><p><strong>Using other music notation software:</strong> Other music notation software like Finale and Sibelius were considered but left behind due to their proprietary nature and lack of support for the programmatic generation of music.</p></li>
</ol>
</section>
<section id="the-upside" class="level2">
<h2 class="anchored" data-anchor-id="the-upside">The Upside</h2>
<ul>
<li>This approach will pave the way for easier music creation.</li>
<li>It will sidestep the limitations posed by the intricate structure of MusicXML.</li>
</ul>
</section>
<section id="the-downside" class="level2">
<h2 class="anchored" data-anchor-id="the-downside">The Downside</h2>
<ul>
<li>There may be some hurdles when using AI models to generate Lilypond syntax.</li>
<li>Training small transformers to output syntactically correct .ABC files might pose a challenge.</li>
</ul>
</section>
<section id="further-reading" class="level2">
<h2 class="anchored" data-anchor-id="further-reading">Further Reading</h2>
<ul>
<li><a href="https://gwern.net/gpt-2-music">Sample .ABC files</a></li>
<li><a href="https://lilypond.org/doc/v2.24/Documentation/notation/index">Lilypond Notation Reference</a></li>
<li><a href="https://news.ycombinator.com/item?id=37016049">Ask HN: AI that produces sheet music for practice?</a></li>
</ul>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20230806-music-gen.html</guid>
  <pubDate>Sun, 06 Aug 2023 22:12:37 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20230804-dokku.html</link>
  <description><![CDATA[ 



<section id="dokku-for-v-sekai-uro-backend-services-hosting-and-development" class="level1">
<h1>Dokku for V-Sekai URO Backend Services Hosting and Development</h1>
<section id="metadata" class="level2">
<h2 class="anchored" data-anchor-id="metadata">Metadata</h2>
<ul>
<li>Status: Proposed</li>
<li>Deciders: V-Sekai</li>
<li>Tags: V-Sekai, Dokku, Backend, Hosting, Development</li>
</ul>
</section>
<section id="context-and-problem-statement" class="level2">
<h2 class="anchored" data-anchor-id="context-and-problem-statement">Context and Problem Statement</h2>
<p>V-Sekai is exploring options to improve its backend services hosting and development. The goal is to find a system that can offer scalability, ease of deployment, and efficient resource management.</p>
</section>
<section id="proposed-solution" class="level2">
<h2 class="anchored" data-anchor-id="proposed-solution">Proposed Solution</h2>
<p>One potential solution could be <a href="http://dokku.viewdocs.io/dokku/">Dokku</a>, a Docker-powered mini-Heroku. Dokku provides a platform that could potentially meet our needs for building, deploying and managing applications effectively.</p>
</section>
<section id="implementation" class="level2">
<h2 class="anchored" data-anchor-id="implementation">Implementation</h2>
<p>If Dokku were chosen, the implementation would involve setting up a Dokku server, migrating existing services, and training the team on how to use Dokku for development and deployment.</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb1-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Install Dokku</span></span>
<span id="cb1-2"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">wget</span> https://raw.githubusercontent.com/dokku/dokku/v0.21.4/bootstrap.sh<span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb1-3"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sudo</span> DOKKU_TAG=v0.21.4 bash bootstrap.sh</span></code></pre></div>
</section>
<section id="potential-benefits" class="level2">
<h2 class="anchored" data-anchor-id="potential-benefits">Potential Benefits</h2>
<ul>
<li><strong>Scalability</strong>: Dokku has features that could allow us to scale our applications based on demand.</li>
<li><strong>Ease of Deployment</strong>: Dokku’s git-based deployment system might simplify the process of deploying new versions of our applications.</li>
<li><strong>Resource Management</strong>: Dokku’s use of Docker containers could lead to more efficient use of system resources.</li>
</ul>
</section>
<section id="potential-drawbacks" class="level2">
<h2 class="anchored" data-anchor-id="potential-drawbacks">Potential Drawbacks</h2>
<ul>
<li>There might be a learning curve for the team members who are not familiar with Dokku or Docker.</li>
<li>Migration of existing services to a new platform could require significant time and resources.</li>
</ul>
</section>
<section id="option-graveyard" class="level2">
<h2 class="anchored" data-anchor-id="option-graveyard">Option Graveyard</h2>
<p>Other options considered include traditional VM-based hosting and other PaaS solutions like Heroku or AWS Elastic Beanstalk. These options have their own sets of advantages and disadvantages that need to be weighed against those of Dokku.</p>
</section>
<section id="if-this-enhancement-will-be-used-infrequently-can-it-be-worked-around-with-a-few-lines-of-script" class="level2">
<h2 class="anchored" data-anchor-id="if-this-enhancement-will-be-used-infrequently-can-it-be-worked-around-with-a-few-lines-of-script">If this enhancement will be used infrequently, can it be worked around with a few lines of script?</h2>
<p>This depends on the specific requirements of our backend services. If the enhancement is fundamental to the hosting and development of our backend services, it may not be possible to work around it with a few lines of script.</p>
</section>
<section id="is-there-a-reason-why-this-should-be-core-and-done-by-us" class="level2">
<h2 class="anchored" data-anchor-id="is-there-a-reason-why-this-should-be-core-and-done-by-us">Is there a reason why this should be core and done by us?</h2>
<p>The choice of hosting and development environment is crucial for the efficiency and effectiveness of our operations. Whether Dokku or another solution is chosen, it will be important for us to maintain control over this aspect of our infrastructure.</p>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<ul>
<li><a href="https://v-sekai.org/">V-Sekai</a></li>
<li><a href="http://dokku.viewdocs.io/dokku/">Dokku Documentation</a></li>
</ul>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20230804-dokku.html</guid>
  <pubDate>Sun, 06 Aug 2023 22:12:37 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20230803-subrepo-addon-management.html</link>
  <description><![CDATA[ 



<section id="git-subrepo-addon-management" class="level1">
<h1>Git Subrepo Addon Management</h1>
<section id="context-and-problem-statement" class="level2">
<h2 class="anchored" data-anchor-id="context-and-problem-statement">Context and Problem Statement</h2>
<p>We are currently managing separate repositories for each addon in the V-Sekai game. This has led to difficulties in synchronizing updates and maintaining consistency across different components of the project.</p>
</section>
<section id="proposed-solution" class="level2">
<h2 class="anchored" data-anchor-id="proposed-solution">Proposed Solution</h2>
<p>We propose to continue maintaining separate repositories for each addon, but use Git subrepo to merge them into the main V-Sekai game repository. This would result in the following structure:</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb1-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">v-sekai-game</span></span>
<span id="cb1-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">│</span></span>
<span id="cb1-3"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">└───addons</span></span>
<span id="cb1-4">    <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">│</span></span>
<span id="cb1-5">    <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">├───vrm</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">(</span><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">from</span> godot-vrm/only-addon<span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">)</span></span>
<span id="cb1-6">    <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">│</span></span>
<span id="cb1-7">    <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">└───Godot-MToon-Shader</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">(</span><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">from</span> Godot-MToon-Shader<span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">)</span></span></code></pre></div>
<p>This way, all addons will be part of the main game repository but can still be managed independently.</p>
</section>
<section id="implementation" class="level2">
<h2 class="anchored" data-anchor-id="implementation">Implementation</h2>
<p>The implementation will involve the following steps:</p>
<ol type="1">
<li>Changes are made in the respective addon repositories.</li>
<li>These changes are then merged into the main V-Sekai game repository using Git subrepo.</li>
</ol>
<p>This ensures that the addons remain up-to-date with their respective repositories.</p>
</section>
<section id="positive-consequences" class="level2">
<h2 class="anchored" data-anchor-id="positive-consequences">Positive Consequences</h2>
<ul>
<li>Streamlined workflow for managing addons.</li>
<li>Easier synchronization of updates across different components of the project.</li>
<li>Reduced complexity in project management.</li>
</ul>
</section>
<section id="negative-consequences" class="level2">
<h2 class="anchored" data-anchor-id="negative-consequences">Negative Consequences</h2>
<ul>
<li>Initial setup may require some time and effort.</li>
<li>Developers will need to adapt to the new workflow.</li>
</ul>
</section>
<section id="option-graveyard" class="level2">
<h2 class="anchored" data-anchor-id="option-graveyard">Option graveyard</h2>
<p>Previously, we considered maintaining separate repositories for each addon without using Git subrepo. However, this approach was discarded due to the difficulties in synchronizing updates and maintaining consistency across different components of the project.</p>
</section>
<section id="if-this-enhancement-will-be-used-infrequently-can-it-be-worked-around-with-a-few-lines-of-script" class="level2">
<h2 class="anchored" data-anchor-id="if-this-enhancement-will-be-used-infrequently-can-it-be-worked-around-with-a-few-lines-of-script">If this enhancement will be used infrequently, can it be worked around with a few lines of script?</h2>
<p>No, this enhancement is fundamental to the project structure and cannot be worked around with a few lines of script.</p>
</section>
<section id="is-there-a-reason-why-this-should-be-core-and-done-by-us" class="level2">
<h2 class="anchored" data-anchor-id="is-there-a-reason-why-this-should-be-core-and-done-by-us">Is there a reason why this should be core and done by us?</h2>
<p>Yes, this change affects the core structure of our project and should therefore be implemented by us to ensure consistency and control over the project.</p>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<ul>
<li><a href="https://v-sekai.org/">V-Sekai</a></li>
</ul>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20230803-subrepo-addon-management.html</guid>
  <pubDate>Sun, 06 Aug 2023 22:12:37 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20230803-publish-vrm-to-assetlibrary.html</link>
  <description><![CDATA[ 



<section id="completing-vrm-1.0-support-and-publishing-to-godot-engine-asset-library" class="level1">
<h1>Completing VRM 1.0 Support and Publishing to Godot Engine Asset Library</h1>
<section id="metadata" class="level2">
<h2 class="anchored" data-anchor-id="metadata">Metadata</h2>
<ul>
<li>Status: Proposed</li>
<li>Deciders: V-Sekai, lyuma, fire</li>
<li>Tags: VRM, Avatars, VRM 1.0, Export, Godot Engine</li>
</ul>
</section>
<section id="context-and-problem-statement" class="level2">
<h2 class="anchored" data-anchor-id="context-and-problem-statement">Context and Problem Statement</h2>
<p>We currently support an older revision of the VRM standard for avatars. However, VRM 1.0 is a new revision that we need to implement. A key feature of this new revision is the ability to export VRM 1.0 files. Additionally, we also need to publish our implementation to the Godot Engine asset library.</p>
</section>
<section id="proposed-solution" class="level2">
<h2 class="anchored" data-anchor-id="proposed-solution">Proposed Solution</h2>
<section id="steps" class="level3">
<h3 class="anchored" data-anchor-id="steps">Steps</h3>
<ol type="1">
<li>Analyze the current implementation of the VRM standard in our system.</li>
<li>Understand the changes and enhancements introduced in VRM 1.0.</li>
<li>Plan the implementation of VRM 1.0 support, including the export feature.</li>
<li>Implement the planned features and changes.</li>
<li>Test the newly implemented VRM 1.0 support in different scenarios.</li>
<li>Prepare the implementation for publishing to the Godot Engine asset library.</li>
<li>Publish the implementation to the Godot Engine asset library.</li>
</ol>
</section>
</section>
<section id="implementation" class="level2">
<h2 class="anchored" data-anchor-id="implementation">Implementation</h2>
<p>The implementation details will be decided upon acceptance of this proposal.</p>
</section>
<section id="positive-consequences" class="level2">
<h2 class="anchored" data-anchor-id="positive-consequences">Positive Consequences</h2>
<ul>
<li>Enhanced avatar functionality with VRM 1.0 support.</li>
<li>Ability to export VRM 1.0 files, increasing compatibility with other systems.</li>
<li>Staying up-to-date with the latest standards in the industry.</li>
<li>Increased visibility and usage through publishing to the Godot Engine asset library.</li>
</ul>
</section>
<section id="negative-consequences" class="level2">
<h2 class="anchored" data-anchor-id="negative-consequences">Negative Consequences</h2>
<ul>
<li>Requires understanding of the new VRM 1.0 standard.</li>
<li>Potential increase in development time due to the complexity of implementing a new standard and preparing it for publishing.</li>
<li>Need to maintain the published asset in the Godot Engine asset library.</li>
</ul>
</section>
<section id="option-graveyard" class="level2">
<h2 class="anchored" data-anchor-id="option-graveyard">Option Graveyard</h2>
<p>This section will be filled as we explore different options and discard those that are not feasible or effective.</p>
</section>
<section id="if-this-enhancement-will-be-used-infrequently-can-it-be-worked-around-with-a-few-lines-of-script" class="level2">
<h2 class="anchored" data-anchor-id="if-this-enhancement-will-be-used-infrequently-can-it-be-worked-around-with-a-few-lines-of-script">If this enhancement will be used infrequently, can it be worked around with a few lines of script?</h2>
<p>Given the complexity of implementing a new standard like VRM 1.0 and publishing it to the Godot Engine asset library, it cannot be simply worked around with a few lines of script.</p>
</section>
<section id="is-there-a-reason-why-this-should-be-core-and-done-by-us" class="level2">
<h2 class="anchored" data-anchor-id="is-there-a-reason-why-this-should-be-core-and-done-by-us">Is there a reason why this should be core and done by us?</h2>
<p>Implementing VRM 1.0 support and publishing it to the Godot Engine asset library is crucial for staying competitive and relevant in the industry. It also aligns with our goal of providing the best possible avatar functionalities to our users.</p>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<ul>
<li><a href="https://vrm.dev/en/vrm1/">VRM 1.0 Specification</a></li>
</ul>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20230803-publish-vrm-to-assetlibrary.html</guid>
  <pubDate>Sun, 06 Aug 2023 22:12:37 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20230803-jolt-gextension-to-module.html</link>
  <description><![CDATA[ 



<section id="port-godot-jolt-from-gdextension-to-c-module" class="level1">
<h1>Port Godot Jolt from GDExtension to C++ Module</h1>
<section id="metadata" class="level2">
<h2 class="anchored" data-anchor-id="metadata">Metadata</h2>
<ul>
<li>Status: Proposed</li>
<li>Deciders: v-sekai, fire</li>
<li>Tags: Godot, Jolt, GDExtension, C++ Module, SCons, CMake</li>
</ul>
</section>
<section id="context-and-problem-statement" class="level2">
<h2 class="anchored" data-anchor-id="context-and-problem-statement">Context and Problem Statement</h2>
<p>Godot Jolt is currently implemented as a GDExtension C++ extension. However, we want to use it as a C++ module, which requires porting from CMake to SCons. This change will also allow us to experiment with soft physics.</p>
</section>
<section id="proposed-solution" class="level2">
<h2 class="anchored" data-anchor-id="proposed-solution">Proposed Solution</h2>
<section id="steps" class="level3">
<h3 class="anchored" data-anchor-id="steps">Steps</h3>
<ol type="1">
<li>Analyze the current structure of Godot Jolt as a GDExtension.</li>
<li>Plan the new structure as a C++ module.</li>
<li>Convert the build system from CMake to SCons.</li>
<li>Test the newly created C++ module in different scenarios.</li>
<li>Experiment with soft physics once the module is stable.</li>
</ol>
</section>
</section>
<section id="implementation" class="level2">
<h2 class="anchored" data-anchor-id="implementation">Implementation</h2>
<p>The implementation details will be decided upon acceptance of this proposal.</p>
</section>
<section id="positive-consequences" class="level2">
<h2 class="anchored" data-anchor-id="positive-consequences">Positive Consequences</h2>
<ul>
<li>More control over the engine’s core functionality.</li>
<li>Ability to experiment with soft physics.</li>
<li>Better integration with Godot’s core systems.</li>
<li>Enable double precision support</li>
</ul>
</section>
<section id="negative-consequences" class="level2">
<h2 class="anchored" data-anchor-id="negative-consequences">Negative Consequences</h2>
<ul>
<li>Requires knowledge of both CMake and SCons.</li>
<li>Potential increase in development time due to the complexity of porting.</li>
</ul>
</section>
<section id="option-graveyard" class="level2">
<h2 class="anchored" data-anchor-id="option-graveyard">Option Graveyard</h2>
<p>This section will be filled as we explore different options and discard those that are not feasible or effective.</p>
</section>
<section id="if-this-enhancement-will-be-used-infrequently-can-it-be-worked-around-with-a-few-lines-of-script" class="level2">
<h2 class="anchored" data-anchor-id="if-this-enhancement-will-be-used-infrequently-can-it-be-worked-around-with-a-few-lines-of-script">If this enhancement will be used infrequently, can it be worked around with a few lines of script?</h2>
<p>Given the complexity of porting a GDExtension to a C++ module, it cannot be simply worked around with a few lines of script.</p>
</section>
<section id="is-there-a-reason-why-this-should-be-core-and-done-by-us" class="level2">
<h2 class="anchored" data-anchor-id="is-there-a-reason-why-this-should-be-core-and-done-by-us">Is there a reason why this should be core and done by us?</h2>
<p>Porting Godot Jolt to a C++ module will provide more flexibility and control over its functionalities. It aligns with our goal of enhancing the capabilities of our game engine.</p>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<ul>
<li><a href="https://godotengine.org/">Godot Engine</a></li>
<li><a href="https://scons.org/">SCons</a></li>
<li><a href="https://cmake.org/">CMake</a></li>
</ul>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20230803-jolt-gextension-to-module.html</guid>
  <pubDate>Sun, 06 Aug 2023 22:12:37 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20230803-idle-rpg-home.html</link>
  <description><![CDATA[ 



<section id="social-rpg-world-proposal" class="level1">
<h1>Social RPG World Proposal</h1>
<section id="metadata" class="level2">
<h2 class="anchored" data-anchor-id="metadata">Metadata</h2>
<ul>
<li>Status: Proposed</li>
<li>Deciders: V-Sekai</li>
<li>Tags: V-Sekai</li>
</ul>
</section>
<section id="context-and-problem-statement" class="level2">
<h2 class="anchored" data-anchor-id="context-and-problem-statement">Context and Problem Statement</h2>
<p>We aim to engage users in the V-Sekai world. A social RPG game could be the solution, offering continuous gameplay that encourages interaction.</p>
</section>
<section id="proposed-solution" class="level2">
<h2 class="anchored" data-anchor-id="proposed-solution">Proposed Solution</h2>
<section id="setting" class="level3">
<h3 class="anchored" data-anchor-id="setting">Setting</h3>
<p>Our game is set in a “Comfortable Cyberprep” realm. It merges sci-fi with ease, where tech and humans coexist. Players explore a future city where technology is part of life. The city glows with neon lights, holographic interfaces, and advanced AI, yet retains homeliness.</p>
<ol type="1">
<li>Static couch collider: A fixed location for player interaction.</li>
<li><strong>Non-functional</strong> Static bed without collider: A rejuvenation spot for characters.</li>
<li><strong>Non-functional</strong> Mirror that is off: A decorative element with potential uses.</li>
<li><strong>Non-functional</strong> Video player screen that is off: A feature for entertainment or information.</li>
</ol>
</section>
<section id="story" class="level3">
<h3 class="anchored" data-anchor-id="story">Story</h3>
<ol type="1">
<li>Chill and hang with friends: The game provides a relaxed environment for socializing.</li>
<li>Play a game: Beyond socializing, players can engage in an RPG game.</li>
</ol>
</section>
<section id="systems" class="level3">
<h3 class="anchored" data-anchor-id="systems">Systems</h3>
<ol type="1">
<li>RPG game with level rewards: Players improve through play.</li>
<li>Combat System: Players choose between different types of weapons or defensive items.</li>
<li>Stationary Target Combat System: A mechanism where players engage in combat with fixed-position targets.</li>
</ol>
</section>
<section id="development-limits" class="level3">
<h3 class="anchored" data-anchor-id="development-limits">Development Limits</h3>
<ol type="1">
<li>Settings are not persisted past server restart.</li>
<li>Limited number of weapon choices: To maintain balance.</li>
<li>Cooldown period for using healing items: To prevent spamming.</li>
</ol>
</section>
</section>
<section id="implementation" class="level2">
<h2 class="anchored" data-anchor-id="implementation">Implementation</h2>
<p>Implementation details will be decided upon proposal acceptance.</p>
</section>
<section id="positive-consequences" class="level2">
<h2 class="anchored" data-anchor-id="positive-consequences">Positive Consequences</h2>
<ul>
<li>Increased user engagement</li>
<li>Prolonged interaction within the V-Sekai world</li>
<li>Enhanced socialization among players</li>
</ul>
</section>
<section id="negative-consequences" class="level2">
<h2 class="anchored" data-anchor-id="negative-consequences">Negative Consequences</h2>
<ul>
<li>Potential increase in development time and resources</li>
<li>Risk of unbalanced gameplay if the RPG system is not properly designed</li>
</ul>
</section>
<section id="option-graveyard" class="level2">
<h2 class="anchored" data-anchor-id="option-graveyard">Option Graveyard</h2>
<p>Options considered but discarded:</p>
<ul>
<li><strong>Idle RPG Mechanic</strong>: Removed due to potential decrease in active engagement from players.</li>
</ul>
</section>
<section id="if-this-enhancement-will-be-used-infrequently-can-it-be-worked-around-with-a-few-lines-of-script" class="level2">
<h2 class="anchored" data-anchor-id="if-this-enhancement-will-be-used-infrequently-can-it-be-worked-around-with-a-few-lines-of-script">If this enhancement will be used infrequently, can it be worked around with a few lines of script?</h2>
<p>The frequency of use depends on the players’ engagement level. However, given the complexity of an RPG system, it cannot be simply worked around with a few lines of script.</p>
</section>
<section id="is-there-a-reason-why-this-should-be-core-and-done-by-us" class="level2">
<h2 class="anchored" data-anchor-id="is-there-a-reason-why-this-should-be-core-and-done-by-us">Is there a reason why this should be core and done by us?</h2>
<p>Creating an RPG system as a feature of V-Sekai will enhance the overall user experience and engagement, which aligns with our goal of providing a compelling virtual world.</p>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<ul>
<li><a href="https://v-sekai.org/">V-Sekai</a></li>
</ul>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20230803-idle-rpg-home.html</guid>
  <pubDate>Sun, 06 Aug 2023 22:12:37 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20230726-solve-renik-directly-rather-than-many-bone-ik.html</link>
  <description><![CDATA[ 



<section id="solve-renik-directly-rather-than-through-many-bone-ik" class="level1">
<h1>Solve Renik directly rather than through many bone ik</h1>
<section id="metadata" class="level2">
<h2 class="anchored" data-anchor-id="metadata">Metadata</h2>
<ul>
<li>Status: proposed</li>
<li>Deciders: V-Sekai</li>
<li>Tags: V-Sekai</li>
</ul>
</section>
<section id="context-and-problem-statement" class="level2">
<h2 class="anchored" data-anchor-id="context-and-problem-statement">Context and Problem Statement</h2>
<p>We want a robust character controller through V-Sekai renik, but we’re working on an abstract many bone ik and there wasn’t visible progress. The current approach is not yielding the desired results and is proving to be inefficient.</p>
</section>
<section id="proposed-solution" class="level2">
<h2 class="anchored" data-anchor-id="proposed-solution">Proposed Solution</h2>
<p>Pause many bone ik and update renik to use many bone ik technologies. This would involve refactoring the existing codebase to integrate the many bone ik technologies directly into the renik solution.</p>
</section>
<section id="implementation" class="level2">
<h2 class="anchored" data-anchor-id="implementation">Implementation</h2>
<p>To be determined.</p>
</section>
<section id="positive-consequences" class="level2">
<h2 class="anchored" data-anchor-id="positive-consequences">Positive Consequences</h2>
<ul>
<li>More efficient and direct solution for character control.</li>
<li>Better utilization of many bone ik technologies.</li>
<li>Potential for improved performance and responsiveness in the final product.</li>
</ul>
</section>
<section id="negative-consequences" class="level2">
<h2 class="anchored" data-anchor-id="negative-consequences">Negative Consequences</h2>
<ul>
<li>Requires significant refactoring of the existing codebase.</li>
<li>Potential for introducing new bugs during the integration process.</li>
<li>May require additional resources and time to implement correctly.</li>
</ul>
</section>
<section id="option-graveyard" class="level2">
<h2 class="anchored" data-anchor-id="option-graveyard">Option graveyard</h2>
<p>This section is reserved for documenting past decisions and their outcomes.</p>
</section>
<section id="if-this-enhancement-will-be-used-infrequently-can-it-be-worked-around-with-a-few-lines-of-script" class="level2">
<h2 class="anchored" data-anchor-id="if-this-enhancement-will-be-used-infrequently-can-it-be-worked-around-with-a-few-lines-of-script">If this enhancement will be used infrequently, can it be worked around with a few lines of script?</h2>
<p>No, this enhancement involves a fundamental change in how the character controller is implemented and cannot be achieved with a simple script workaround.</p>
</section>
<section id="is-there-a-reason-why-this-should-be-core-and-done-by-us" class="level2">
<h2 class="anchored" data-anchor-id="is-there-a-reason-why-this-should-be-core-and-done-by-us">Is there a reason why this should be core and done by us?</h2>
<p>Yes, as the creators of the system, we have the best understanding of its architecture and potential improvements. Outsourcing or relying on external contributions may not align with our vision for the project.</p>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<ul>
<li><a href="https://v-sekai.org/">V-Sekai</a></li>
</ul>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20230726-solve-renik-directly-rather-than-many-bone-ik.html</guid>
  <pubDate>Sun, 06 Aug 2023 22:12:37 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20230719-pose-kusudama-constraints-in-vr.html</link>
  <description><![CDATA[ 



<section id="enhancing-the-many-bone-ik-configuration" class="level1">
<h1>Enhancing the Many Bone IK Configuration</h1>
<section id="metadata" class="level2">
<h2 class="anchored" data-anchor-id="metadata">Metadata</h2>
<ul>
<li>Status: proposed</li>
<li>Deciders: V-Sekai</li>
<li>Tags: V-Sekai, VR, Game Development</li>
</ul>
</section>
<section id="context-and-problem-statement" class="level2">
<h2 class="anchored" data-anchor-id="context-and-problem-statement">Context and Problem Statement</h2>
<p>We have identified a limitation in the V-Sekai platform where there are too many variables to pose the kusudama constraints on the desktop. We propose to overcome this limitation by introducing a VR mode.</p>
</section>
<section id="proposed-solution" class="level2">
<h2 class="anchored" data-anchor-id="proposed-solution">Proposed Solution</h2>
<p>Our solution involves creating a VR mode specifically for posing Many Bone IK kusudama constraints. The steps for implementation are as follows:</p>
<ol type="1">
<li>Take an off the shelf VR controller.</li>
<li>Take an off the shelf multiplayer functionality.</li>
<li>Develop a tool selection ui. Collaborate with guillefix.</li>
<li>Adjust the kusudama constraint attributes to match posing.</li>
<li>Save attributes.</li>
</ol>
<section id="definition-of-a-kusudama" class="level3">
<h3 class="anchored" data-anchor-id="definition-of-a-kusudama">Definition of a Kusudama</h3>
<p>Imagine you have a ball. There are two ways you can move it:</p>
<ol type="1">
<li><strong>Twist</strong>: Like spinning a globe on its stand.</li>
<li><strong>Swing</strong>: Like moving your finger from one spot to another on the ball.</li>
</ol>
<p>Think of a Kusudama (a type of origami that forms a sphere) as an example for the swing movement. The pieces of paper move just like your finger would on the ball.</p>
</section>
</section>
<section id="implementation" class="level2">
<h2 class="anchored" data-anchor-id="implementation">Implementation</h2>
<ol type="1">
<li>Investigate Saracen’s VR networking prototype.</li>
<li>Rebuild character posing without tracking the physical sensors</li>
<li>Apply Many Bone IK tracking</li>
<li>Rotation swing (10x Vector4)</li>
<li>Rotation twist (From and range)</li>
<li>Adjust for quality</li>
<li>Complete configuration</li>
</ol>
<p>Assigning physical sensors to IK points is non-goal.</p>
</section>
<section id="option-graveyard" class="level2">
<h2 class="anchored" data-anchor-id="option-graveyard">Option Graveyard</h2>
<ol type="1">
<li><p><strong>Desktop Mode Enhancement:</strong> Initially, we considered enhancing the desktop mode to handle the kusudama constraints better. However, this option was discarded due to the inherent limitations of the desktop interface for such complex interactions.</p></li>
<li><p><strong>Use of External Tools:</strong> Another option was to use external tools or plugins specifically designed for handling Many Bone IK kusudama constraints. This option was rejected because it would require users to learn and manage additional software, which could lead to a fragmented user experience.</p></li>
<li><p><strong>Simplified Kusudama Constraints:</strong> We also thought about simplifying the kusudama constraints to make them more manageable on the desktop. But this option was discarded as it would limit the capabilities and flexibility that our platform currently offers.</p></li>
<li><p><strong>Automated Posing:</strong> An automated system for posing the kusudama constraints was also considered. However, this option was rejected because it would take away control from the users, potentially leading to less satisfactory results.</p></li>
<li><p><strong>Tutorials and Guides:</strong> Providing extensive tutorials and guides to help users navigate the complexity of posing kusudama constraints on the desktop was another option. This was discarded because it doesn’t address the core issue - the difficulty of managing these constraints on a desktop interface.</p></li>
</ol>
</section>
<section id="negative-consequences" class="level2">
<h2 class="anchored" data-anchor-id="negative-consequences">Negative Consequences</h2>
<ul>
<li>Increased complexity in game development.</li>
<li>Potential need for more resources (time, manpower, etc.) for implementation and testing.</li>
</ul>
</section>
<section id="option-graveyard-1" class="level2">
<h2 class="anchored" data-anchor-id="option-graveyard-1">Option graveyard</h2>
<p>This section is reserved for options considered but rejected.</p>
</section>
<section id="if-this-enhancement-will-be-used-infrequently-can-it-be-worked-around-with-a-few-lines-of-script" class="level2">
<h2 class="anchored" data-anchor-id="if-this-enhancement-will-be-used-infrequently-can-it-be-worked-around-with-a-few-lines-of-script">If this enhancement will be used infrequently, can it be worked around with a few lines of script?</h2>
<p>Posing the avatar is the first interaction a user has when entering our virtual world, V-Sekai. This underlines the necessity of investing in this enhancement to ensure a seamless and engaging user experience right from their first interaction with our platform.</p>
</section>
<section id="is-there-a-reason-why-this-should-be-core-and-done-by-us" class="level2">
<h2 class="anchored" data-anchor-id="is-there-a-reason-why-this-should-be-core-and-done-by-us">Is there a reason why this should be core and done by us?</h2>
<p>Pose quality is crucial to us. As the creators of V-Sekai, we have an unparalleled understanding of our platform’s limitations and potential improvements. This insight puts us in a unique position to enhance the pose quality in a way that aligns with our users’ needs and expectations. Therefore, it is essential that we undertake this enhancement.</p>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<ul>
<li><a href="https://v-sekai.org/">V-Sekai</a></li>
</ul>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20230719-pose-kusudama-constraints-in-vr.html</guid>
  <pubDate>Sun, 06 Aug 2023 22:12:37 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20230719-dual-databases-cockroachdb-khepri.html</link>
  <description><![CDATA[ 



<section id="game-simulation-server-sidekick-process" class="level1">
<h1>Game simulation server sidekick process</h1>
<section id="metadata" class="level2">
<h2 class="anchored" data-anchor-id="metadata">Metadata</h2>
<ul>
<li>Status: proposed</li>
<li>Deciders: V-Sekai</li>
<li>Tags: V-Sekai, Godot Engine, khepri, elixir</li>
</ul>
</section>
<section id="context-and-problem-statement" class="level2">
<h2 class="anchored" data-anchor-id="context-and-problem-statement">Context and Problem Statement</h2>
<p>We want to provide each game server a sidekick process that restarts Godot Engine on crash and acts as a local processor before upload to the source of truth backend database. This will ensure continuous gameplay and data integrity.</p>
</section>
<section id="proposed-solution" class="level2">
<h2 class="anchored" data-anchor-id="proposed-solution">Proposed Solution</h2>
<p>We propose to use khepri for sidekick server data with an elixir frontend.</p>
<p>Khepri provides robustness and reliability while Elixir offers scalability and fault-tolerance.</p>
</section>
<section id="implementation" class="level2">
<h2 class="anchored" data-anchor-id="implementation">Implementation</h2>
<ol type="1">
<li>Develop a sidekick process using khepri that monitors the Godot Engine.</li>
<li>In case of a crash, the sidekick process should be able to restart the Godot Engine.</li>
<li>The sidekick process should also act as a local processor for game data before it’s uploaded to the backend database.</li>
<li>Implement an Elixir frontend to interact with the sidekick process.</li>
</ol>
</section>
<section id="positive-consequences" class="level2">
<h2 class="anchored" data-anchor-id="positive-consequences">Positive Consequences</h2>
<ul>
<li>Improved game server stability.</li>
<li>Continuous gameplay even in the event of a crash.</li>
<li>Ensured data integrity before upload to the backend database.</li>
</ul>
</section>
<section id="negative-consequences" class="level2">
<h2 class="anchored" data-anchor-id="negative-consequences">Negative Consequences</h2>
<ul>
<li>Additional development time and resources required.</li>
<li>Potential complexity in managing the sidekick process.</li>
</ul>
</section>
<section id="option-graveyard" class="level2">
<h2 class="anchored" data-anchor-id="option-graveyard">Option graveyard</h2>
<ol type="1">
<li><p><strong>Using a simple watchdog script:</strong> A simple script that monitors the Godot Engine and restarts it in case of a crash. This was rejected due to its inability to act as a local processor for game data before upload.</p></li>
<li><p><strong>Relying on third-party services:</strong> There are several third-party services that offer process monitoring and automatic restarts. However, these were rejected due to potential issues with customization, cost, and data privacy.</p></li>
<li><p><strong>Building a custom solution from scratch:</strong> While this would give us the most control, it was deemed too resource-intensive and unnecessary given the existence of suitable tools like khepri and Elixir.</p></li>
<li><p><strong>Do nothing:</strong> The option to maintain the status quo was considered but ultimately rejected due to the negative impact on user experience and data integrity.</p></li>
</ol>
</section>
<section id="if-this-enhancement-will-be-used-infrequently-can-it-be-worked-around-with-a-few-lines-of-script" class="level2">
<h2 class="anchored" data-anchor-id="if-this-enhancement-will-be-used-infrequently-can-it-be-worked-around-with-a-few-lines-of-script">If this enhancement will be used infrequently, can it be worked around with a few lines of script?</h2>
<p>No, this enhancement is fundamental to the stability of the game servers and cannot be achieved with a simple script workaround.</p>
</section>
<section id="is-there-a-reason-why-this-should-be-core-and-done-by-us" class="level2">
<h2 class="anchored" data-anchor-id="is-there-a-reason-why-this-should-be-core-and-done-by-us">Is there a reason why this should be core and done by us?</h2>
<p>Yes, as this directly impacts the user experience and the integrity of our game data, it is crucial that we have full control over its implementation and maintenance.</p>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<ul>
<li><a href="https://v-sekai.org/">V-Sekai</a> <!-- - This article [is / or is not] assisted by AI. --></li>
</ul>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20230719-dual-databases-cockroachdb-khepri.html</guid>
  <pubDate>Sun, 06 Aug 2023 22:12:37 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20230716-enhancing-avatar-creation-process-02-advanced.html</link>
  <description><![CDATA[ 



<section id="enhancing-avatar-creation-process-in-v-sekai-advanced" class="level1">
<h1>Enhancing Avatar Creation Process in V-Sekai Advanced</h1>
<section id="metadata" class="level2">
<h2 class="anchored" data-anchor-id="metadata">Metadata</h2>
<ul>
<li>Status: proposed</li>
<li>Deciders: V-Sekai</li>
<li>Tags: V-Sekai</li>
</ul>
</section>
<section id="context-and-problem-statement" class="level2">
<h2 class="anchored" data-anchor-id="context-and-problem-statement">Context and Problem Statement</h2>
<p>V-Sekai currently has limitations when it comes to creating avatars with specific features and customizations. This can be a hindrance for users who want to have more control over the appearance of their avatars. To address this, we propose an enhancement that introduces various tools and techniques to overcome these limitations and provide a more comprehensive avatar creation process.</p>
</section>
<section id="proposed-solution" class="level2">
<h2 class="anchored" data-anchor-id="proposed-solution">Proposed Solution</h2>
<p>Here is a list of raw processes to be broken down.</p>
<section id="to-create-a-source-filter-sink-pipeline-system-for-this-project-we-can-use-the-following-mime-labels" class="level3">
<h3 class="anchored" data-anchor-id="to-create-a-source-filter-sink-pipeline-system-for-this-project-we-can-use-the-following-mime-labels">To create a source, filter, sink pipeline system for this project, we can use the following mime labels:</h3>
<ol type="1">
<li><p>Source: The source will provide the initial avatar model and any additional assets required. The input mime type for the source could be <code>application/gltf+json</code> or <code>model/gltf+json</code> if the avatar is in GLTF format, or <code>image/png</code> or <code>image/svg+xml</code> if the avatar is provided as a 2D image.</p></li>
<li><p>Filter: The filter will handle all the customization steps mentioned above. It will take the input from the source and apply the necessary modifications to create the desired avatar. The input mime type for the filter would be the same as the output mime type of the source, depending on whether the avatar is in GLTF format or represented as an image.</p></li>
<li><p>Sink: The sink will receive the customized avatar from the filter and store it as the final output. For this project, the sink should support both PNG and SVG images for 2D avatars, and GLTF for 3D avatars. Therefore, the output mime types for the sink would be <code>image/png</code> or <code>image/svg+xml</code> for 2D avatars, and <code>application/gltf+json</code> or <code>model/gltf+json</code> for 3D avatars.</p></li>
</ol>
<p>Note: To avoid lossy formats, we are using PNG or SVG for 2D images and GLTF for 3D formats. PNG and SVG are lossless image formats, while GLTF is a lossless 3D format that preserves the fidelity of the avatar model.</p>
</section>
<section id="advanced-customization-steps" class="level3">
<h3 class="anchored" data-anchor-id="advanced-customization-steps">Advanced Customization Steps:</h3>
<p>Here are the converted inputs and outputs in the xstate format for each step:</p>
<ol type="1">
<li><strong>Importing the avatar into Godot Engine and “Project Mirage”:</strong>
<ul>
<li>Input: <code>.vrm</code> file</li>
<li>Output: <code>.vrm</code> file</li>
</ul></li>
<li><strong>Refining the imported avatar:</strong>
<ul>
<li>Input: <code>.vrm</code> file</li>
<li>Output: <code>.vrm</code> file</li>
</ul></li>
<li><strong>Converting spring bone to physical simulation bones and colliders:</strong>
<ul>
<li>Input: <code>.vrm</code> file</li>
<li>Output: assetpackage file</li>
</ul></li>
<li><strong>Addressing painting errors:</strong>
<ul>
<li>Input: <code>.vrm</code> file</li>
<li>Output: <code>.vrm</code> file</li>
</ul></li>
<li><strong>Choosing a material:</strong>
<ul>
<li>Input: <code>.vrm</code> file</li>
<li>Output: <code>.vrm</code> file</li>
</ul></li>
<li><strong>Resolving issues with materials and bones:</strong>
<ul>
<li>Input: <code>.vrm</code> file</li>
<li>Output: <code>.vrm</code> file</li>
</ul></li>
<li><strong>Correcting colors and addressing pleated folds:</strong>
<ul>
<li>Input: <code>.vrm</code> file</li>
<li>Output: <code>.vrm</code> file</li>
</ul></li>
<li><strong>Creating complex geometric structures:</strong>
<ul>
<li>Input: <code>.vrm</code> file</li>
<li>Output: <code>.vrm</code> file</li>
</ul></li>
<li><strong>Utilizing Vroid Hub’s hair painter and mesh generator:</strong></li>
</ol>
<ul>
<li>Input: <code>.vrm</code> file</li>
<li>Output: <code>.vrm</code> enhanced data</li>
</ul>
<ol start="11" type="1">
<li><strong>Adding facial expressions for motion capture:</strong></li>
</ol>
<ul>
<li>Input: <code>.vrm</code> file</li>
<li>Output: <code>.gltf</code> motion capture data</li>
</ul>
<ol start="12" type="1">
<li><strong>Setting up motion capture:</strong></li>
</ol>
<ul>
<li>Input: <code>.vrm</code> file</li>
<li>Output: vrm animations data stored as <code>.gltf</code>.</li>
</ul>
</section>
</section>
<section id="positive-consequences" class="level2">
<h2 class="anchored" data-anchor-id="positive-consequences">Positive Consequences</h2>
<ul>
<li>Users will be able to create highly customizable avatars with specific features.</li>
<li>The avatar creation process will be enhanced with a variety of tools and techniques.</li>
<li>Detailed customization of colors, clothing, accessories, and facial expressions will be possible.</li>
<li>Motion capture capabilities can be integrated for more realistic animations.</li>
</ul>
</section>
<section id="negative-consequences" class="level2">
<h2 class="anchored" data-anchor-id="negative-consequences">Negative Consequences</h2>
<ul>
<li>The implementation process is complex and may require advanced technical skills from users.</li>
<li>Some steps, like creating a 3D model of the back of the avatar, may not always be successful.</li>
<li>Painting errors and other imperfections may remain in the final avatar.</li>
</ul>
</section>
<section id="option-graveyard" class="level2">
<h2 class="anchored" data-anchor-id="option-graveyard">Option graveyard</h2>
<ul>
<li>Excessive complexity or technical requirements: We want the avatar creation process to be user-friendly and accessible to a wide range of users, so any options that require advanced technical skills or have excessively complex customization controls will not be included.</li>
</ul>
</section>
<section id="if-this-enhancement-will-be-used-infrequently-can-it-be-worked-around-with-a-few-lines-of-script" class="level2">
<h2 class="anchored" data-anchor-id="if-this-enhancement-will-be-used-infrequently-can-it-be-worked-around-with-a-few-lines-of-script">If this enhancement will be used infrequently, can it be worked around with a few lines of script?</h2>
<p>No, the proposed enhancement involves a multi-step process that cannot be easily replicated with just a few lines of script.</p>
</section>
<section id="is-there-a-reason-why-this-should-be-core-and-done-by-us" class="level2">
<h2 class="anchored" data-anchor-id="is-there-a-reason-why-this-should-be-core-and-done-by-us">Is there a reason why this should be core and done by us?</h2>
<p>The proposed enhancement addresses the limitations in V-Sekai’s avatar creation process, providing users with a comprehensive solution for creating highly customizable avatars. By implementing these tools and techniques within the platform, V-Sekai can offer a more robust and user-friendly experience for its community.</p>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<ul>
<li><a href="https://v-sekai.org/">V-Sekai</a></li>
</ul>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20230716-enhancing-avatar-creation-process-02-advanced.html</guid>
  <pubDate>Sun, 06 Aug 2023 22:12:37 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20230716-enhancing-avatar-creation-process-01-regular.html</link>
  <description><![CDATA[ 



<section id="enhancing-avatar-creation-process-in-v-sekai-regular" class="level1">
<h1>Enhancing Avatar Creation Process in V-Sekai Regular</h1>
<section id="metadata" class="level2">
<h2 class="anchored" data-anchor-id="metadata">Metadata</h2>
<ul>
<li>Status: proposed</li>
<li>Deciders: V-Sekai</li>
<li>Tags: V-Sekai</li>
</ul>
</section>
<section id="context-and-problem-statement" class="level2">
<h2 class="anchored" data-anchor-id="context-and-problem-statement">Context and Problem Statement</h2>
<p>V-Sekai currently has limitations when it comes to creating avatars with specific features and customizations. This can be a hindrance for users who want to have more control over the appearance of their avatars. To address this, we propose an enhancement that introduces various tools and techniques to overcome these limitations and provide a more comprehensive avatar creation process.</p>
</section>
<section id="proposed-solution" class="level2">
<h2 class="anchored" data-anchor-id="proposed-solution">Proposed Solution</h2>
<p>Here is a list of raw processes to be broken down.</p>
<section id="avatar-creation-steps" class="level3">
<h3 class="anchored" data-anchor-id="avatar-creation-steps">Avatar Creation Steps:</h3>
<p>To implement the requested changes, here are the modified instructions:</p>
<ol type="1">
<li><strong>Creating the avatar face:</strong> Utilizes digital drawing techniques to design and create the facial features of the avatar.
<ul>
<li>Input mime type: None</li>
<li>Output mime type: Digital drawing/image file (e.g., PNG, SVG)</li>
</ul></li>
<li><strong>Changing colors:</strong> Utilizes a digital paintbrush tool like Penpot to modify and customize the colors of the avatar.
<ul>
<li>Input mime type: Digital drawing/image file (e.g., PNG, SVG)</li>
<li>Output mime type: Digital drawing/image file (e.g., PNG, SVG)</li>
</ul></li>
<li><strong>Selecting the best-looking avatars:</strong> Evaluates and chooses the most visually appealing avatars from a pool of options.
<ul>
<li>Input mime type: Digital drawing/image file (e.g., PNG, SVG)</li>
<li>Output mime type: Digital drawing/image file (e.g., PNG, SVG)</li>
</ul></li>
<li><strong>Removing the background image:</strong> Removes the background image to make rework easier. May provide worse results with edge details.
<ul>
<li>Input mime type: Digital drawing/image file (e.g., PNG, SVG)</li>
<li>Output mime type: Digital drawing/image file (e.g., PNG, SVG)</li>
</ul></li>
<li><strong>Adding a body:</strong> Incorporates a body to the avatar using Blender’s CC0 base mesh or a similar tool.
<ul>
<li>Input mime type: Digital drawing/image file (e.g., PNG, SVG)</li>
<li>Output mime type: Digital drawing/image file (e.g., PNG, SVG)</li>
</ul></li>
<li><strong>Creating a 3D model of the back of the avatar:</strong> If feasible, attempts to create a 3D model of the back of the avatar for a more comprehensive representation.
<ul>
<li>Input mime type: Digital drawing/image file (e.g., PNG, SVG)</li>
<li>Output mime type: Digital drawing/image file (e.g., PNG, SVG)</li>
</ul></li>
<li><strong>Simplifying images:</strong> Uses a tool to simplify and refine the entire avatar image as a whole, removing any unnecessary image details or complexities.
<ul>
<li>Input mime type: Digital drawing/image file (e.g., PNG, SVG)</li>
<li>Output mime type: Digital drawing/image file (e.g., PNG, SVG)</li>
</ul></li>
<li><strong>Adding clothing and accessories:</strong> Enhances the avatar by adding clothing and accessories using tools like Vroid Hub.
<ul>
<li>Input mime type: Digital drawing/image file (e.g., PNG, SVG)</li>
<li>Output mime type: Digital drawing/image file (e.g., PNG, SVG)</li>
</ul></li>
<li><strong>Placing the 2D image as a reference:</strong> Positions the 2D reference image in front of the 3D model to serve as a visual guide during customization.
<ul>
<li>Input mime type: Digital drawing/image file (e.g., PNG, SVG), 3D model file (e.g., GLTF)</li>
<li>Output mime type: 3D model file (e.g., GLTF), Digital image file (e.g., PNG, SVG)</li>
</ul></li>
<li><strong>Capturing and enhancing images:</strong> Captures images from various angles using a camera and enhances them to improve the overall quality.</li>
</ol>
<ul>
<li>Input mime type: Digital drawing/image file (e.g., PNG, SVG)</li>
<li>Output mime type: Digital image file (e.g., PNG, SVG)</li>
</ul>
<ol start="11" type="1">
<li><strong>Generating text captions:</strong> Creates descriptive text captions for the captured images to provide additional context or information.</li>
</ol>
<ul>
<li>Input mime type: Digital image file (e.g., PNG, SVG)</li>
<li>Output mime type: Text file (e.g., TXT)</li>
</ul>
<ol start="12" type="1">
<li><strong>Using a 2D reference image in Blender:</strong> Uses a 2D reference image within Blender to guide the customization process.</li>
</ol>
<ul>
<li>Input mime type: Digital drawing/image file (e.g., PNG, SVG)</li>
<li>Output mime type: 3D model file (e.g., GLTF), Digital image file (e.g., PNG, SVG)</li>
</ul>
</section>
</section>
<section id="positive-consequences" class="level2">
<h2 class="anchored" data-anchor-id="positive-consequences">Positive Consequences</h2>
<ul>
<li>Users will be able to create highly customizable avatars with specific features.</li>
<li>The avatar creation process will be enhanced with a variety of tools and techniques.</li>
<li>Detailed customization of colors, clothing, accessories, and facial expressions will be possible.</li>
<li>Motion capture capabilities can be integrated for more realistic animations.</li>
</ul>
</section>
<section id="negative-consequences" class="level2">
<h2 class="anchored" data-anchor-id="negative-consequences">Negative Consequences</h2>
<ul>
<li>The implementation process is complex and may require advanced technical skills from users.</li>
<li>Some steps, like creating a 3D model of the back of the avatar, may not always be successful.</li>
<li>Painting errors and other imperfections may remain in the final avatar.</li>
</ul>
</section>
<section id="option-graveyard" class="level2">
<h2 class="anchored" data-anchor-id="option-graveyard">Option graveyard</h2>
<ul>
<li>Excessive complexity or technical requirements: We want the avatar creation process to be user-friendly and accessible to a wide range of users, so any options that require advanced technical skills or have excessively complex customization controls will not be included.</li>
</ul>
</section>
<section id="if-this-enhancement-will-be-used-infrequently-can-it-be-worked-around-with-a-few-lines-of-script" class="level2">
<h2 class="anchored" data-anchor-id="if-this-enhancement-will-be-used-infrequently-can-it-be-worked-around-with-a-few-lines-of-script">If this enhancement will be used infrequently, can it be worked around with a few lines of script?</h2>
<p>No, the proposed enhancement involves a multi-step process that cannot be easily replicated with just a few lines of script.</p>
</section>
<section id="is-there-a-reason-why-this-should-be-core-and-done-by-us" class="level2">
<h2 class="anchored" data-anchor-id="is-there-a-reason-why-this-should-be-core-and-done-by-us">Is there a reason why this should be core and done by us?</h2>
<p>The proposed enhancement addresses the limitations in V-Sekai’s avatar creation process, providing users with a comprehensive solution for creating highly customizable avatars. By implementing these tools and techniques within the platform, V-Sekai can offer a more robust and user-friendly experience for its community.</p>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<ul>
<li><a href="https://v-sekai.org/">V-Sekai</a></li>
<li><a href="https://civitai.com/models/58390/detail-tweaker-lora-lora">Detail Tweaker</a></li>
<li><a href="https://github.com/gfodor/instructblip-replicate">InstructBLIP: Towards General-purpose Vision-Language Models with Instruction Tuning</a></li>
<li><a href="https://github.com/bigscience-workshop/petals">Petals</a></li>
</ul>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20230716-enhancing-avatar-creation-process-01-regular.html</guid>
  <pubDate>Sun, 06 Aug 2023 22:12:37 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20230701-vsekai-broken-down-goals.html</link>
  <description><![CDATA[ 



<section id="v-sekai-feature-enhancement-proposal" class="level1">
<h1>V-Sekai Feature Enhancement Proposal</h1>
<section id="metadata" class="level2">
<h2 class="anchored" data-anchor-id="metadata">Metadata</h2>
<ul>
<li><strong>Status</strong>: Proposed</li>
<li><strong>Deciders</strong>: V-Sekai</li>
<li><strong>Tags</strong>: V-Sekai, ai summarized</li>
</ul>
</section>
<section id="context-and-problem-statement" class="level2">
<h2 class="anchored" data-anchor-id="context-and-problem-statement">Context and Problem Statement</h2>
<p>We are developing a virtual reality platform, V-Sekai. To ensure the platform meets user needs and expectations, we have identified several features that need to be implemented. These features have been categorized based on their priority and necessity for the initial release.</p>
</section>
<section id="proposed-solution" class="level2">
<h2 class="anchored" data-anchor-id="proposed-solution">Proposed Solution</h2>
<p>The features have been organized into three categories: Must-Have, Nice-to-Have, and Out of Scope Initially. The priority within each category reflects the relative importance of the features for an initial release.</p>
<section id="must-have-features" class="level3">
<h3 class="anchored" data-anchor-id="must-have-features">Must-Have Features</h3>
<table class="table">
<colgroup>
<col style="width: 32%">
<col style="width: 25%">
<col style="width: 41%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">Priority</th>
<th style="text-align: left;">Feature</th>
<th style="text-align: left;">Dependencies</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">1</td>
<td style="text-align: left;">Environment (scene loading, world hosting, instancing)</td>
<td style="text-align: left;">None</td>
</tr>
<tr class="even">
<td style="text-align: center;">2</td>
<td style="text-align: left;">Web requests to servers (HTTP/WebSocket API)</td>
<td style="text-align: left;">Environment</td>
</tr>
<tr class="odd">
<td style="text-align: center;">3</td>
<td style="text-align: left;">Person to person interaction (avatars, animation, synchronization)</td>
<td style="text-align: left;">Environment</td>
</tr>
<tr class="even">
<td style="text-align: center;">4</td>
<td style="text-align: left;">Interaction with the world (interactive elements, physics)</td>
<td style="text-align: left;">Environment</td>
</tr>
</tbody>
</table>
</section>
<section id="nice-to-have-features" class="level3">
<h3 class="anchored" data-anchor-id="nice-to-have-features">Nice-to-Have Features</h3>
<table class="table">
<colgroup>
<col style="width: 32%">
<col style="width: 25%">
<col style="width: 41%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">Priority</th>
<th style="text-align: left;">Feature</th>
<th style="text-align: left;">Dependencies</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">5</td>
<td style="text-align: left;">Collaboration features (doodling, modeling, content loading)</td>
<td style="text-align: left;">Environment, Person to person interaction</td>
</tr>
<tr class="even">
<td style="text-align: center;">6</td>
<td style="text-align: left;">Static content creation in editor (import avatars, create worlds)</td>
<td style="text-align: left;">Environment</td>
</tr>
<tr class="odd">
<td style="text-align: center;">7</td>
<td style="text-align: left;">Shareable content (inventory)</td>
<td style="text-align: left;">Environment, Static content creation in editor</td>
</tr>
<tr class="even">
<td style="text-align: center;">8</td>
<td style="text-align: left;">Local API for extending platform</td>
<td style="text-align: left;">Environment, Web requests to servers</td>
</tr>
<tr class="odd">
<td style="text-align: center;">9</td>
<td style="text-align: left;">Video playback</td>
<td style="text-align: left;">Environment</td>
</tr>
<tr class="even">
<td style="text-align: center;">10</td>
<td style="text-align: left;">Support for proprietary video hosting</td>
<td style="text-align: left;">Video playback</td>
</tr>
</tbody>
</table>
</section>
<section id="out-of-scope-initially" class="level3">
<h3 class="anchored" data-anchor-id="out-of-scope-initially">Out of Scope Initially</h3>
<table class="table">
<colgroup>
<col style="width: 32%">
<col style="width: 25%">
<col style="width: 41%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">Priority</th>
<th style="text-align: left;">Feature</th>
<th style="text-align: left;">Dependencies</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">11</td>
<td style="text-align: left;">Text chat</td>
<td style="text-align: left;">Environment, Person to person interaction</td>
</tr>
<tr class="even">
<td style="text-align: center;">12</td>
<td style="text-align: left;">Screen sharing (OBS)</td>
<td style="text-align: left;">Environment, Person to person interaction</td>
</tr>
<tr class="odd">
<td style="text-align: center;">13</td>
<td style="text-align: left;">Modeling and 3D Creation (Blender)</td>
<td style="text-align: left;">Environment, Static content creation in editor</td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="implementation" class="level2">
<h2 class="anchored" data-anchor-id="implementation">Implementation</h2>
<p>The implementation details will be determined once the proposal is accepted and the features are finalized.</p>
</section>
<section id="positive-consequences" class="level2">
<h2 class="anchored" data-anchor-id="positive-consequences">Positive Consequences</h2>
<ul>
<li>A well-structured and prioritized feature list will guide development efforts.</li>
<li>Clear categorization helps manage stakeholder expectations about what will be included in the initial release.</li>
</ul>
</section>
<section id="negative-consequences" class="level2">
<h2 class="anchored" data-anchor-id="negative-consequences">Negative Consequences</h2>
<ul>
<li>Some features may require more time and resources than initially estimated.</li>
<li>Stakeholders may have different opinions on the priority of certain features.</li>
</ul>
</section>
<section id="option-graveyard" class="level2">
<h2 class="anchored" data-anchor-id="option-graveyard">Option Graveyard</h2>
<p>This section will include any options considered but ultimately rejected during the decision-making process.</p>
</section>
<section id="if-this-enhancement-will-be-used-infrequently-can-it-be-worked-around-with-a-few-lines-of-script" class="level2">
<h2 class="anchored" data-anchor-id="if-this-enhancement-will-be-used-infrequently-can-it-be-worked-around-with-a-few-lines-of-script">If this enhancement will be used infrequently, can it be worked around with a few lines of script?</h2>
<p>This question will be addressed during the implementation phase for each feature.</p>
</section>
<section id="is-there-a-reason-why-this-should-be-core-and-done-by-us" class="level2">
<h2 class="anchored" data-anchor-id="is-there-a-reason-why-this-should-be-core-and-done-by-us">Is there a reason why this should be core and done by us?</h2>
<p>As these features form the core functionality of the V-Sekai platform, they should be developed by our team to ensure quality and consistency.</p>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<ul>
<li><a href="https://v-sekai.org/">V-Sekai</a></li>
</ul>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20230701-vsekai-broken-down-goals.html</guid>
  <pubDate>Sun, 06 Aug 2023 22:12:37 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20230630-vsekai-goal-meeting.html</link>
  <description><![CDATA[ 



<section id="v-sekai-meeting---friday-june-30-2023" class="level1">
<h1>V-Sekai Meeting - Friday, June 30, 2023</h1>
<p>Original pad (90 day expiration): https://pad.sfconservancy.org/p/v-sekai-goals-meet-2023-06-30.md /timeslider#937</p>
<section id="context-and-problem-statement" class="level2">
<h2 class="anchored" data-anchor-id="context-and-problem-statement">Context and Problem Statement</h2>
<p>Meeting goal: determine what we can feasibly build and what we can enable others to build.</p>
</section>
<section id="principles" class="level2">
<h2 class="anchored" data-anchor-id="principles">Principles</h2>
<ul>
<li>Optimally piggybacking on systems others have built / are maintaining.</li>
<li>Build things we would want to use</li>
</ul>
</section>
<section id="foundational-runtime-features-provided-by-the-platform" class="level2">
<h2 class="anchored" data-anchor-id="foundational-runtime-features-provided-by-the-platform">Foundational Runtime Features (Provided by the Platform)</h2>
<section id="environment" class="level3">
<h3 class="anchored" data-anchor-id="environment">Environment</h3>
<ul>
<li>Scene loading support</li>
<li>World hosting (network protocol)</li>
<li>Instancing: Holepunching (users host?) and relay system and Multi-instance server system?</li>
</ul>
</section>
<section id="person-to-person-interaction" class="level3">
<h3 class="anchored" data-anchor-id="person-to-person-interaction">Person to person interaction</h3>
<ul>
<li>Avatar support</li>
<li>Avatar animation system</li>
<li>VoIP (voice communication)</li>
<li>IK synchronization and other player / avatar synchronization</li>
<li>Object parenting support (chairs)</li>
</ul>
</section>
<section id="interaction-with-the-world" class="level3">
<h3 class="anchored" data-anchor-id="interaction-with-the-world">Interaction with the World</h3>
<ul>
<li>Interactive elements</li>
<li>Grabbable objects</li>
<li>Buttons</li>
<li>Physics</li>
</ul>
</section>
<section id="additional-features" class="level3">
<h3 class="anchored" data-anchor-id="additional-features">Additional Features</h3>
<ul>
<li>Doodling (with a builtin script to save to a file)</li>
<li>Cameras (take a picture - screenshot?)</li>
<li>Mirrors + camera</li>
<li>Video player (static + playback of videos without a duration aka live) libvlc or ffmpeg</li>
<li>Local API (http OR jsonrpc OR local pipe OR OSC etc.) for Extending the Platform
<ul>
<li>Allow users to write scripts and plugins for V-Sekai</li>
<li>Or allow a local user to write custom GDScript into V-Sekai</li>
<li>API to create an object.</li>
<li>Determine RPCs or functions to expose)</li>
</ul></li>
</ul>
</section>
</section>
<section id="web-requests-http-or-websocket-to-servers" class="level2">
<h2 class="anchored" data-anchor-id="web-requests-http-or-websocket-to-servers">Web Requests (HTTP or WebSocket) to Servers</h2>
<ul>
<li>Needs API or scripting language.</li>
</ul>
</section>
<section id="foundational-static-content-creationsdk-features-in-the-editor" class="level2">
<h2 class="anchored" data-anchor-id="foundational-static-content-creationsdk-features-in-the-editor">Foundational Static Content Creation/SDK Features (in the Editor)</h2>
<ul>
<li>VRM import (avatars)</li>
<li>Godot editor</li>
<li>World creation</li>
<li>Uploading / sharing content items to an inventory.</li>
</ul>
</section>
<section id="features-that-we-can-interface-with-third-parties" class="level2">
<h2 class="anchored" data-anchor-id="features-that-we-can-interface-with-third-parties">Features that We Can interface with Third Parties</h2>
<ul>
<li>Screen sharing (OBS)</li>
<li>Modeling and 3D Creation (Blender)</li>
</ul>
</section>
<section id="features-that-we-can-enable-platform-developers-to-build" class="level2">
<h2 class="anchored" data-anchor-id="features-that-we-can-enable-platform-developers-to-build">Features that We Can Enable Platform Developers to Build</h2>
<ul>
<li>Text chat</li>
<li>Collaboration features / meeting spaces
<ul>
<li>Doodling</li>
<li>3D doodling/modeling tools sketch</li>
<li>Saving and loading of content at runtime</li>
</ul></li>
<li>Support for proprietary video hosting websites</li>
</ul>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<ul>
<li><a href="https://v-sekai.org/">V-Sekai</a></li>
</ul>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20230630-vsekai-goal-meeting.html</guid>
  <pubDate>Sun, 06 Aug 2023 22:12:37 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20230626-godot-vrm1-addon.html</link>
  <description><![CDATA[ 



<section id="ship-godot-engine-vrm1-to-solve-portable-humanoid-avatars" class="level1">
<h1>Ship Godot Engine VRM1 to solve portable humanoid avatars</h1>
<section id="metadata" class="level2">
<h2 class="anchored" data-anchor-id="metadata">Metadata</h2>
<ul>
<li>Status: proposed <!-- draft | proposed | rejected | accepted | deprecated | superseded by --></li>
<li>Deciders: V-Sekai, fire, lyuma</li>
<li>Tags: V-Sekai, ai copilot</li>
</ul>
</section>
<section id="context-and-problem-statement" class="level2">
<h2 class="anchored" data-anchor-id="context-and-problem-statement">Context and Problem Statement</h2>
<p>Have portable humanoid avatars.</p>
</section>
<section id="proposed-solution" class="level2">
<h2 class="anchored" data-anchor-id="proposed-solution">Proposed Solution</h2>
<p>Ship Godot Engine VRM1 to Godot Engine asset Library.</p>
</section>
<section id="implementation" class="level2">
<h2 class="anchored" data-anchor-id="implementation">Implementation</h2>
<ol type="1">
<li>Implement basic humanoid avatar functionality such as rigging, animation, and basic physics through VRM1 spring bones.</li>
<li>Implement support for both MToon1 and MToon0 materials, which provide a physically-based rendering approach for anime-style graphics.</li>
<li>Implement support for the glTF PBR material type, which provides a more physically-based rendering approach for realistic graphics.</li>
<li>Implement facial expressions, eye tracking, and lip syncing for a more immersive experience.</li>
<li>Implement export by copying the import code in reverse, and refine it over time.</li>
<li>Use the VRM spec’s suggested algorithm for implementing first-person view, which eliminates the need for head scaling.</li>
<li>Prioritize necessary features and say no to suggestions that are not necessary to avoid feature bloat.</li>
<li>Do not implement AnimationTree for this proposal.</li>
</ol>
</section>
<section id="positive-consequences" class="level2">
<h2 class="anchored" data-anchor-id="positive-consequences">Positive Consequences</h2>
<ul>
<li>Portable humanoid avatars can be easily created and used in Godot Engine projects.</li>
<li>The addition of MToon1 material support provides a physically-based rendering approach for anime-style graphics.</li>
<li>Facial expressions, eye tracking, and lip syncing enhance the immersive experience for users.</li>
<li>Export functionality allows for easy sharing of avatars between projects and with other users.</li>
<li>The use of the VRM spec’s suggested algorithm for implementing first-person view simplifies the implementation process.</li>
</ul>
</section>
<section id="negative-consequences" class="level2">
<h2 class="anchored" data-anchor-id="negative-consequences">Negative Consequences</h2>
<ul>
<li>The implementation of these features may require additional development time and resources.</li>
<li>The addition of new features may increase the complexity of the codebase and require additional maintenance.</li>
<li>The use of the MToon1 material may require additional GPU resources and may not be suitable for low-end hardware.</li>
<li>The implementation of facial expressions, eye tracking, and lip syncing may require additional hardware or software support.</li>
</ul>
</section>
<section id="option-graveyard" class="level2">
<h2 class="anchored" data-anchor-id="option-graveyard">Option graveyard</h2>
<p>We are not implementing support for other material types beyond MToon0, MToon1 and gltf PBR, which could limit the range of visual styles that can be achieved with Godot Engine.</p>
</section>
<section id="if-this-enhancement-will-be-used-infrequently-can-it-be-worked-around-with-a-few-lines-of-script" class="level2">
<h2 class="anchored" data-anchor-id="if-this-enhancement-will-be-used-infrequently-can-it-be-worked-around-with-a-few-lines-of-script">If this enhancement will be used infrequently, can it be worked around with a few lines of script?</h2>
<p>It is unlikely that these enhancements can be easily worked around with a few lines of script, as they require significant development effort and integration with the Godot Engine codebase.</p>
</section>
<section id="is-there-a-reason-why-this-should-be-core-and-done-by-us" class="level2">
<h2 class="anchored" data-anchor-id="is-there-a-reason-why-this-should-be-core-and-done-by-us">Is there a reason why this should be core and done by us?</h2>
<ul>
<li>Portable humanoid avatars are a key feature for many Godot Engine projects, and the ability to easily create and use them is important for the success of the engine.</li>
<li>The addition of MToon1 material support and other enhancements will improve the quality and visual fidelity of Godot Engine projects.</li>
<li>By implementing these features in-house, we can ensure that they are well-integrated with the Godot Engine codebase and meet our quality standards.</li>
</ul>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<ul>
<li><a href="https://v-sekai.org/">V-Sekai</a></li>
<li>https://github.com/vrm-c/vrm-specification</li>
<li>https://github.com/vrm-c/vrm-specification/blob/master/specification/VRMC_vrm-1.0/firstPerson.md#meshannotationauto-algorithm</li>
</ul>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20230626-godot-vrm1-addon.html</guid>
  <pubDate>Sun, 06 Aug 2023 22:12:37 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20230624-v-sekai-roadmap.html</link>
  <description><![CDATA[ 



<section id="v-sekai-roadmap-and-goals-2023-06-24" class="level1">
<h1>V-Sekai Roadmap and Goals 2023-06-24</h1>
<section id="metadata" class="level3">
<h3 class="anchored" data-anchor-id="metadata">Metadata</h3>
<ul>
<li>Status: accepted</li>
<li>Deciders: V-Sekai, fire</li>
<li>Tags: V-Sekai, chatgpt4 summary,</li>
</ul>
</section>
<section id="context-and-problem-statement" class="level3">
<h3 class="anchored" data-anchor-id="context-and-problem-statement">Context and Problem Statement</h3>
<p>What is the V-Sekai Roadmap and Goals?</p>
</section>
<section id="describe-the-proposed-option-and-how-it-helps-to-overcome-the-problem-or-limitation" class="level3">
<h3 class="anchored" data-anchor-id="describe-the-proposed-option-and-how-it-helps-to-overcome-the-problem-or-limitation">Describe the proposed option and how it helps to overcome the problem or limitation</h3>
<p>The roadmap presented here is short-term.</p>
</section>
<section id="describe-how-your-proposal-will-work-with-code-pseudo-code-mock-ups-or-diagrams" class="level3">
<h3 class="anchored" data-anchor-id="describe-how-your-proposal-will-work-with-code-pseudo-code-mock-ups-or-diagrams">Describe how your proposal will work with code, pseudo-code, mock-ups, or diagrams</h3>
<p>By avoiding work on User Generated Content (UGC) and world building, we can prioritize the three main states in the roadmap: “World / Avatar Performance” (WAP), “Networking” (NET), and “UI/UX”. This allows the team to focus on the core aspects of V-Sekai and achieve the goals more efficiently.</p>
<ol type="1">
<li><strong>Monitoring and Logging System Test</strong>:
<ol type="1">
<li>Setup logging framework</li>
<li>Configure monitoring system</li>
<li>Create a dashboard</li>
</ol></li>
<li><strong>Test Environment with Simulated Data Test</strong>:
<ol type="1">
<li>Create test scenarios</li>
<li>Generate simulated data</li>
<li>Configure test environment</li>
<li>Execute test scenarios</li>
<li>Analyze test results</li>
</ol></li>
</ol>
</section>
<section id="positive-consequences" class="level3">
<h3 class="anchored" data-anchor-id="positive-consequences">Positive Consequences</h3>
<ul>
<li>Easier creation of V-Sekai.</li>
<li>Focused development on core aspects.</li>
</ul>
</section>
<section id="negative-consequences" class="level3">
<h3 class="anchored" data-anchor-id="negative-consequences">Negative Consequences</h3>
<ul>
<li>Potential overhead challenges.</li>
</ul>
</section>
<section id="option-graveyard" class="level3">
<h3 class="anchored" data-anchor-id="option-graveyard">Option graveyard</h3>
<ul>
<li>Waiting for Godot Engine 4.2 instead of assisting with 4.1 features.</li>
</ul>
</section>
<section id="if-this-enhancement-will-be-used-infrequently-can-it-be-worked-around-with-a-few-lines-of-script" class="level3">
<h3 class="anchored" data-anchor-id="if-this-enhancement-will-be-used-infrequently-can-it-be-worked-around-with-a-few-lines-of-script">If this enhancement will be used infrequently, can it be worked around with a few lines of script?</h3>
<p>No.&nbsp;This is a process.</p>
</section>
<section id="is-there-a-reason-why-this-should-be-core-and-done-by-us" class="level3">
<h3 class="anchored" data-anchor-id="is-there-a-reason-why-this-should-be-core-and-done-by-us">Is there a reason why this should be core and done by us?</h3>
<p>This is a core process for V-Sekai.</p>
</section>
<section id="references" class="level3">
<h3 class="anchored" data-anchor-id="references">References</h3>
<ul>
<li><a href="https://v-sekai.org/">V-Sekai</a></li>
</ul>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20230624-v-sekai-roadmap.html</guid>
  <pubDate>Sun, 06 Aug 2023 22:12:37 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20230623-fdn-reverb-solution.html</link>
  <description><![CDATA[ 



<section id="implementing-feedback-delay-networks-for-enhanced-audio-reverb-simulation-in-v-sekai" class="level1">
<h1>Implementing Feedback Delay Networks for Enhanced Audio Reverb Simulation in V-Sekai</h1>
<section id="metadata" class="level2">
<h2 class="anchored" data-anchor-id="metadata">Metadata</h2>
<ul>
<li>Status: proposed</li>
<li>Deciders: V-Sekai, ellenhp, fire</li>
<li>Tags: V-Sekai, ai assisted</li>
</ul>
</section>
<section id="context-and-problem-statement" class="level2">
<h2 class="anchored" data-anchor-id="context-and-problem-statement">Context and Problem Statement</h2>
<p>The problem of simulating audio reverb in Godot Engine 4 involves accurately modeling the way sound waves propagate, reflect, and interact within a given environment. This requires sampling a chaotic 7-dimensional space every frame, either through precomputation or real-time processing. The complexity arises from the fact that sound behaves more like light with intense diffraction, making it impossible to rasterize.</p>
</section>
<section id="proposed-solution" class="level2">
<h2 class="anchored" data-anchor-id="proposed-solution">Proposed Solution</h2>
<p>Implement Feedback Delay Networks (FDNs) for artificial reverberation. FDNs consist of multiple delay lines connected in a feedback loop with a mixing matrix. The output is a combination of the input signal and the delayed signals.</p>
<section id="steps" class="level3">
<h3 class="anchored" data-anchor-id="steps">Steps:</h3>
<ol type="1">
<li>Choose the number of delay lines and their lengths based on the desired reverberation time and room characteristics.</li>
<li>Implement a mixing matrix to control the energy distribution between the delay lines.</li>
<li>Create a feedback loop by connecting the outputs of the delay lines to the inputs through the mixing matrix.</li>
<li>Combine the input signal with the delayed signals to produce the reverberated output.</li>
</ol>
</section>
</section>
<section id="implementation" class="level2">
<h2 class="anchored" data-anchor-id="implementation">Implementation</h2>
<pre class="gdscript"><code>class_name FDN
extends Node

var num_delay_lines : int
var delay_lines : Array
var mixing_matrix : Array
var room_characteristics : Dictionary

func _init(num_delay_lines: int, delay_lengths: Array, mixing_matrix: Array, room_characteristics: Dictionary):
    self.num_delay_lines = num_delay_lines
    self.delay_lines = []
    for length in delay_lengths:
        self.delay_lines.append(DelayLine.new(length))
    self.mixing_matrix = mixing_matrix
    self.room_characteristics = room_characteristics

func process(input_signal: float) -&gt; float:
    # Step 1: Calculate the output of each delay line
    var delay_outputs = []
    for dl in self.delay_lines:
        delay_outputs.append(dl.process(input_signal))

    # Step 2: Apply the room characteristics to the delay line outputs
    var processed_outputs = apply_room_characteristics(delay_outputs)

    # Step 3: Apply the mixing matrix to the processed delay line outputs
    var mixed_outputs = apply_mixing_matrix(processed_outputs)

    # Step 4: Update the delay lines with the mixed outputs
    for i in range(self.num_delay_lines):
        self.delay_lines[i].update(mixed_outputs[i])

    # Step 5: Combine the input signal with the delayed signals
    var output_signal = input_signal + sum(mixed_outputs)
    return output_signal

func apply_room_characteristics(delay_outputs: Array) -&gt; Array:
    var processed_outputs = []
    for i in range(len(delay_outputs)):
        processed_output = delay_outputs[i] * room_characteristics["absorption"][i]
        processed_outputs.append(processed_output)
    return processed_outputs

func apply_mixing_matrix(delay_outputs: Array) -&gt; Array:
    # TODO: Implement the mixing matrix application logic
    pass</code></pre>
</section>
<section id="positive-consequences" class="level2">
<h2 class="anchored" data-anchor-id="positive-consequences">Positive Consequences</h2>
<ul>
<li>Improved audio reverb simulation</li>
<li>More realistic sound propagation and interaction within environments</li>
<li>Smarter estimation of long reverb times</li>
</ul>
</section>
<section id="negative-consequences" class="level2">
<h2 class="anchored" data-anchor-id="negative-consequences">Negative Consequences</h2>
<ul>
<li>Increased computational complexity</li>
<li>Potential performance impact on real-time processing</li>
</ul>
</section>
<section id="option-graveyard" class="level2">
<h2 class="anchored" data-anchor-id="option-graveyard">Option graveyard</h2>
<ul>
<li>Generalized Dijkstra Pathfinding</li>
<li>DWN (Digital Waveguide Network): A method for simulating audio reverb by modeling sound propagation as waves traveling along waveguides with bidirectional delay lines and scattering junctions.</li>
<li>Ray tracing can be used to simulate sound propagation in 3D environments. It involves casting rays from the sound source and tracing their paths as they interact with the environment (reflect, refract, and diffract). By calculating the time delay and attenuation of each ray reaching the listener, you can generate an impulse response that represents the acoustic properties of the space.</li>
<li>Convolution reverb is a technique that uses recorded impulse responses (IRs) of real spaces or digital simulations to recreate the reverberation characteristics of those spaces. The process involves convolving the dry audio signal with the impulse response to produce the reverberated audio.</li>
</ul>
</section>
<section id="if-this-enhancement-will-be-used-infrequently-can-it-be-worked-around-with-a-few-lines-of-script" class="level2">
<h2 class="anchored" data-anchor-id="if-this-enhancement-will-be-used-infrequently-can-it-be-worked-around-with-a-few-lines-of-script">If this enhancement will be used infrequently, can it be worked around with a few lines of script?</h2>
<p>No, implementing FDNs requires a more complex algorithm and cannot be achieved with just a few lines of script.</p>
</section>
<section id="is-there-a-reason-why-this-should-be-core-and-done-by-us" class="level2">
<h2 class="anchored" data-anchor-id="is-there-a-reason-why-this-should-be-core-and-done-by-us">Is there a reason why this should be core and done by us?</h2>
<p>Yes, as it directly impacts the audio experience within V-Sekai environments, it should be a core feature to ensure consistent and high-quality audio reverb simulation.</p>
</section>
<section id="glossary-implementing-feedback-delay-networks-for-enhanced-audio-reverb-simulation-in-v-sekai" class="level2">
<h2 class="anchored" data-anchor-id="glossary-implementing-feedback-delay-networks-for-enhanced-audio-reverb-simulation-in-v-sekai">Glossary: Implementing Feedback Delay Networks for Enhanced Audio Reverb Simulation in V-Sekai</h2>
<ul>
<li><strong>V-Sekai</strong>: A virtual reality platform that allows users to create and explore immersive environments.</li>
<li><strong>Godot Engine 4</strong>: An open-source game engine used for creating 2D and 3D games and interactive applications.</li>
<li><strong>Audio Reverb</strong>: The persistence of sound in a particular space after the original sound has stopped, caused by reflections off surfaces within the environment.</li>
<li><strong>Feedback Delay Networks (FDNs)</strong>: A method for simulating artificial reverberation using multiple delay lines connected in a feedback loop with a mixing matrix.</li>
<li><strong>Delay Line</strong>: A digital signal processing technique that introduces a time delay to an input signal, often used in audio effects such as reverb and echo.</li>
<li><strong>Mixing Matrix</strong>: A mathematical construct used to control the energy distribution between the delay lines in an FDN.</li>
<li><strong>Room Characteristics</strong>: Acoustic properties of a room or environment, such as absorption, reflection, and diffusion, which affect how sound propagates within the space.</li>
<li><strong>Reverberation Time</strong>: The time it takes for the sound level in a room to decrease by 60 decibels after the sound source has stopped.</li>
<li><strong>Digital Waveguide Network (DWN)</strong>: An alternative method for simulating audio reverb by modeling sound propagation as waves traveling along waveguides with bidirectional delay lines and scattering junctions.</li>
<li><strong>Ray Tracing</strong>: A technique used to simulate sound propagation in 3D environments by casting rays from the sound source and tracing their paths as they interact with the environment (reflect, refract, and diffract).</li>
<li><strong>Convolution Reverb</strong>: A technique that uses recorded impulse responses (IRs) of real spaces or digital simulations to recreate the reverberation characteristics of those spaces by convolving the dry audio signal with the impulse response.</li>
<li><strong>Impulse Response (IR)</strong>: A recording or simulation of the acoustic properties of a space, used in convolution reverb to recreate the reverberation characteristics of that space.</li>
</ul>
</section>
<section id="computational-and-io-complexity-an-example" class="level2">
<h2 class="anchored" data-anchor-id="computational-and-io-complexity-an-example">Computational and I/O Complexity: An Example</h2>
<p>Let’s consider an example of implementing a Feedback Delay Network (FDN) for audio reverb simulation with 8 delay lines. We will analyze the computational and I/O complexity involved in this specific case.</p>
<section id="fdn-reverb-claims-may-need-to-be-verified" class="level3">
<h3 class="anchored" data-anchor-id="fdn-reverb-claims-may-need-to-be-verified">FDN reverb claims may need to be verified</h3>
<ol type="1">
<li>For a medium-quality reverb effect, let’s consider using 8 delay lines in the FDN.</li>
<li>For an 8x8 matrix, there are 64 multiplications and 56 additions required for each sample.</li>
<li>Overall, the computational complexity for a medium-quality reverb effect with 8 delay lines is manageable for most modern CPUs and can be efficiently processed in real-time.</li>
<li>In summary, implementing a medium-quality reverb effect using an FDN with 8 delay lines has a manageable computational and I/O complexity, making it suitable for real-time processing on most modern hardware.</li>
</ol>
</section>
<section id="computational-complexity" class="level3">
<h3 class="anchored" data-anchor-id="computational-complexity">Computational Complexity</h3>
<p>For a medium-quality reverb effect, let’s consider using 8 delay lines in the FDN. The main components contributing to the computational complexity are:</p>
<ol type="1">
<li><p><strong>Delay Lines</strong>: Each delay line requires memory for storing the delayed samples and computations for updating the delay buffer. For 8 delay lines, the complexity scales linearly with the number of delay lines.</p></li>
<li><p><strong>Matrix Mixing</strong>: The mixing matrix combines the outputs of the delay lines in a specific way to create the desired reverb effect. For an 8x8 matrix, there are 64 multiplications and 56 additions required for each sample.</p></li>
<li><p><strong>Feedback and Input/Output Processing</strong>: Additional processing, such as filtering or gain adjustments, may be applied to the input, output, or feedback paths. This complexity depends on the specific filters or processing used but is generally proportional to the number of delay lines.</p></li>
</ol>
<p>Overall, the computational complexity for a medium-quality reverb effect with 8 delay lines is manageable for most modern CPUs and can be efficiently processed in real-time.</p>
</section>
<section id="io-complexity" class="level3">
<h3 class="anchored" data-anchor-id="io-complexity">I/O Complexity</h3>
<p>The I/O complexity refers to the amount of data that needs to be read from and written to memory during the processing of the reverb effect. In the case of an FDN with 8 delay lines, the I/O complexity is mainly determined by:</p>
<ol type="1">
<li><p><strong>Reading and Writing Delay Line Buffers</strong>: Each delay line requires reading and writing operations for updating the delay buffer. The I/O complexity scales linearly with the number of delay lines.</p></li>
<li><p><strong>Input and Output Audio Data</strong>: The audio input data must be read, processed, and combined with the output of the FDN to generate the final reverberated audio signal. The I/O complexity for input and output audio data is generally low compared to the delay line buffer operations.</p></li>
</ol>
<p>In summary, implementing a medium-quality reverb effect using an FDN with 8 delay lines has a manageable computational and I/O complexity, making it suitable for real-time processing on most modern hardware.</p>


</section>
</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20230623-fdn-reverb-solution.html</guid>
  <pubDate>Sun, 06 Aug 2023 22:12:37 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20230620-t5-jsonformer-xstate.html</link>
  <description><![CDATA[ 



<section id="large-language-model-t5-generating-xstate-json-reliabily-for-digital-beings" class="level1">
<h1>Large language model t5 generating xstate json reliabily for digital beings</h1>
<section id="metadata" class="level2">
<h2 class="anchored" data-anchor-id="metadata">Metadata</h2>
<ul>
<li>Status: proposed</li>
<li>Deciders: V-Sekai</li>
<li>Tags: V-Sekai</li>
</ul>
</section>
<section id="context-and-problem-statement" class="level2">
<h2 class="anchored" data-anchor-id="context-and-problem-statement">Context and Problem Statement</h2>
<p>V-Sekai is facing a limitation that requires a solution to convert natural language text into XState JSON format for executing behavior statecharts for digital beings. This can be achieved by using the T5 (Text-to-Text Transfer Transformer) model with JSON-former for XState in Godot Engine 4.0.</p>
</section>
<section id="proposed-solution" class="level2">
<h2 class="anchored" data-anchor-id="proposed-solution">Proposed Solution</h2>
<p>The proposed solution involves using the T5 model to generate text based on input text and then converting the generated text into XState JSON format, all within the Godot Engine 4.0 environment.</p>
</section>
<section id="implementation" class="level2">
<h2 class="anchored" data-anchor-id="implementation">Implementation</h2>
<p>To use T5 (Text-to-Text Transfer Transformer) with JSON-former for XState in Godot Engine 4.0, you’ll need to follow these steps:</p>
<ol type="1">
<li><strong>Load the necessary libraries</strong></li>
</ol>
<pre class="gd"><code>var transformers = preload("res://path/to/transformers.gd")
var torch = preload("res://path/to/torch.gd")</code></pre>
<ol start="2" type="1">
<li><strong>Load the T5 model and tokenizer</strong></li>
</ol>
<pre class="gd"><code>var model_name = "t5-small"
var tokenizer = transformers.load_T5Tokenizer(model_name)
var model = transformers.load_T5ForConditionalGeneration(model_name)</code></pre>
<ol start="3" type="1">
<li><strong>Create a function to generate text using T5</strong></li>
</ol>
<pre class="gd"><code>func generate_text(input_text: String) -&gt; String:
    var input_ids = tokenizer.encode(input_text)
    var outputs = model.generate(input_ids)
    var generated_text = tokenizer.decode(outputs[0])
    return generated_text</code></pre>
<ol start="4" type="1">
<li><strong>Create a function to replace placeholders in T5 output</strong></li>
</ol>
<pre class="gd"><code>func replace_placeholders(text: String) -&gt; String:
    var formatted_text = text.replace("&lt;extra_id_0&gt;", "event").replace("&lt;extra_id_1&gt;", "state")
    return formatted_text</code></pre>
<ol start="5" type="1">
<li><strong>Create a function to parse JSON from formatted text</strong></li>
</ol>
<pre class="gd"><code>func parse_JSON(formatted_text: String) -&gt; Dictionary:
    var json_object = JSON.parse(formatted_text).result
    return json_object</code></pre>
<ol start="6" type="1">
<li><strong>Create a function to convert T5 output to XState JSON format</strong></li>
</ol>
<pre class="gd"><code>func t5_to_jsonformer_xstate(text: String) -&gt; Dictionary:
    var formatted_text = replace_placeholders(text)
    var json_object = parse_JSON(formatted_text)
    return json_object</code></pre>
<ol start="7" type="1">
<li><strong>Use the functions to generate XState JSON</strong></li>
</ol>
<pre class="gd"><code>func _ready():
    var input_text = "your input text here"
    var t5_output = generate_text(input_text)
    var xstate_json = t5_to_jsonformer_xstate(t5_output)
    print(xstate_json)</code></pre>
<p>This will give you the XState JSON format for the given input text. Note that the T5 model might need to be fine-tuned on a dataset specific to your use case to generate accurate XState JSON representations.</p>
</section>
<section id="positive-consequences" class="level2">
<h2 class="anchored" data-anchor-id="positive-consequences">Positive Consequences</h2>
<ul>
<li>Automates the process of converting natural language text into XState JSON format within the Godot Engine 4.0 environment.</li>
<li>Reduces manual effort and potential errors in creating XState JSON representations.</li>
</ul>
</section>
<section id="negative-consequences" class="level2">
<h2 class="anchored" data-anchor-id="negative-consequences">Negative Consequences</h2>
<ul>
<li>The T5 model may require fine-tuning on a specific dataset to generate accurate XState JSON representations.</li>
<li>There might be limitations in understanding complex or ambiguous input text.</li>
</ul>
</section>
<section id="option-graveyard" class="level2">
<h2 class="anchored" data-anchor-id="option-graveyard">Option graveyard</h2>
<p>Here are some option graveyard items for the proposal:</p>
<ol type="1">
<li><p><strong>Using rule-based natural language processing (NLP) techniques</strong></p>
<ul>
<li>Pros:
<ul>
<li>Easier to implement and understand.</li>
<li>No need for training data or fine-tuning.</li>
</ul></li>
<li>Cons:
<ul>
<li>Limited in handling complex or ambiguous input text.</li>
<li>Requires manual updates to rules as new use cases emerge.</li>
</ul></li>
</ul></li>
<li><p><strong>Using other pre-trained NLP models (e.g., GPT-3, BERT)</strong></p>
<ul>
<li>Pros:
<ul>
<li>Can leverage existing state-of-the-art NLP models.</li>
<li>May provide better performance on certain tasks.</li>
</ul></li>
<li>Cons:
<ul>
<li>May require additional fine-tuning or adaptation for the specific task.</li>
<li>Some models may have higher computational requirements or costs.</li>
</ul></li>
</ul></li>
<li><p><strong>Creating a custom NLP model from scratch</strong></p>
<ul>
<li>Pros:
<ul>
<li>Tailored specifically for the task of converting natural language text into XState JSON format.</li>
<li>Potential for better performance if designed well.</li>
</ul></li>
<li>Cons:
<ul>
<li>Requires significant time and effort to develop, train, and maintain.</li>
<li>May not perform as well as existing state-of-the-art models.</li>
</ul></li>
</ul></li>
<li><p><strong>Using an external API or service for natural language understanding</strong></p>
<ul>
<li>Pros:
<ul>
<li>Offloads the complexity of NLP to an external service.</li>
<li>Can potentially leverage more advanced NLP techniques.</li>
</ul></li>
<li>Cons:
<ul>
<li>Introduces dependency on an external service.</li>
<li>May incur additional costs or usage limitations.</li>
</ul></li>
</ul></li>
</ol>
<p>These options were considered but ultimately discarded in favor of using the T5 model with JSON-former for XState in Godot Engine 4.0 due to its balance of performance, ease of implementation, and adaptability to the specific task.</p>
</section>
<section id="if-this-enhancement-will-be-used-infrequently-can-it-be-worked-around-with-a-few-lines-of-script" class="level2">
<h2 class="anchored" data-anchor-id="if-this-enhancement-will-be-used-infrequently-can-it-be-worked-around-with-a-few-lines-of-script">If this enhancement will be used infrequently, can it be worked around with a few lines of script?</h2>
<p>The proposed solution requires more than a few lines of script and involves using a pre-trained model (T5) to generate the desired output within the Godot Engine 4.0 environment.</p>
</section>
<section id="is-there-a-reason-why-this-should-be-core-and-done-by-us" class="level2">
<h2 class="anchored" data-anchor-id="is-there-a-reason-why-this-should-be-core-and-done-by-us">Is there a reason why this should be core and done by us?</h2>
<p>Implementing this solution as part of the core functionality can help V-Sekai users automate the process of generating XState JSON representations from natural language text within the Godot Engine 4.0 environment, improving efficiency and reducing manual effort.</p>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<ul>
<li><a href="https://v-sekai.org/">V-Sekai</a></li>
<li><a href="https://godotengine.org/">Godot Engine</a></li>
<li><a href="https://docs.godotengine.org/en/stable/getting_started/scripting/gdscript/gdscript_basics.html">GDScript documentation</a></li>
<li><a href="https://arxiv.org/abs/1910.10683">T5 (Text-to-Text Transfer Transformer)</a></li>
<li><a href="https://huggingface.co/transformers/">Transformers library</a></li>
<li><a href="https://xstate.js.org/docs/">XState documentation</a></li>
</ul>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20230620-t5-jsonformer-xstate.html</guid>
  <pubDate>Sun, 06 Aug 2023 22:12:37 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20230620-doi-github.html</link>
  <description><![CDATA[ 



<section id="a-potential-solution-for-v-sekais-identifier-assignment-challenge" class="level1">
<h1>A Potential Solution for V-Sekai’s Identifier Assignment Challenge</h1>
<section id="metadata" class="level2">
<h2 class="anchored" data-anchor-id="metadata">Metadata</h2>
<ul>
<li>Status: proposed</li>
<li>Deciders: V-Sekai, fire</li>
<li>Tags: V-Sekai, AI-augmented</li>
</ul>
</section>
<section id="context-and-problem-statement" class="level2">
<h2 class="anchored" data-anchor-id="context-and-problem-statement">Context and Problem Statement</h2>
<p>V-Sekai requires a method to assign permanent Digital Object Identifiers (DOIs) to their digital artifacts.</p>
</section>
<section id="suggested-solution" class="level2">
<h2 class="anchored" data-anchor-id="suggested-solution">Suggested Solution</h2>
<p>Leverage Github and Zenodo to create a permanent DOI for V-Sekai’s data and code.</p>
</section>
<section id="implementation" class="level2">
<h2 class="anchored" data-anchor-id="implementation">Implementation</h2>
<p>Follow these steps in the guide below:</p>
<ol type="1">
<li>Set up a Github Repository</li>
<li>Connect Github to Zenodo</li>
<li>Activate Github Repository in Zenodo</li>
<li>Generate a Release in Github</li>
<li>Obtain Your DOI from Zenodo</li>
<li>Showcase DOI Badge in Github README (optional)</li>
</ol>
</section>
<section id="positive-consequences" class="level2">
<h2 class="anchored" data-anchor-id="positive-consequences">Positive Consequences</h2>
<ul>
<li>Persistent DOIs for data and code</li>
<li>Effortless referencing of repositories across browsers</li>
<li>Enhanced visibility and accessibility of V-Sekai’s digital artifacts</li>
</ul>
</section>
<section id="negative-consequences" class="level2">
<h2 class="anchored" data-anchor-id="negative-consequences">Negative Consequences</h2>
<ul>
<li>Necessitates managing multiple platforms (Github and Zenodo)</li>
<li>Possible learning curve for users unfamiliar with Github and Zenodo</li>
</ul>
</section>
<section id="alternative-options" class="level2">
<h2 class="anchored" data-anchor-id="alternative-options">Alternative Options</h2>
<ol type="1">
<li><p><strong>Utilizing Figshare</strong>: Figshare is an alternative platform that enables assigning DOIs to digital artifacts. However, its integration with Github may not be as smooth as Zenodo’s.</p></li>
<li><p><strong>Manual DOI registration</strong>: Manually registering a DOI through agencies like DataCite or CrossRef. This option can be labor-intensive and might involve additional fees.</p></li>
<li><p><strong>Depending on publisher-assigned DOIs</strong>: Some publishers allocate DOIs to supplementary materials during article publication. However, this option relies on the publisher’s policies and may not encompass all digital artifacts.</p></li>
<li><p><strong>Employing institutional repositories</strong>: Certain institutions provide their own repositories for hosting digital artifacts and assigning DOIs. This option could be constrained by institutional policies and access limitations.</p></li>
<li><p><strong>No DOI</strong>: Opting not to assign a DOI to V-Sekai’s digital artifacts, which would complicate referencing and long-term accessibility.</p></li>
</ol>
</section>
<section id="can-this-enhancement-be-worked-around-with-a-few-lines-of-script-if-used-infrequently" class="level2">
<h2 class="anchored" data-anchor-id="can-this-enhancement-be-worked-around-with-a-few-lines-of-script-if-used-infrequently">Can this enhancement be worked around with a few lines of script if used infrequently?</h2>
<p>No, this solution demands integration between Github and Zenodo to produce a permanent DOI.</p>
</section>
<section id="is-there-a-reason-why-this-should-be-core-and-implemented-by-us" class="level2">
<h2 class="anchored" data-anchor-id="is-there-a-reason-why-this-should-be-core-and-implemented-by-us">Is there a reason why this should be core and implemented by us?</h2>
<p>Yes, allocating a permanent DOI to V-Sekai’s digital artifacts guarantees long-term accessibility and accurate referencing in publications or other materials.</p>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<ul>
<li><a href="https://v-sekai.org/">V-Sekai</a></li>
<li><a href="https://github.com/">Github</a></li>
<li><a href="https://zenodo.org/">Zenodo</a></li>
<li>https://github.com/GlobalEcologyFlinders/assignDOI</li>
</ul>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20230620-doi-github.html</guid>
  <pubDate>Sun, 06 Aug 2023 22:12:37 GMT</pubDate>
</item>
</channel>
</rss>
