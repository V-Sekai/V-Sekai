<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>V-Sekai - Manuals</title>
<link>https://v-sekai.github.io/manuals/decisions.html</link>
<atom:link href="https://v-sekai.github.io/manuals/decisions.xml" rel="self" type="application/rss+xml"/>
<description></description>
<generator>quarto-1.6.39</generator>
<lastBuildDate>Wed, 11 Dec 2024 15:00:09 GMT</lastBuildDate>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/present-proposal-template.html</link>
  <description><![CDATA[ 




<section id="draft-template" class="level1">
<h1>Draft: Template</h1>
<section id="the-context" class="level2">
<h2 class="anchored" data-anchor-id="the-context">The Context</h2>
</section>
<section id="the-problem-statement" class="level2">
<h2 class="anchored" data-anchor-id="the-problem-statement">The Problem Statement</h2>
</section>
<section id="describe-how-your-proposal-will-work-with-code-pseudo-code-mock-ups-or-diagrams" class="level2">
<h2 class="anchored" data-anchor-id="describe-how-your-proposal-will-work-with-code-pseudo-code-mock-ups-or-diagrams">Describe how your proposal will work with code, pseudo-code, mock-ups, or diagrams</h2>
</section>
<section id="the-benefits" class="level2">
<h2 class="anchored" data-anchor-id="the-benefits">The Benefits</h2>
</section>
<section id="the-downsides" class="level2">
<h2 class="anchored" data-anchor-id="the-downsides">The Downsides</h2>
</section>
<section id="the-road-not-taken" class="level2">
<h2 class="anchored" data-anchor-id="the-road-not-taken">The Road Not Taken</h2>
</section>
<section id="the-infrequent-use-case" class="level2">
<h2 class="anchored" data-anchor-id="the-infrequent-use-case">The Infrequent Use Case</h2>
</section>
<section id="why-is-it-in-core-and-done-by-us" class="level2">
<h2 class="anchored" data-anchor-id="why-is-it-in-core-and-done-by-us">Why is it in Core and done by us?</h2>
</section>
<section id="status" class="level2">
<h2 class="anchored" data-anchor-id="status">Status</h2>
<p>Status: Draft <!-- Draft | Proposed | Rejected | Accepted | Deprecated | Superseded by --></p>
</section>
<section id="decision-makers" class="level2">
<h2 class="anchored" data-anchor-id="decision-makers">Decision Makers</h2>
<ul>
<li>V-Sekai development team</li>
</ul>
</section>
<section id="tags" class="level2">
<h2 class="anchored" data-anchor-id="tags">Tags</h2>
<ul>
<li>V-Sekai</li>
</ul>
</section>
<section id="further-reading" class="level2">
<h2 class="anchored" data-anchor-id="further-reading">Further Reading</h2>
<ol type="1">
<li><a href="https://github.com/v-sekai">V-Sekai · GitHub</a> - Official GitHub account for the V-Sekai development community focusing on social VR functionality for the Godot Engine.</li>
<li><a href="https://github.com/v-sekai/v-sekai-game">V-Sekai/v-sekai-game</a> is the GitHub page for the V-Sekai open-source project, which brings social VR/VRSNS/metaverse components to the Godot Engine.</li>
</ol>
<p>AI assistant Aria assisted with this article.</p>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/present-proposal-template.html</guid>
  <pubDate>Wed, 11 Dec 2024 15:00:09 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/ai-assisted-proposal-style-guide.html</link>
  <description><![CDATA[ 




<section id="accepted-ai-assisted-style-guide" class="level1">
<h1>Accepted: AI-Assisted Style Guide</h1>
<section id="the-context" class="level2">
<h2 class="anchored" data-anchor-id="the-context">The Context</h2>
<p>Maintaining a consistent and professional style is crucial in proposal writing. However, the output often needs more stylistic quality when AI assists in this process.</p>
</section>
<section id="the-problem-statement" class="level2">
<h2 class="anchored" data-anchor-id="the-problem-statement">The Problem Statement</h2>
<p>We often need better style and consistent formatting when we instruct AI to help complete our proposals.</p>
</section>
<section id="describe-how-your-proposal-will-work-with-code-pseudo-code-mock-ups-or-diagrams" class="level2">
<h2 class="anchored" data-anchor-id="describe-how-your-proposal-will-work-with-code-pseudo-code-mock-ups-or-diagrams">Describe how your proposal will work with code, pseudo-code, mock-ups, or diagrams</h2>
<ol type="1">
<li><strong>Avoid Purple Speech</strong>: Use clear and concise language, avoiding overly elaborate or flowery expressions.</li>
<li><strong>Be Snappy</strong>: Keep sentences short and concise to maintain reader engagement.</li>
<li><strong>Avoid Coded Phrases</strong>: Refrain from using coded phrases like “effective altruism” since altruism inherently implies effectiveness and not the opposite.</li>
<li><strong>Keep Consistent Headers</strong>: Please be sure to adhere to the header structure provided in the template to ensure consistency across documents.</li>
</ol>
</section>
<section id="the-benefits" class="level2">
<h2 class="anchored" data-anchor-id="the-benefits">The Benefits</h2>
<ul>
<li><strong>Improved Readability</strong>: Clear and concise language enhances the readability of proposals.</li>
<li><strong>Consistency</strong>: Maintaining a consistent style ensures that all documents appear professionally.</li>
<li><strong>Efficiency</strong>: Streamlined guidelines make it easier for AI to generate high-quality content quickly.</li>
</ul>
</section>
<section id="the-downsides" class="level2">
<h2 class="anchored" data-anchor-id="the-downsides">The Downsides</h2>
<ul>
<li><strong>Limited Creativity</strong>: Strict adherence to style guidelines may limit creative expression.</li>
<li><strong>Initial Setup Time</strong>: Establishing and fine-tuning the style guide may require an initial investment of time and resources.</li>
</ul>
</section>
<section id="the-road-not-taken" class="level2">
<h2 class="anchored" data-anchor-id="the-road-not-taken">The Road Not Taken</h2>
<p>Alternative approaches, such as manual editing or using different AI models, were considered but ultimately deemed less efficient or effective.</p>
</section>
<section id="the-infrequent-use-case" class="level2">
<h2 class="anchored" data-anchor-id="the-infrequent-use-case">The Infrequent Use Case</h2>
<p>In scenarios where highly specialized or technical language is required, additional human oversight may be necessary to ensure accuracy and appropriateness.</p>
</section>
<section id="in-core-and-done-by-us" class="level2">
<h2 class="anchored" data-anchor-id="in-core-and-done-by-us">In Core and Done by Us</h2>
<p>This proposal aligns with our core values of efficiency and professionalism and will be implemented by our team.</p>
</section>
<section id="status" class="level2">
<h2 class="anchored" data-anchor-id="status">Status</h2>
<p>Status: Accepted <!-- Draft | Proposed | Rejected | Accepted | Deprecated | Superseded by --></p>
</section>
<section id="decision-makers" class="level2">
<h2 class="anchored" data-anchor-id="decision-makers">Decision Makers</h2>
<ul>
<li>V-Sekai development team</li>
</ul>
</section>
<section id="tags" class="level2">
<h2 class="anchored" data-anchor-id="tags">Tags</h2>
<ul>
<li>V-Sekai</li>
</ul>
</section>
<section id="further-reading" class="level2">
<h2 class="anchored" data-anchor-id="further-reading">Further Reading</h2>
<ol type="1">
<li><a href="https://github.com/v-sekai">V-Sekai · GitHub</a> - Official GitHub account for the V-Sekai development community focusing on social VR functionality for the Godot Engine.</li>
<li><a href="https://github.com/v-sekai/v-sekai-game">V-Sekai/v-sekai-game</a> - GitHub page for the V-Sekai open-source project, which brings social VR/VRSNS/metaverse components to the Godot Engine.</li>
</ol>
<p>AI assistant Aria assisted with this article.</p>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/ai-assisted-proposal-style-guide.html</guid>
  <pubDate>Wed, 11 Dec 2024 15:00:09 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20241210-vsekai-charter.html</link>
  <description><![CDATA[ 




<section id="draft-update-v-sekai-charter-to-2024." class="level1">
<h1>Draft: Update V-Sekai Charter to 2024.</h1>
<section id="the-context" class="level2">
<h2 class="anchored" data-anchor-id="the-context">The Context</h2>
<p>The Mozilla Builders Summer MVP Lab charter was submitted on June 8, 2020.</p>
</section>
<section id="the-problem-statement" class="level2">
<h2 class="anchored" data-anchor-id="the-problem-statement">The Problem Statement</h2>
<p>We want to update our V-Sekai charter to 2024.</p>
</section>
<section id="describe-how-your-proposal-will-work-with-code-pseudo-code-mock-ups-or-diagrams" class="level2">
<h2 class="anchored" data-anchor-id="describe-how-your-proposal-will-work-with-code-pseudo-code-mock-ups-or-diagrams">Describe how your proposal will work with code, pseudo-code, mock-ups, or diagrams</h2>
<p><strong>A one-line summary of the MVP:</strong></p>
<p>A customizable and self-hosted virtual reality environment using Godot Engine.</p>
<p><strong>Description of the product: What will the MVP be in 8 weeks?</strong></p>
<p>In 8 weeks, our virtual reality app will work with all SteamVR-compatible PC headsets and the Meta Quest VR platform. It will have a social hub with 3D voice chat, real-time body tracking, simple games, physics, and social video viewing.</p>
<p><strong>Category:</strong></p>
<ul>
<li>Collaboration &amp; Society</li>
<li>Decentralized Web: YES</li>
<li>Messaging &amp; Social Networking: YES</li>
<li>Surveillance Capitalism</li>
<li>Misinformation &amp; Content</li>
<li>Artificial Intelligence</li>
<li>Web Assembly</li>
</ul>
<p><strong>Why does your idea matter? How will it help deliver on the full promise of the internet or make the internet more awesome?</strong></p>
<p>The Internet is about openness and communication. We see virtual reality as a new way to connect people. With the closure of the High Fidelity platform, we need open-source alternatives to the growing number of closed VR platforms.</p>
<p>We are at a point where VR and related tech are advancing quickly. With better game engines, audio and video codecs, faster internet, and more VR hardware, it’s the right time to develop an open platform.</p>
<p>We believe in giving power back to individuals through decentralized technology. Our goal is to create a polished, well-functioning service and integrate decentralized authentication and encryption, as well as content distribution technologies like BitTorrent and IPFS.</p>
<p><strong>Who are your users or potential users?</strong></p>
<p>We are building this for users of social virtual reality, online collaboration, and communication products. Social VR is growing, and its potential is just starting to be realized.</p>
<p>Even though VR is still new, it has a large potential market, especially with affordable headsets like the Meta Quest. For example, VRChat has between 12,000 and 15,000 concurrent users, with about 4,000 using VR in 2019.</p>
<p><strong>What is your connection to the service &amp; the user group you plan to reach with your product?</strong></p>
<p>We’re a team of VR enthusiasts who work on visual effects, level design, and graphics in our spare time.</p>
<p>In a time when connecting at a distance is important, VR can bring people together in a shared space better than video calls. One of our team members has participated in Virtual Market 4, a growing virtual content marketplace.</p>
<p>Other social VR platforms have allowed us to engage with people worldwide, attend live events, and form friendships. We want to enable these experiences in an open and accessible setting.</p>
<p><strong>Will your team still work on this project if we do not fund it? To what extent?</strong></p>
<p>Without funding, we will continue to work on it in our spare time, but other closed platforms are catching up, and time is crucial.</p>
<p><strong>Why did you pick this idea? Would you happen to have domain expertise? How do you know people need what you’re building?</strong></p>
<p>We see a need for an open alternative to closed VR platforms. Many VR platforms are free now, but there’s no guarantee they will stay that way. Our platform can be self-hosted, used privately, and modified.</p>
<p>Our team has experience in backend operations and working with Godot Engine, which is relevant to building this platform.</p>
<p><strong>Are you looking for any teammates? If so, please indicate what skills or roles you seek.</strong></p>
<p>We have a Discord group, a GitHub repository, and an issues list where we can post about the project and look for teammates.</p>
<p><strong>Could you describe your work plan?</strong></p>
<table class="caption-top table">
<colgroup>
<col style="width: 11%">
<col style="width: 88%">
</colgroup>
<thead>
<tr class="header">
<th>Week</th>
<th>Tasks</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Week 1</strong></td>
<td>- Maintain continuous integration of Windows SteamVR, Meta Quest, and Linux server builds.</td>
</tr>
<tr class="even">
<td></td>
<td>- VOIP implementation: Basic lipsync based on volume, and spatialization library integration.</td>
</tr>
<tr class="odd">
<td></td>
<td>- Improve Inverse Kinematics implementation and add non-VR support.</td>
</tr>
<tr class="even">
<td><strong>Week 2</strong></td>
<td>- Headless clients will stress test the system.</td>
</tr>
<tr class="odd">
<td></td>
<td>- Implement crash reporting system and performance metrics.</td>
</tr>
<tr class="even">
<td></td>
<td>- Content: Use a basic scripting API to implement physics-based games.</td>
</tr>
<tr class="odd">
<td></td>
<td>- Begin work on engine changes for smooth frame rates during content loading.</td>
</tr>
<tr class="even">
<td><strong>Week 3</strong></td>
<td>- Networking interpolation: eliminate stuttering caused by networking.</td>
</tr>
<tr class="odd">
<td></td>
<td>- Godot OpenVR Plugin: fix bugs causing inconsistent framerate in VR.</td>
</tr>
<tr class="even">
<td></td>
<td>- Pre-load content to avoid stutters in the 3D environment.</td>
</tr>
<tr class="odd">
<td><strong>Week 4</strong></td>
<td>- Content: Begin work on hardcoded avatars.</td>
</tr>
<tr class="even">
<td></td>
<td>- Content: Recruit artists for creating a default home map.</td>
</tr>
<tr class="odd">
<td></td>
<td>- Physics: fix physics errors such as sliding down ramps.</td>
</tr>
<tr class="even">
<td></td>
<td>- Test performance on regular VR hardware and optimization.</td>
</tr>
<tr class="odd">
<td><strong>Week 5-6</strong></td>
<td>- Account system, TOS, Privacy Policy.</td>
</tr>
<tr class="even">
<td></td>
<td>- Allow closed registration of users.</td>
</tr>
<tr class="odd">
<td></td>
<td>- Continue working on content and fix bugs.</td>
</tr>
<tr class="even">
<td></td>
<td>- Integration of video playback.</td>
</tr>
<tr class="odd">
<td></td>
<td>- Focus on stress testing.</td>
</tr>
<tr class="even">
<td><strong>Week 7-8</strong></td>
<td>- Fix bugs found during testing.</td>
</tr>
<tr class="odd">
<td></td>
<td>- Monitor performance metrics and keep fixing performance.</td>
</tr>
</tbody>
</table>
<p><strong>Could you describe the team’s approach to developing the Minimum Viable Product throughout the summer? This includes, but is not limited to:</strong></p>
<p><strong>Who are your peers?</strong></p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Tier S</th>
<th>Tier A</th>
<th>Tier B</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>VRChat</td>
<td>Spatial</td>
<td>ENGAGE VR</td>
</tr>
<tr class="even">
<td>Meta Horizon Worlds</td>
<td>Mozilla Hubs</td>
<td>HTC Vive Sync</td>
</tr>
<tr class="odd">
<td>cluster</td>
<td>VirtualCast</td>
<td>Oasis VR</td>
</tr>
<tr class="even">
<td>Rec Room</td>
<td>Sansar</td>
<td>ChilloutVR</td>
</tr>
<tr class="odd">
<td>Roblox VR</td>
<td>Somnium Space</td>
<td>Lavender</td>
</tr>
<tr class="even">
<td></td>
<td>Overte</td>
<td>Resonite</td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td>Bigscreen</td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td>Anyland</td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td>VirBELA</td>
</tr>
</tbody>
</table>
<p><strong>How will you attract your first 1000 users? Your first 1,000,000?</strong></p>
<p>We will start with contacts from our VR communities to get the first 50 users. To get more users, we will offer unique experiences not available on other platforms. To reach thousands of users, we will host events and ensure privacy and self-hosting capabilities.</p>
<p><strong>First 2-week development milestone</strong></p>
<p><strong>First two weeks:</strong></p>
<ul>
<li>Maintain continuous integration of Windows SteamVR, Meta Quest, and Linux server builds.</li>
<li>VOIP implementation: basic lipsync based on volume, and spatialization library integration.</li>
<li>Improve Inverse Kinematics implementation and add non-VR support.</li>
<li>Headless clients will stress test the system.</li>
<li>Implement crash reporting system and performance metrics.</li>
<li>Content: Use a basic scripting API to implement physics-based games.</li>
<li>Work on engine changes for smooth frame rates during content loading.</li>
</ul>
<p><strong>Tech stack you plan to use (Cloud services, APIs, mobile platforms, languages, etc)</strong></p>
<p>Godot Engine, k3s, Elixir, OAuth, CockroachDB, Nginx, Fedora, CentOS 8, Digital Ocean Spaces, Meta Quest SDK on Android, Valve OpenVR on Windows.</p>
<p><strong>Link to simple sketches (can be as simple as paper and pencil) of your product or idea</strong></p>
<p>Most Social VR applications are being developed in Unity, leading to design challenges. Social platforms are strongly impacted by the network effect, which challenges acquisition. VR applications tend to have low retention compared with conventional applications.</p>
<p><strong>What challenges do you anticipate with this idea?</strong></p>
<p><strong>Team Member Locations by Country</strong></p>
<p>Canada, United States, United Kingdom</p>
<p><strong>Team Details</strong></p>
<p><strong>MMMaellon:</strong> C++, Java, and Python. Familiar with the Android and iOS frameworks. Design skills come from working professionally as a motion graphics, VFX artist, and video editor. I used to work as a mobile app developer and am getting a master’s in computer science.</p>
<p><strong>Saracen:</strong> C++, C, C#, Java, Python, GDScript, Android. Worked several years professionally on mobile app development, self-taught experience working on game mods and game engine architecture, including forks of the Id Software GPL releases, code contributions to the open source Godot Engine and other VR platforms, tools development including Unity, Godot, and Blender plugins, and work on reimplementing legacy game engines for modern platforms.</p>
<p><strong>Lyuma:</strong> C++, Java, Python, Javascript, C#, Android, iOS. Familiar with backend, operations, and networking. Spent 9 years working in industry: led a team developing the VOIP and video implementation on an iOS and Android app, reaching hundreds of millions of users, including the backend architecture, scaling, operations, and networking, as well as the stats and monitoring needed to optimize the design.</p>
<p><strong>iFire:</strong> C++. Familiar with Godot Engine and Unreal Engine. Working professionally in game development. A Blender to glTF2 pipeline was created for Godot Engine, and an FBX pipeline was coordinated. Shipped Offworld Industries’ Squad (80-player War Simulator) as a programmer, DevOps, and IT for nearly two years. As a team, I implemented an Unreal Engine touchscreen product demo for an aerospace company exhibited at the Las Vegas NBAA convention using HTML5 and Blueprints.</p>
<p><strong>Will all team members commit their full-time energy to this project during the 8 weeks of the program?</strong></p>
<p>Not all successful MVP applicants will, but we expect a significant commitment to the MVP Lab. Please explain if you cannot commit full-time to this and how we can be sure this will be a very serious commitment by you and your team.</p>
<p>MMMaellon is making individual contributions, including a VR character movement system, that have proved extremely valuable, as needed.</p>
<p>Saracen will be working full-time on the core client written for Godot.</p>
<p>Lyuma will work full-time on this project, starting with the MVP Lab, focusing on dev ops, operations, backend, and testing.</p>
<p>iFire is heavily engaged with the wider open-source community surrounding Godot Engine and takes on projects that help further Godot as an ecosystem. In addition, it spends part-time dedicated to this MVP project.</p>
<p><strong>How did you hear about the MVP Lab?</strong></p>
<p>We heard about it from Hacker News: https://news.ycombinator.com/item?id=23194178</p>
<p><strong>Is there anything else we should know?</strong></p>
<p>We are passionate about VR, open source, and decentralization, and strive to bring value to the internet community.</p>
</section>
<section id="the-benefits" class="level2">
<h2 class="anchored" data-anchor-id="the-benefits">The Benefits</h2>
<p>Updating our V-Sekai charter to 2024 will:</p>
<ul>
<li>Keep the project relevant and aligned with current technological advancements and user needs.</li>
<li>Provide a clear roadmap and goals for the development team.</li>
<li>Attract potential investors and collaborators.</li>
<li>Enhance the project’s credibility and visibility within the VR and open-source communities.</li>
</ul>
</section>
<section id="the-downsides" class="level2">
<h2 class="anchored" data-anchor-id="the-downsides">The Downsides</h2>
<p>Updating our V-Sekai charter to 2024 could:</p>
<ul>
<li>Overcommit resources and time without guaranteed funding.</li>
<li>Risk technological changes or market shifts rendering parts of the charter obsolete.</li>
<li>Lead to team burnout or turnover due to the extended timeline and ambitious goals.</li>
</ul>
</section>
<section id="the-road-not-taken" class="level2">
<h2 class="anchored" data-anchor-id="the-road-not-taken">The Road Not Taken</h2>
<p>Maintaining the current charter and focusing on short-term goals could:</p>
<ul>
<li>Allow more flexibility and adaptability to changing market conditions.</li>
<li>Reduce the risk of overcommitting resources and time.</li>
<li>Potentially limit the project’s growth and impact.</li>
</ul>
</section>
<section id="the-infrequent-use-case" class="level2">
<h2 class="anchored" data-anchor-id="the-infrequent-use-case">The Infrequent Use Case</h2>
<p>An infrequent use case for our V-Sekai platform could be:</p>
<ul>
<li>Virtual historical reenactments or educational tours.</li>
<li>Hosting virtual conferences or trade shows.</li>
</ul>
</section>
<section id="why-is-it-in-core-and-done-by-us" class="level2">
<h2 class="anchored" data-anchor-id="why-is-it-in-core-and-done-by-us">Why is it in Core and done by us?</h2>
<p>Updating the V-Sekai charter to 2024 is core to our mission because:</p>
<ul>
<li>We are committed to developing an open-source, decentralized VR platform.</li>
<li>Our team has the expertise and passion for VR and open-source technology.</li>
<li>Setting long-term goals ensures the project’s sustainability and growth.</li>
</ul>
</section>
<section id="status" class="level2">
<h2 class="anchored" data-anchor-id="status">Status</h2>
<p><strong>Status:</strong> Draft <!-- Draft | Proposed | Rejected | Accepted | Deprecated | Superseded by --></p>
</section>
<section id="decision-makers" class="level2">
<h2 class="anchored" data-anchor-id="decision-makers">Decision Makers</h2>
<ul>
<li>V-Sekai development team</li>
</ul>
</section>
<section id="tags" class="level2">
<h2 class="anchored" data-anchor-id="tags">Tags</h2>
<ul>
<li>V-Sekai</li>
</ul>
</section>
<section id="further-reading" class="level2">
<h2 class="anchored" data-anchor-id="further-reading">Further Reading</h2>
<ol type="1">
<li><a href="https://github.com/v-sekai">V-Sekai · GitHub</a> - Official GitHub account for the V-Sekai development community focusing on social VR functionality for the Godot Engine.</li>
<li><a href="https://github.com/v-sekai/v-sekai-game">V-Sekai/v-sekai-game</a> is the GitHub page for the V-Sekai open-source project, which brings social VR/VRSNS/metaverse components to the Godot Engine.</li>
</ol>
<p>AI assistant Aria assisted with this article.</p>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20241210-vsekai-charter.html</guid>
  <pubDate>Wed, 11 Dec 2024 15:00:09 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20241112-godot-animation-streaming.html</link>
  <description><![CDATA[ 




<section id="accepted-godot-animation-streaming" class="level1">
<h1>Accepted: Godot Animation streaming</h1>
<section id="the-context" class="level2">
<h2 class="anchored" data-anchor-id="the-context">The Context</h2>
<p>Animation streaming is a technique for handling extremely long animations. It involves loading only portions of the animation data as needed, which helps manage memory efficiently and ensures smooth playback without requiring the entire animation to be loaded into memory simultaneously.</p>
</section>
<section id="the-problem-statement" class="level2">
<h2 class="anchored" data-anchor-id="the-problem-statement">The Problem Statement</h2>
<p>We need a system to handle the streaming of long animations in a way that minimizes memory usage and ensures smooth playback. The system should be configurable and handle various animation lengths and complexities.</p>
</section>
<section id="describe-how-your-proposal-will-work-with-code-pseudo-code-mock-ups-or-diagrams" class="level2">
<h2 class="anchored" data-anchor-id="describe-how-your-proposal-will-work-with-code-pseudo-code-mock-ups-or-diagrams">Describe how your proposal will work with code, pseudo-code, mock-ups, or diagrams</h2>
<p>We have a resource, <code>AnimationStreamingData</code>, which, when exported, is a custom binary resource containing animation pages. Export animation compressed data to this.</p>
<p>If you have an LRU of pages in the animation resource, you can customize this in the project settings (animation page LRU). I would like to know the number of pages, time, or size. Time is best, say 3 seconds.</p>
<p>Have a particular track for streamed animations. Always load the first 3 seconds of animation (buffer size). For the rest, while playing the animation, you can use <code>WorkerThreadPool</code> to queue loading resource pages ahead of you on a thread. Always strive to have 3 seconds (again, buffer size) ahead of the playback cursor. After you are done with a page, you can free it.</p>
<p><code>AnimationStreamingData</code> should be a binary format, custom-made, with all pages saved.</p>
<p>Animation streaming must be restricted to compressed keyframe pages.</p>
<p>When opening this, you should have an index (file offset, size, and position in the timeline) that you load first from it, then stream pages as you go.</p>
<section id="animationstreamingdata-stored-on-disk-and-runtime-component" class="level3">
<h3 class="anchored" data-anchor-id="animationstreamingdata-stored-on-disk-and-runtime-component">AnimationStreamingData (Stored on Disk and Runtime Component)</h3>
<ol type="1">
<li>Exporting animation compressed data to <code>AnimationStreamingData</code>.</li>
<li>Implementing an LRU (Least Recently Used) cache for animation pages, configurable in the project settings (animation page LRU).</li>
<li>Loading the first 3 seconds of animation as a buffer.</li>
<li>Using <code>WorkerThreadPool</code> to queue loading resource pages ahead of the playback cursor.</li>
<li>Freeing pages after they are no longer needed.</li>
</ol>
<pre class="gdscript"><code>class AnimationStreamingData:
    var index = []  # Array of arrays (file_offset, size, position_in_timeline)
    var pages = {}
    var ring_buffer = RingBuffer.new()  # Custom type for ring buffer
    var usage = []  # Track usage for LRU

    func _init():
        load_index()
        var buffer_size = 16  # Example size, adjust as needed
        ring_buffer.resize(buffer_size)
        usage.resize(buffer_size)

    func load_index():
        # Load index from binary resource
        pass

    func get_page_info(page_number):
        # Retrieve page info from the index
        var page_info = index[page_number]
        return {"file_offset": page_info[0], "size": page_info[1], "position_in_timeline": page_info[2]}

    func store_page(page_number, page_data):
        # Store compressed animation page data
        pages[page_number] = page_data

    func load_page(page_number):
        # Load compressed animation page data
        return pages.get(page_number, null)

    func fetch_page(page_number):
        # Fetch page data from AnimationStreamingData
        return load_page(page_number)

    func stream_page(page_number):
        # Stream page data from RingBuffer
        if ring_buffer.data_left() &gt; 0:
            var page = ring_buffer.read()
            update_usage(page_number)
            return page
        else:
            return null

    func write_page(page_data, page_number):
        # Write page data to RingBuffer
        if ring_buffer.space_left() &lt; 1:
            # Find and replace the least recently used page
            var lru_index = find_lru()
            ring_buffer.write_pos = lru_index
        ring_buffer.write(page_data)
        update_usage(page_number)

    func update_usage(page_number):
        # Update usage list
        for i in range(usage.size()):
            usage[i] += 1
        usage[page_number] = 0

    func find_lru():
        # Find the least recently used page
        var max_usage = -1
        var lru_index = -1
        for i in range(usage.size()):
            if usage[i] &gt; max_usage:
                max_usage = usage[i]
                lru_index = i
        return lru_index</code></pre>
</section>
<section id="animationplayer" class="level3">
<h3 class="anchored" data-anchor-id="animationplayer">AnimationPlayer</h3>
<pre class="gdscript"><code>class AnimationPlayer:
    var buffer_size = 3.0 # FIXME: Calculate a better buffer size.
    var worker_pool = WorkerThreadPool.new()
    var streaming_data = AnimationStreamingData.new()

    func _init():
        streaming_data.load_index()

    func play_animation():
        # Load initial buffer
        load_initial_buffer()
        # Stream pages ahead of playback cursor
        stream_pages_ahead()

    func load_initial_buffer():
        # Load the first 3 seconds of animation into RingBuffer
        for i in range(buffer_size):
            var page_info = streaming_data.get_page_info(i)
            var page = streaming_data.fetch_page(page_info)
            if page != null:
                streaming_data.write_page(page, i)

    func stream_pages_ahead():
        # Queue loading of pages ahead of playback cursor
        worker_pool.queue_task(callable(self, "_load_next_page"))

    func _load_next_page():
        var next_page_info = streaming_data.get_page_info(buffer_size)
        var next_page = streaming_data.fetch_page(next_page_info)
        if next_page != null:
            streaming_data.write_page(next_page, buffer_size)

    func free_page(page):
        # Free page after use
        streaming_data.ring_buffer.advance_read(1)</code></pre>
</section>
</section>
<section id="the-benefits" class="level2">
<h2 class="anchored" data-anchor-id="the-benefits">The Benefits</h2>
<p>Efficient memory usage by loading only necessary animation data. This allows for the import and streaming of extremely long animations with configurable settings to suit different project needs.</p>
<ol type="1">
<li><p><strong>Character Animations</strong>: In an open-world game, characters may have complex animations such as walking, running, jumping, and interacting with the environment. Animation streaming ensures that only the necessary parts of these animations are loaded, reducing memory usage and improving performance.</p></li>
<li><p><strong>Environmental Animations</strong>: Open-world games often feature dynamic environments with animations like trees swaying, water flowing, and weather changes. Streaming these animations helps maintain a seamless experience without overloading the system.</p></li>
<li><p><strong>Cutscenes and Cinematics</strong>: Long cutscenes and cinematic sequences can be streamed to avoid loading large animation files simultaneously, ensuring smooth transitions and playback.</p></li>
<li><p><strong>NPC Interactions</strong>: Non-player characters (NPCs) in open-world games may have varied and lengthy interaction animations. Streaming these animations allows for more complex and varied NPC behaviours without compromising performance.</p></li>
</ol>
</section>
<section id="the-downsides" class="level2">
<h2 class="anchored" data-anchor-id="the-downsides">The Downsides</h2>
<ul>
<li>Increased complexity in animation handling.</li>
<li>Potential latency in loading pages if not appropriately managed.</li>
</ul>
</section>
<section id="the-road-not-taken" class="level2">
<h2 class="anchored" data-anchor-id="the-road-not-taken">The Road Not Taken</h2>
<p>An alternative approach could be to load the entire animation into memory, simplifying the implementation but resulting in high memory usage and potential performance issues for long animations.</p>
</section>
<section id="the-infrequent-use-case" class="level2">
<h2 class="anchored" data-anchor-id="the-infrequent-use-case">The Infrequent Use Case</h2>
<p>Handling extremely short animations where streaming might not be necessary.</p>
</section>
<section id="in-core-and-done-by-us" class="level2">
<h2 class="anchored" data-anchor-id="in-core-and-done-by-us">In Core and Done by Us</h2>
<p>The V-Sekai development team will implement this proposal as part of the core functionality for handling animations in the Godot Engine.</p>
</section>
<section id="status" class="level2">
<h2 class="anchored" data-anchor-id="status">Status</h2>
<p>Status: Accepted <!-- Draft | Proposed | Rejected | Accepted | Deprecated | Superseded by --></p>
</section>
<section id="decision-makers" class="level2">
<h2 class="anchored" data-anchor-id="decision-makers">Decision Makers</h2>
<ul>
<li>V-Sekai development team</li>
<li>fire</li>
<li>reduz</li>
</ul>
</section>
<section id="tags" class="level2">
<h2 class="anchored" data-anchor-id="tags">Tags</h2>
<ul>
<li>V-Sekai</li>
</ul>
</section>
<section id="further-reading" class="level2">
<h2 class="anchored" data-anchor-id="further-reading">Further Reading</h2>
<ol type="1">
<li><a href="https://github.com/v-sekai">V-Sekai · GitHub</a> - Official GitHub account for the V-Sekai development community focusing on social VR functionality for the Godot Engine.</li>
<li><a href="https://github.com/v-sekai/v-sekai-game">V-Sekai/v-sekai-game</a> is the GitHub page for the V-Sekai open-source project, which brings social VR/VRSNS/metaverse components to the Godot Engine.</li>
</ol>
<p>AI assistant Aria assisted with this article.</p>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20241112-godot-animation-streaming.html</guid>
  <pubDate>Wed, 11 Dec 2024 15:00:09 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20241102-plan-november-2024.html</link>
  <description><![CDATA[ 




<section id="draft-plan-november-2024." class="level1">
<h1>Draft: Plan November 2024.</h1>
<section id="the-context" class="level2">
<h2 class="anchored" data-anchor-id="the-context">The Context</h2>
</section>
<section id="the-problem-statement" class="level2">
<h2 class="anchored" data-anchor-id="the-problem-statement">The Problem Statement</h2>
</section>
<section id="describe-how-your-proposal-will-work-with-code-pseudo-code-mock-ups-or-diagrams" class="level2">
<h2 class="anchored" data-anchor-id="describe-how-your-proposal-will-work-with-code-pseudo-code-mock-ups-or-diagrams">Describe how your proposal will work with code, pseudo-code, mock-ups, or diagrams</h2>
<pre class="mermaid"><code>graph TD
    Z[Restore Backend Server]
    A[Restore old V-Sekai]
    F[Recruit Artist for Default Home Map]
    H[Integration of Video Playback &amp; Streaming]

    Z --&gt; A
    A --&gt; Z
    A --&gt; F
    A --&gt; H</code></pre>
</section>
<section id="the-benefits" class="level2">
<h2 class="anchored" data-anchor-id="the-benefits">The Benefits</h2>
</section>
<section id="the-downsides" class="level2">
<h2 class="anchored" data-anchor-id="the-downsides">The Downsides</h2>
</section>
<section id="the-road-not-taken" class="level2">
<h2 class="anchored" data-anchor-id="the-road-not-taken">The Road Not Taken</h2>
</section>
<section id="the-infrequent-use-case" class="level2">
<h2 class="anchored" data-anchor-id="the-infrequent-use-case">The Infrequent Use Case</h2>
</section>
<section id="in-core-and-done-by-us" class="level2">
<h2 class="anchored" data-anchor-id="in-core-and-done-by-us">In Core and Done by Us</h2>
</section>
<section id="status" class="level2">
<h2 class="anchored" data-anchor-id="status">Status</h2>
<p>Status: Draft <!-- Draft | Proposed | Rejected | Accepted | Deprecated | Superseded by --></p>
</section>
<section id="decision-makers" class="level2">
<h2 class="anchored" data-anchor-id="decision-makers">Decision Makers</h2>
<ul>
<li>V-Sekai development team</li>
</ul>
</section>
<section id="tags" class="level2">
<h2 class="anchored" data-anchor-id="tags">Tags</h2>
<ul>
<li>V-Sekai</li>
</ul>
</section>
<section id="further-reading" class="level2">
<h2 class="anchored" data-anchor-id="further-reading">Further Reading</h2>
<ol type="1">
<li><a href="https://github.com/v-sekai">V-Sekai · GitHub</a> - Official GitHub account for the V-Sekai development community focusing on social VR functionality for the Godot Engine.</li>
<li><a href="https://github.com/v-sekai/v-sekai-game">V-Sekai/v-sekai-game</a> is the GitHub page for the V-Sekai open-source project, which brings social VR/VRSNS/metaverse components to the Godot Engine.</li>
</ol>
<p>AI assistant Aria assisted with this article.</p>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20241102-plan-november-2024.html</guid>
  <pubDate>Wed, 11 Dec 2024 15:00:09 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20241028-use-data-tables-for-godot-constraints.html</link>
  <description><![CDATA[ 




<section id="proposal-use-data-tables-for-godot-constraints" class="level1">
<h1>Proposal: Use Data Tables for Godot Constraints</h1>
<section id="the-context" class="level2">
<h2 class="anchored" data-anchor-id="the-context">The Context</h2>
<p>In the development of VR applications using the Godot Engine, managing complex interactions and constraints can become cumbersome and error-prone when handled purely through code.</p>
</section>
<section id="the-problem-statement" class="level2">
<h2 class="anchored" data-anchor-id="the-problem-statement">The Problem Statement</h2>
<p>Currently, developers must manually code each constraint and interaction within the Godot Engine, which is time-consuming and increases the risk of errors. This approach lacks scalability and efficiency, particularly in large-scale VR projects like those developed by V-Sekai.</p>
</section>
<section id="describe-how-your-proposal-will-work-with-code-pseudo-code-mock-ups-or-diagrams" class="level2">
<h2 class="anchored" data-anchor-id="describe-how-your-proposal-will-work-with-code-pseudo-code-mock-ups-or-diagrams">Describe how your proposal will work with code, pseudo-code, mock-ups, or diagrams</h2>
<p>The proposal involves integrating a data table system within the Godot Engine to manage constraints. Here’s a basic example of how it might look in pseudo-code:</p>
</section>
<section id="the-benefits" class="level2">
<h2 class="anchored" data-anchor-id="the-benefits">The Benefits</h2>
<ul>
<li><strong>Scalability</strong>: Easier to manage large numbers of constraints.</li>
<li><strong>Efficiency</strong>: Reduces development time by allowing non-programmers to adjust constraints.</li>
<li><strong>Error Reduction</strong>: Minimizes coding errors associated with manual constraint setup.</li>
</ul>
</section>
<section id="the-downsides" class="level2">
<h2 class="anchored" data-anchor-id="the-downsides">The Downsides</h2>
<ul>
<li><strong>Complexity in Setup</strong>: Initial setup of data tables and integration into the Godot project might be complex.</li>
<li><strong>Performance Concerns</strong>: Reading from data tables at runtime could impact performance if not properly optimized.</li>
</ul>
</section>
<section id="the-road-not-taken" class="level2">
<h2 class="anchored" data-anchor-id="the-road-not-taken">The Road Not Taken</h2>
<p>An alternative could have been to develop a visual editor for constraints within Godot, but this would require significantly more development resources and may not offer the same flexibility as a data-driven approach.</p>
</section>
<section id="the-infrequent-use-case" class="level2">
<h2 class="anchored" data-anchor-id="the-infrequent-use-case">The Infrequent Use Case</h2>
<p>For projects where constraints are minimal or highly static, this system might introduce unnecessary complexity and overhead.</p>
</section>
<section id="in-core-and-done-by-us" class="level2">
<h2 class="anchored" data-anchor-id="in-core-and-done-by-us">In Core and Done by Us</h2>
<p>This feature should be developed and maintained by the core V-Sekai team to ensure it aligns with the overall architecture and performance standards of the engine.</p>
</section>
<section id="status" class="level2">
<h2 class="anchored" data-anchor-id="status">Status</h2>
<p>Status: Draft <!-- Draft | Proposed | Rejected | Accepted | Deprecated | Superseded by --></p>
</section>
<section id="decision-makers" class="level2">
<h2 class="anchored" data-anchor-id="decision-makers">Decision Makers</h2>
<ul>
<li>V-Sekai development team</li>
</ul>
</section>
<section id="tags" class="level2">
<h2 class="anchored" data-anchor-id="tags">Tags</h2>
<ul>
<li>V-Sekai</li>
</ul>
</section>
<section id="further-reading" class="level2">
<h2 class="anchored" data-anchor-id="further-reading">Further Reading</h2>
<ol type="1">
<li><a href="https://github.com/v-sekai">V-Sekai · GitHub</a> - Official GitHub account for the V-Sekai development community focusing on social VR functionality for the Godot Engine.</li>
<li><a href="https://github.com/v-sekai/v-sekai-game">V-Sekai/v-sekai-game</a> is the GitHub page for the V-Sekai open-source project, which brings social VR/VRSNS/metaverse components to the Godot Engine.</li>
</ol>
<p>AI assistant Aria assisted with this article.</p>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20241028-use-data-tables-for-godot-constraints.html</guid>
  <pubDate>Wed, 11 Dec 2024 15:00:09 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20241019-reduce-size-difference-between-capsules-and-mesh-volume.html</link>
  <description><![CDATA[ 




<section id="draft-reduce-size-difference-between-capsules-and-mesh-volume" class="level1">
<h1>Draft: Reduce Size Difference Between Capsules and Mesh Volume</h1>
<section id="the-context" class="level2">
<h2 class="anchored" data-anchor-id="the-context">The Context</h2>
<p>Accurately fit capsules around bones in skinned skeleton meshes. The example provided involves a rectangle skinned by two bones, with each vertex influenced by up to 8 weights.</p>
</section>
<section id="the-problem-statement" class="level2">
<h2 class="anchored" data-anchor-id="the-problem-statement">The Problem Statement</h2>
<p>The goal is to minimize the size discrepancies between the capsules surrounding the bones and the actual volume defined by the skin mesh. This will be approached using the Minimum Deviation Flow problem in bidirected graphs (Bi-MDF).</p>
</section>
<section id="describe-how-your-proposal-will-work-with-code-pseudo-code-mock-ups-or-diagrams" class="level2">
<h2 class="anchored" data-anchor-id="describe-how-your-proposal-will-work-with-code-pseudo-code-mock-ups-or-diagrams">Describe how your proposal will work with code, pseudo-code, mock-ups, or diagrams</h2>
<section id="step-1-representation-of-the-skeleton-and-skin-mesh" class="level3">
<h3 class="anchored" data-anchor-id="step-1-representation-of-the-skeleton-and-skin-mesh">Step 1: Representation of the Skeleton and Skin Mesh</h3>
<ul>
<li><strong>Skeleton</strong>: Represent each bone as a node in a graph.</li>
<li><strong>Skin Mesh</strong>: Each vertex of the mesh is also a node. Connect a bone to a vertex with an edge if the vertex is influenced by that bone, based on skin weights.</li>
</ul>
</section>
<section id="step-2-define-the-objective" class="level3">
<h3 class="anchored" data-anchor-id="step-2-define-the-objective">Step 2: Define the Objective</h3>
<ul>
<li>The objective is to minimize the size differences between the capsules (nodes) and the volume of the skin mesh. This is quantified using a cost function that measures the deviation from ideal capsule sizes.</li>
</ul>
</section>
<section id="implementation" class="level3">
<h3 class="anchored" data-anchor-id="implementation">Implementation</h3>
<p>I have no idea.</p>
</section>
</section>
<section id="the-benefits" class="level2">
<h2 class="anchored" data-anchor-id="the-benefits">The Benefits</h2>
<ul>
<li><strong>Accuracy</strong>: Improves the fit of capsules to the actual mesh, enhancing animation quality.</li>
<li><strong>Efficiency</strong>: Reduces computational overhead by focusing on significant discrepancies.</li>
</ul>
</section>
<section id="the-downsides" class="level2">
<h2 class="anchored" data-anchor-id="the-downsides">The Downsides</h2>
<ul>
<li><strong>Complexity</strong>: Implementing and tuning the Bi-MDF algorithm can be complex.</li>
<li><strong>Dependency</strong>: Relies heavily on accurate weight assignments and initial conditions.</li>
</ul>
</section>
<section id="the-road-not-taken" class="level2">
<h2 class="anchored" data-anchor-id="the-road-not-taken">The Road Not Taken</h2>
<ul>
<li>Alternative methods such as direct geometric fitting or machine learning approaches were considered but not pursued due to their complexity and computational requirements.</li>
</ul>
</section>
<section id="the-infrequent-use-case" class="level2">
<h2 class="anchored" data-anchor-id="the-infrequent-use-case">The Infrequent Use Case</h2>
<ul>
<li>Handling cases where bones have minimal influence on any vertices, which might lead to underutilized algorithms and resources.</li>
</ul>
</section>
<section id="in-core-and-done-by-us" class="level2">
<h2 class="anchored" data-anchor-id="in-core-and-done-by-us">In Core and Done by Us</h2>
<ul>
<li>The development and integration of this feature are handled internally by the V-Sekai development team, ensuring it aligns with the core functionalities of the Godot Engine used for VR.</li>
</ul>
</section>
<section id="status" class="level2">
<h2 class="anchored" data-anchor-id="status">Status</h2>
<p>Status: Draft <!-- Draft | Proposed | Rejected | Accepted | Deprecated | Superseded by --></p>
</section>
<section id="decision-makers" class="level2">
<h2 class="anchored" data-anchor-id="decision-makers">Decision Makers</h2>
<ul>
<li>V-Sekai development team</li>
</ul>
</section>
<section id="tags" class="level2">
<h2 class="anchored" data-anchor-id="tags">Tags</h2>
<ul>
<li>V-Sekai</li>
</ul>
</section>
<section id="further-reading" class="level2">
<h2 class="anchored" data-anchor-id="further-reading">Further Reading</h2>
<ol type="1">
<li><a href="https://github.com/v-sekai">V-Sekai · GitHub</a> - Official GitHub account for the V-Sekai development community focusing on social VR functionality for the Godot Engine.</li>
<li><a href="https://github.com/v-sekai/v-sekai-game">V-Sekai/v-sekai-game</a> is the GitHub page for the V-Sekai open-source project, which brings social VR/VRSNS/metaverse components to the Godot Engine.</li>
<li><a href="https://github.com/V-Sekai-fire/libsatsuma">cgg-bern/libSatsuma</a> Exact and approximate solvers for minimum-cost-flow problems in bi-directed graphs.</li>
</ol>
<p>AI assistant Aria assisted with this article.</p>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20241019-reduce-size-difference-between-capsules-and-mesh-volume.html</guid>
  <pubDate>Wed, 11 Dec 2024 15:00:09 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20241016-instantiating-v-sekai-content.html</link>
  <description><![CDATA[ 




<section id="draft-evaluate-three-proposals-for-v-sekai-content-distribution" class="level1">
<h1>Draft: Evaluate three proposals for V-Sekai content distribution</h1>
<section id="the-context" class="level2">
<h2 class="anchored" data-anchor-id="the-context">The Context</h2>
<p>Address security concerns with V-Sekai content distribution like including the sandbox API surface, file size management, resource loading, and packed scene instantiation.</p>
</section>
<section id="the-problem-statement" class="level2">
<h2 class="anchored" data-anchor-id="the-problem-statement">The Problem Statement</h2>
<p>We aim to safely initialize an avatar body from the V-Sekai content distribution network into the virtual world without compromising security or performance.</p>
<p>We wish to enable Godot to load older content seamlessly.</p>
<p>We want to avoid animations causing security issues.</p>
</section>
<section id="describe-how-your-proposal-will-work-with-code-pseudo-code-mock-ups-or-diagrams" class="level2">
<h2 class="anchored" data-anchor-id="describe-how-your-proposal-will-work-with-code-pseudo-code-mock-ups-or-diagrams">Describe how your proposal will work with code, pseudo-code, mock-ups, or diagrams</h2>
<section id="option-1-instantiate-and-validate-binary-packedscene" class="level3">
<h3 class="anchored" data-anchor-id="option-1-instantiate-and-validate-binary-packedscene">Option 1: Instantiate and Validate binary PackedScene</h3>
<p>This method involves loading chunks of an average packed scene from the web, instantiating it in the sandbox, and applying runtime verification. This approach prevents double initializer security concerns and avoids using double the memory to copy PackedScene.</p>
<section id="double-initializer-security-concern" class="level4">
<h4 class="anchored" data-anchor-id="double-initializer-security-concern">Double initializer security concern</h4>
<p>Different content initializers becomes a security problem as code drifts and fixes are lost.</p>
</section>
</section>
<section id="option-2-instantiate-and-validate-binary-gltf" class="level3">
<h3 class="anchored" data-anchor-id="option-2-instantiate-and-validate-binary-gltf">Option 2: Instantiate and Validate binary GLTF</h3>
<p>For this option, we would stream an average glTF file from the web and develop a loader for glTF within the Godot sandbox equipped with a set of verifiers.</p>
<p>We must create custom VSEKAI or GODOT extensions for each unspecified resource and node type, though simple schemas could be autogenerated from classes.</p>
</section>
<section id="option-3-stream-arbitrary-godot-packed-scene-resources-write-a-verifier-and-then-parse" class="level3">
<h3 class="anchored" data-anchor-id="option-3-stream-arbitrary-godot-packed-scene-resources-write-a-verifier-and-then-parse">Option 3: Stream arbitrary Godot-packed scene resources, write a verifier and then parse</h3>
<p>Creating a JSON schema for arbitrary Godot-packed scene resources that have been converted to JSON is a complex task. This option might be more challenging than adapting glTF for sandbox C++.</p>
</section>
</section>
<section id="the-benefits" class="level2">
<h2 class="anchored" data-anchor-id="the-benefits">The Benefits</h2>
<p>A significant benefit of these approaches is the ability to enforce specific requirements, such as using PCVR and mobile image textures through formats like Basis Universal, BPTC, and ASTC during upload and download. By controlling the instantiation process, we can also prevent loading when, for example, an avatar exceeds a polycount of 70,000 triangles. We can size worlds according to predefined constraints, with various optimization settings available.</p>
</section>
<section id="the-downsides" class="level2">
<h2 class="anchored" data-anchor-id="the-downsides">The Downsides</h2>
<p>The primary downside is the complexity of these security measures and their potential performance impact. Each option requires substantial development effort and may introduce latency or processing overhead. Furthermore, maintaining these systems as Godot evolves could increase long-term maintenance costs.</p>
</section>
<section id="the-road-not-taken" class="level2">
<h2 class="anchored" data-anchor-id="the-road-not-taken">The Road Not Taken</h2>
<p>We could have explored simpler, less secure methods of content distribution that rely more heavily on post-load validation rather than stringent pre-load checks.</p>
</section>
<section id="the-infrequent-use-case" class="level2">
<h2 class="anchored" data-anchor-id="the-infrequent-use-case">The Infrequent Use Case</h2>
<p>These methods are designed to handle extremely large or complex scenes that might exceed the proposed limits and infrequent resource types not covered by standard validators.</p>
</section>
<section id="in-core-and-done-by-us" class="level2">
<h2 class="anchored" data-anchor-id="in-core-and-done-by-us">In Core and Done by Us</h2>
<p>We will maintain the core functionality of the sandbox and basic loaders, ensuring that critical updates or security patches can be applied swiftly and uniformly.</p>
</section>
<section id="status" class="level2">
<h2 class="anchored" data-anchor-id="status">Status</h2>
<p>Status: Draft <!-- Draft | Proposed | Rejected | Accepted | Deprecated | Superseded by --></p>
</section>
<section id="decision-makers" class="level2">
<h2 class="anchored" data-anchor-id="decision-makers">Decision Makers</h2>
<ul>
<li>V-Sekai development team</li>
<li>Fire</li>
<li>Lyuma</li>
<li>fwsgonzo</li>
</ul>
</section>
<section id="tags" class="level2">
<h2 class="anchored" data-anchor-id="tags">Tags</h2>
<ul>
<li>V-Sekai</li>
</ul>
</section>
<section id="further-reading" class="level2">
<h2 class="anchored" data-anchor-id="further-reading">Further Reading</h2>
<ol type="1">
<li><a href="https://github.com/v-sekai">V-Sekai · GitHub</a> - Official GitHub account for the V-Sekai development community focusing on social VR functionality for the Godot Engine.</li>
<li><a href="https://github.com/v-sekai/v-sekai-game">V-Sekai/v-sekai-game</a> - This GitHub page hosts the V-Sekai open-source project, which integrates social VR/VRSNS/metaverse components into the Godot Engine.</li>
</ol>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20241016-instantiating-v-sekai-content.html</guid>
  <pubDate>Wed, 11 Dec 2024 15:00:09 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20241014-xr-interface-for-rigging.html</link>
  <description><![CDATA[ 




<section id="draft-editing-character-body-bone-constraints-in-immersive-mode" class="level1">
<h1>Draft: Editing Character Body Bone Constraints in Immersive Mode</h1>
<section id="the-context" class="level2">
<h2 class="anchored" data-anchor-id="the-context">The Context</h2>
<p>V-Sekai is a social VR community.</p>
</section>
<section id="the-problem-statement" class="level2">
<h2 class="anchored" data-anchor-id="the-problem-statement">The Problem Statement</h2>
<p>We aim to develop a prototype interface for editing bone constraints such as position, rotation, twist rotation, and swing rotation on character body bones within an immersive environment.</p>
<p>Interactivity makes a difference, similar to the feeling of presence and being fully engaged with the editor. This greater flow state occurs because you don’t have to switch contexts, allowing for continuous interaction and focus.</p>
</section>
<section id="proposal-description" class="level2">
<h2 class="anchored" data-anchor-id="proposal-description">Proposal Description</h2>
<section id="interactive-design-concept" class="level3">
<h3 class="anchored" data-anchor-id="interactive-design-concept">Interactive Design Concept</h3>
<p>The proposed system will allow users to interact directly with avatar bone structures in a 3D space, manipulating constraints through intuitive gestures and tools. This approach aims to enhance user engagement and precision in modifying avatars.</p>
</section>
<section id="implementation-strategy" class="level3">
<h3 class="anchored" data-anchor-id="implementation-strategy">Implementation Strategy</h3>
<ol type="1">
<li><p><strong>Visual Representation of Bones</strong>:</p>
<ul>
<li>Each bone will be represented by a dot that becomes visible and enlarges when the user’s hand or controller approaches it, facilitating easy selection.</li>
</ul></li>
<li><p><strong>Avoiding Selection Mechanism</strong>:</p>
<ul>
<li>Instead of using a traditional selection mechanism, the system will employ proximity-based interaction. When a user’s hand or controller is near a bone, the relevant constraints automatically appear, allowing immediate manipulation without the need for explicit selection. This reduces complexity and enhances flow in the immersive environment.</li>
</ul></li>
<li><p><strong>Constraint Manipulation Tools</strong>:</p>
<ul>
<li>A virtual tool palette will be available to the user, containing different constraint modifiers.</li>
<li>Users can grab these tools and attach them to bones to adjust constraints like positions and rotations.</li>
</ul></li>
<li><p><strong>Tool Switcher Interface</strong>:</p>
<ul>
<li>In addition to the tool palette, a tool switcher mechanism will be implemented allowing users to quickly switch between tools without returning to the palette. This could be activated via a gesture or a button press, bringing up a radial or linear menu to select the desired tool.</li>
</ul></li>
<li><p><strong>Intuitive Constraint Adjustment</strong>:</p>
<ul>
<li>For position constraints, a 3D gizmo will appear, allowing users to manipulate the position directly within the VR space.</li>
<li>For rotational constraints, a 3D gizmo will appear, allowing users to manipulate the angle directly within the VR space.</li>
<li>Twist constraints will be adjusted using a 2d disk arc interface where permissible rotation areas are defined by the user.</li>
<li>Swing constraints can be adjusted using a spherical interface where permissible rotation areas are defined by the user.</li>
<li>Swing constraints can be adjusted using a 2d orbit map interface where permissible rotation areas are defined by the user.</li>
</ul></li>
<li><p><strong>Feedback and Precision</strong>:</p>
<ul>
<li>Visual and haptic feedback will be provided to ensure users are aware of the changes they are making.</li>
<li>Precision tools and snapping features will help in making exact adjustments.</li>
</ul></li>
<li><p><strong>Deselection and Context Switching</strong>:</p>
<ul>
<li>Moving the controller away from the bones or performing a specific gesture will clear the current interaction, allowing for a smooth workflow without accidental adjustments.</li>
</ul></li>
</ol>
</section>
<section id="mock-up-diagram" class="level3">
<h3 class="anchored" data-anchor-id="mock-up-diagram">Mock-up Diagram</h3>
<pre class="plaintext"><code>[User Interface Mock-up]
+------------------------------------------------+
|                                                |
|  [Avatar]                                      |
|    * (Head)                                    |
|    * (Shoulder)                                |
|    * (Elbow) &lt;-- [Interacting]                 |
|    * (Wrist)                                   |
|                                                |
|  [Tool Palette]                                |
|    - Grab Tool                                 |
|    - Rotate Tool                               |
|    - Swing Tool                                |
|    - Twist Tool                                |
|                                                |
|  [Tool Switcher]                               |
|    - Quick Switch Gesture                      |
|    - Radial Menu for Tool Selection            |
|                                                |
+------------------------------------------------+</code></pre>
</section>
</section>
<section id="benefits" class="level2">
<h2 class="anchored" data-anchor-id="benefits">Benefits</h2>
<ul>
<li><strong>Enhanced User Experience</strong>: Direct manipulation of bones and constraints in VR enhances the intuitiveness and enjoyment of avatar customization.</li>
<li><strong>Increased Precision</strong>: Fine control over adjustments leads to more accurate and satisfying results.</li>
<li><strong>Seamless Workflow</strong>: Integration of tools and interactions within the VR environment reduces the cognitive load and context switching, fostering a more creative and productive user experience.</li>
</ul>
</section>
<section id="downsides" class="level2">
<h2 class="anchored" data-anchor-id="downsides">Downsides</h2>
<ul>
<li><strong>Complexity in Implementation</strong>: Developing a fully interactive 3D UI with precise control mechanisms can be challenging and time-consuming.</li>
<li><strong>Performance Concerns</strong>: High fidelity models and real-time updates in VR may lead to performance issues on lower-end systems.</li>
<li>In a shared space app on the Apple Vision Pro neither switching or tool palette will work.</li>
<li>In an immersive app on the Apple Vision Pro either switching or tool palette will work with hand tracking.</li>
</ul>
</section>
<section id="the-road-not-taken" class="level2">
<h2 class="anchored" data-anchor-id="the-road-not-taken">The Road Not Taken</h2>
<ul>
<li><strong>2D GUI for Constraint Management</strong>: Using a traditional 2D interface for constraint management was considered but rejected due to the lack of immersion and intuitiveness in a VR context.</li>
</ul>
<p>The implementation of scale for matching clothing to the character’s body, as well as the adjustment of constraint weight, will be addressed in future work.</p>
</section>
<section id="in-core-and-done-by-us" class="level2">
<h2 class="anchored" data-anchor-id="in-core-and-done-by-us">In Core and Done by Us</h2>
<p>This feature is core to the V-Sekai project’s mission of enhancing VR interaction and will be developed internally to maintain control over quality and integration.</p>
</section>
<section id="status" class="level2">
<h2 class="anchored" data-anchor-id="status">Status</h2>
<p>Status: Draft <!-- Draft | Proposed | Rejected | Accepted | Deprecated | Superseded by --></p>
</section>
<section id="decision-makers" class="level2">
<h2 class="anchored" data-anchor-id="decision-makers">Decision Makers</h2>
<ul>
<li>V-Sekai development team</li>
<li>Fire</li>
<li>Nova</li>
</ul>
</section>
<section id="tags" class="level2">
<h2 class="anchored" data-anchor-id="tags">Tags</h2>
<ul>
<li>V-Sekai, interactive presence, unfolding complexity, avatar dots, maximum precision, angle constraints, twist constraint, sphere visualization, constraint palette, tool shadow, localized selection, proprioceptive action, switcher interface, tool palette, deselection method, user flow</li>
</ul>
</section>
<section id="further-reading" class="level2">
<h2 class="anchored" data-anchor-id="further-reading">Further Reading</h2>
<ol type="1">
<li><a href="https://github.com/v-sekai">V-Sekai · GitHub</a> - Official GitHub account for the V-Sekai development community focusing on social VR functionality for the Godot Engine.</li>
<li><a href="https://github.com/v-sekai/v-sekai-game">V-Sekai/v-sekai-game</a> - GitHub page for the V-Sekai open-source project, which brings social VR/VRSNS/metaverse components to the Godot Engine.</li>
<li><a href="https://github.com/V-Sekai/lasso">V-Sekai/lasso</a> - GitHub for vr interaction.</li>
</ol>
<p>AI assistant Aria assisted with this article.</p>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20241014-xr-interface-for-rigging.html</guid>
  <pubDate>Wed, 11 Dec 2024 15:00:09 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20241014-basic-realtime-interaction.html</link>
  <description><![CDATA[ 




<section id="draft-basic-real-time-interaction-for-character-and-world-scenes" class="level1">
<h1>Draft: Basic Real-Time Interaction for Character and World Scenes</h1>
<section id="the-context" class="level2">
<h2 class="anchored" data-anchor-id="the-context">The Context</h2>
<p>The project will enable users to interact in real-time by manipulating objects within a shared virtual environment, enhancing the user experience.</p>
</section>
<section id="the-problem-statement" class="level2">
<h2 class="anchored" data-anchor-id="the-problem-statement">The Problem Statement</h2>
<p>I want to extend V-Sekai’s functionality to support real-time interaction with uploaded character and world scenes. This includes the ability for users to manipulate objects within the scene and have those changes reflected in real-time for other users connected to the same session. Additionally, seamless integration of new elements into the environment is crucial.</p>
<p>Here’s a detailed breakdown of the features we plan to implement:</p>
<ul>
<li><strong>Real-time Interaction</strong>: Users can move and rotate objects in the scene. Changes appear instantly, providing immediate visual feedback.</li>
<li><strong>Networked Synchronization</strong>: When one user modifies something, the change is immediately visible to all other users in the same session.</li>
<li><strong>Object Persistence</strong>: Users can save their current scene setup to continue working on it later or retrieve it in another session.</li>
<li><strong>Dynamic Environment Integration</strong>: Facilitate the introduction of new interactive elements during live sessions.</li>
<li><strong>Mediator Role</strong>: A special user, called a mediator, can manage permissions like who can move what, start or end the session, and oversee interactions between users.</li>
<li><strong>Limited Scope</strong>: Initially, this feature will support multiple users interacting in one scene without additional complexities like handling multiple scenes or advanced physics.</li>
</ul>
<p>This upgrade leverages the existing functionality of V-Sekai for uploading and rendering game engine assets. It assumes the utilization of V-Sekai’s current game engine and networking capabilities, or the integration of clearly specified, readily available libraries or services to achieve the desired real-time interaction and synchronization.</p>
</section>
<section id="describe-how-your-proposal-will-work-with-code-pseudo-code-mock-ups-or-diagrams" class="level2">
<h2 class="anchored" data-anchor-id="describe-how-your-proposal-will-work-with-code-pseudo-code-mock-ups-or-diagrams">Describe how your proposal will work with code, pseudo-code, mock-ups, or diagrams</h2>
<section id="mock-up-diagram" class="level3">
<h3 class="anchored" data-anchor-id="mock-up-diagram">Mock-up Diagram</h3>
<pre class="plaintext"><code>[Scene Interaction Mock-up]
+------------------------------------------------+
|                                                |
|  [User1]                                       |
|    * (Object1) &lt;-- [Moving]                    |
|                                                |
|  [Tool Switcher Pie Menu]                      |
|    - Move Tool                                 |
|    - Rotate Tool                               |
|    - Close                                     |
|                                                |
|  [User2]                                       |
|    * (Object2)                                 |
|                                                |
+------------------------------------------------+</code></pre>
</section>
</section>
<section id="the-benefits" class="level2">
<h2 class="anchored" data-anchor-id="the-benefits">The Benefits</h2>
<p>Enhanced user engagement allows users to interact dynamically with objects, increasing the sense of presence. Establishing basic functionalities lays the foundation for future features that can include more complex interactions. Immediate feedback is crucial for collaborative environments, and intuitive tool selection through the Tool Switcher Pie Menu enhances workflow efficiency.</p>
</section>
<section id="the-downsides" class="level2">
<h2 class="anchored" data-anchor-id="the-downsides">The Downsides</h2>
<p>The initial features are limited to basic manipulations, which might not meet all user expectations. As the user base grows, the current simple synchronization mechanism may need significant enhancements.</p>
</section>
<section id="the-road-not-taken" class="level2">
<h2 class="anchored" data-anchor-id="the-road-not-taken">The Road Not Taken</h2>
<p>A full-scale interaction suite was initially considered, including scaling and advanced physics, but it was decided against due to complexity and resource constraints.</p>
</section>
<section id="the-infrequent-use-case" class="level2">
<h2 class="anchored" data-anchor-id="the-infrequent-use-case">The Infrequent Use Case</h2>
<p>While the system is designed for multiple users, it will also support single-user sessions, although this is not the primary focus.</p>
</section>
<section id="in-core-and-done-by-us" class="level2">
<h2 class="anchored" data-anchor-id="in-core-and-done-by-us">In Core and Done by Us</h2>
<p>This feature is core to the project’s mission of enhancing interactive capabilities and will be developed internally to ensure seamless integration and maintain control over quality.</p>
</section>
<section id="status" class="level2">
<h2 class="anchored" data-anchor-id="status">Status</h2>
<p>Status: Draft <!-- Draft | Proposed | Rejected | Accepted | Deprecated | Superseded by --></p>
</section>
<section id="decision-makers" class="level2">
<h2 class="anchored" data-anchor-id="decision-makers">Decision Makers</h2>
<ul>
<li>Project development team</li>
<li>Fire</li>
<li>Humble Tim</li>
</ul>
</section>
<section id="tags" class="level2">
<h2 class="anchored" data-anchor-id="tags">Tags</h2>
<p>Real-time interaction, basic object manipulation, networked synchronization, user engagement, virtual collaboration, intuitive tool switching</p>
</section>
<section id="further-reading" class="level2">
<h2 class="anchored" data-anchor-id="further-reading">Further Reading</h2>
<ol type="1">
<li><a href="https://github.com/project">Project GitHub</a> - Official GitHub account for the project development community focusing on enhancing virtual interaction capabilities.</li>
<li><a href="https://docs.project.com">Project Documentation</a> - Comprehensive documentation on the project’s features and development guidelines.</li>
</ol>
<p><em>AI assistant Aria assisted with this article.</em></p>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20241014-basic-realtime-interaction.html</guid>
  <pubDate>Wed, 11 Dec 2024 15:00:09 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20241014-app-updater.html</link>
  <description><![CDATA[ 




<section id="draft-updater-no-op-implementation-using-velopack" class="level1">
<h1>Draft: Updater No-Op Implementation Using Velopack</h1>
<section id="the-context" class="level2">
<h2 class="anchored" data-anchor-id="the-context">The Context</h2>
<p>V-Sekai needs frequent updates to improve and expand its VR features.</p>
</section>
<section id="the-problem-statement" class="level2">
<h2 class="anchored" data-anchor-id="the-problem-statement">The Problem Statement</h2>
<p>It’s essential to keep users informed during updates without distracting them with complex visuals.</p>
</section>
<section id="describe-how-your-proposal-will-work-with-code-pseudo-code-mock-ups-or-diagrams" class="level2">
<h2 class="anchored" data-anchor-id="describe-how-your-proposal-will-work-with-code-pseudo-code-mock-ups-or-diagrams">Describe how your proposal will work with code, pseudo-code, mock-ups, or diagrams</h2>
<section id="pseudo-code-using-velopack" class="level3">
<h3 class="anchored" data-anchor-id="pseudo-code-using-velopack">Pseudo-Code Using Velopack</h3>
<pre class="gdscript"><code>func update_application():
    show_text("Updating V-Sekai... Please wait.")
    if Velopack.check_for_updates():
        Velopack.perform_update()
    hide_text()
    notify("Update complete!")

func show_text(text):
    var label = Label.new()
    label.text = text
    add_child(label)

func hide_text():
    get_node("Label").queue_free()

func notify(message):
    show_message(message)</code></pre>
</section>
</section>
<section id="the-benefits" class="level2">
<h2 class="anchored" data-anchor-id="the-benefits">The Benefits</h2>
<ul>
<li><strong>Simplicity:</strong> Straightforward user communication.</li>
<li><strong>Clarity:</strong> Clear update status messages.</li>
<li><strong>Performance:</strong> Efficient use of resources through Velopack’s optimized update mechanisms.</li>
</ul>
</section>
<section id="the-downsides" class="level2">
<h2 class="anchored" data-anchor-id="the-downsides">The Downsides</h2>
<ul>
<li><strong>Lack of Visual Appeal:</strong> Simple text might seem less professional.</li>
<li><strong>Dependency on External Tool:</strong> Reliance on Velopack for update management.</li>
</ul>
</section>
<section id="the-road-not-taken" class="level2">
<h2 class="anchored" data-anchor-id="the-road-not-taken">The Road Not Taken</h2>
<p>A full graphical interface was considered but deemed too distracting for this phase.</p>
</section>
<section id="the-infrequent-use-case" class="level2">
<h2 class="anchored" data-anchor-id="the-infrequent-use-case">The Infrequent Use Case</h2>
<p>Users who rarely update might prefer more detailed visuals.</p>
</section>
<section id="in-core-and-done-by-us" class="level2">
<h2 class="anchored" data-anchor-id="in-core-and-done-by-us">In Core and Done by Us</h2>
<p>Handled internally to ensure seamless integration with Velopack.</p>
</section>
<section id="status" class="level2">
<h2 class="anchored" data-anchor-id="status">Status</h2>
<p>Status: Draft <!-- Draft | Proposed | Rejected | Accepted | Deprecated | Superseded by --></p>
</section>
<section id="decision-makers" class="level2">
<h2 class="anchored" data-anchor-id="decision-makers">Decision Makers</h2>
<ul>
<li>V-Sekai development team</li>
</ul>
</section>
<section id="tags" class="level2">
<h2 class="anchored" data-anchor-id="tags">Tags</h2>
<ul>
<li>V-Sekai</li>
<li>Updater</li>
<li>Velopack</li>
</ul>
</section>
<section id="further-reading" class="level2">
<h2 class="anchored" data-anchor-id="further-reading">Further Reading</h2>
<ol type="1">
<li><a href="https://github.com/v-sekai">V-Sekai · GitHub</a> - Official GitHub repository.</li>
<li><a href="https://github.com/v-sekai/v-sekai-game">V-Sekai/v-sekai-game</a> - Project page on GitHub.</li>
<li><a href="https://velopack.org/docs">Velopack Documentation</a> - Learn more about how Velopack manages application updates.</li>
</ol>
<p>AI assistant Aria assisted with this article.</p>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20241014-app-updater.html</guid>
  <pubDate>Wed, 11 Dec 2024 15:00:09 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20241011-recovering-makehuman-parameters.html</link>
  <description><![CDATA[ 




<section id="draft-recovering-makehuman-parameters-using-depth-map-comparison-with-godot-engine" class="level1">
<h1>Draft: Recovering MakeHuman Parameters Using Depth Map Comparison with Godot Engine</h1>
<section id="the-context" class="level2">
<h2 class="anchored" data-anchor-id="the-context">The Context</h2>
<p>In the realm of digital animation and character modeling, fitting an avatar to a specific image can enhance personalization and realism in various applications such as gaming and virtual reality.</p>
</section>
<section id="the-problem-statement" class="level2">
<h2 class="anchored" data-anchor-id="the-problem-statement">The Problem Statement</h2>
<p>The challenge lies in accurately estimating the parameters of a MakeHuman model from a given anime-style image to ensure the avatar closely resembles the original character.</p>
</section>
<section id="describe-how-your-proposal-will-work-with-code-pseudo-code-mock-ups-or-diagrams" class="level2">
<h2 class="anchored" data-anchor-id="describe-how-your-proposal-will-work-with-code-pseudo-code-mock-ups-or-diagrams">Describe how your proposal will work with code, pseudo-code, mock-ups, or diagrams</h2>
<section id="proposal-overview" class="level3">
<h3 class="anchored" data-anchor-id="proposal-overview">Proposal Overview</h3>
<p>We propose a system that utilizes depth map comparisons between rendered images from the Godot Engine and depth maps generated from anime images using Apple’s ML-Depth-Pro. This approach aims to optimize the MakeHuman parameters to recreate accurate 3D models of anime characters.</p>
<section id="key-objectives" class="level4">
<h4 class="anchored" data-anchor-id="key-objectives">Key Objectives</h4>
<ul>
<li><strong>Depth Map Generation</strong>: Generate depth maps from both anime images and Godot-rendered characters.</li>
<li><strong>Optimization</strong>: Employ machine learning techniques to minimize the differences between these depth maps, facilitating accurate parameter recovery.</li>
<li><strong>Cost Efficiency</strong>: Leverage open-source tools to maintain budget-friendliness.</li>
</ul>
</section>
<section id="scope" class="level4">
<h4 class="anchored" data-anchor-id="scope">Scope</h4>
<ul>
<li><strong>Input Data</strong>: Anime images with manually labeled MakeHuman parameters for initial calibration.</li>
<li><strong>Depth Comparison</strong>: Analyze the discrepancies between the depth maps produced by Godot and those derived from anime images.</li>
<li><strong>Optimization Process</strong>: Utilize a search algorithm (e.g., genetic algorithm or bayesian optimization) to iteratively adjust and determine optimal MakeHuman parameters.</li>
</ul>
</section>
<section id="work-breakdown" class="level4">
<h4 class="anchored" data-anchor-id="work-breakdown">Work Breakdown</h4>
<ol type="1">
<li><strong>Data Collection</strong>:
<ul>
<li><strong>Task</strong>: Manually label a small set of images with MakeHuman parameters.</li>
<li><strong>Outcome</strong>: Create a baseline dataset for initial optimization efforts.</li>
</ul></li>
<li><strong>Godot Integration</strong>:
<ul>
<li><strong>Task</strong>: Develop a script within Godot to render depth maps from configured MakeHuman models.</li>
<li><strong>Outcome</strong>: Prepare depth maps for subsequent comparison.</li>
</ul></li>
<li><strong>Optimization Algorithm</strong>:
<ul>
<li><strong>Task</strong>: Implement a cost-effective optimization algorithm using a suitable loss function (e.g., L2, Chamfer distance).</li>
<li><strong>Outcome</strong>: Establish a mechanism to identify the best matching MakeHuman parameters.</li>
</ul></li>
<li><strong>Testing and Refinement</strong>:
<ul>
<li><strong>Task</strong>: Systematically compare generated depth maps and refine the algorithm to improve accuracy.</li>
<li><strong>Timeline</strong>:
<ul>
<li><strong>Data Collection</strong>: 1 week</li>
<li><strong>Godot Integration</strong>: 2 weeks</li>
<li><strong>Optimization Model</strong>: 3 weeks</li>
<li><strong>Testing &amp; Refinement</strong>: 1 week</li>
<li><strong>Total Duration</strong>: 7 weeks</li>
</ul></li>
</ul></li>
</ol>
</section>
</section>
</section>
<section id="the-benefits" class="level2">
<h2 class="anchored" data-anchor-id="the-benefits">The Benefits</h2>
<p>This streamlined, budget-conscious methodology promises significant enhancements in personalization and realism in digital character modeling, making it ideal for applications in gaming and virtual reality where character authenticity is crucial.</p>
</section>
<section id="the-downsides" class="level2">
<h2 class="anchored" data-anchor-id="the-downsides">The Downsides</h2>
<ul>
<li><strong>Limited Creativity</strong>: Strict adherence to replicating existing images may limit creative modifications.</li>
<li><strong>Technical Complexity</strong>: The integration of multiple advanced technologies (depth sensing, machine learning, and 3D rendering) requires high technical expertise.</li>
</ul>
</section>
<section id="the-road-not-taken" class="level2">
<h2 class="anchored" data-anchor-id="the-road-not-taken">The Road Not Taken</h2>
<p>Alternative methods such as direct 3D scanning of physical models or manual tweaking of parameters were considered but deemed less efficient and scalable compared to our proposed automated depth comparison method.</p>
</section>
<section id="the-infrequent-use-case" class="level2">
<h2 class="anchored" data-anchor-id="the-infrequent-use-case">The Infrequent Use Case</h2>
<p>In cases where extremely high fidelity is required, such as in professional film production, additional manual adjustments by expert artists might still be necessary.</p>
</section>
<section id="in-core-and-done-by-us" class="level2">
<h2 class="anchored" data-anchor-id="in-core-and-done-by-us">In Core and Done by Us</h2>
<p>This project aligns with our core mission of enhancing digital interaction experiences and will be developed and maintained by our team.</p>
</section>
<section id="status" class="level2">
<h2 class="anchored" data-anchor-id="status">Status</h2>
<p>Status: Draft <!-- Draft | Proposed | Rejected | Accepted | Deprecated | Superseded by --></p>
</section>
<section id="decision-makers" class="level2">
<h2 class="anchored" data-anchor-id="decision-makers">Decision Makers</h2>
<ul>
<li>V-Sekai development team</li>
</ul>
</section>
<section id="tags" class="level2">
<h2 class="anchored" data-anchor-id="tags">Tags</h2>
<ul>
<li>V-Sekai</li>
</ul>
</section>
<section id="further-reading" class="level2">
<h2 class="anchored" data-anchor-id="further-reading">Further Reading</h2>
<ol type="1">
<li><a href="https://github.com/v-sekai">V-Sekai · GitHub</a> - Official GitHub account for the V-Sekai development community focusing on social VR functionality for the Godot Engine.</li>
<li><a href="https://github.com/v-sekai/v-sekai-game">V-Sekai/v-sekai-game</a> - GitHub page for the V-Sekai open-source project, which brings social VR/VRSNS/metaverse components to the Godot Engine.</li>
<li><a href="https://huggingface.co/spaces/A19grey/Depth-Pro-in-Meters">DepthPro Demo with 3D Visualization</a></li>
<li><a href="https://ludwig.ai/0.4/developer_guide/hyper_parameter_optimization/">Hyper_parameter_optimization like bayensian optimization</a></li>
</ol>
<p>AI assistant Aria assisted with this article.</p>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20241011-recovering-makehuman-parameters.html</guid>
  <pubDate>Wed, 11 Dec 2024 15:00:09 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20241006-restore-onedrive-shortcut-overrides.html</link>
  <description><![CDATA[ 




<section id="accepted-restoring-default-user-directory-structure-in-windows-11" class="level1">
<h1>Accepted: Restoring Default User Directory Structure in Windows 11</h1>
<section id="the-context" class="level2">
<h2 class="anchored" data-anchor-id="the-context">The Context</h2>
<p>Using Windows 11.</p>
</section>
<section id="the-problem-statement" class="level2">
<h2 class="anchored" data-anchor-id="the-problem-statement">The Problem Statement</h2>
<p>Microsoft has configured OneDrive to automatically move key user folders such as Documents, Desktop, and others from the user directory into the OneDrive folder. This change can disrupt users’ familiar file organization and system workflows.</p>
</section>
<section id="describe-how-your-proposal-will-work-with-code-pseudo-code-mock-ups-or-diagrams" class="level2">
<h2 class="anchored" data-anchor-id="describe-how-your-proposal-will-work-with-code-pseudo-code-mock-ups-or-diagrams">Describe how your proposal will work with code, pseudo-code, mock-ups, or diagrams</h2>
<p>The solution involves two main steps:</p>
<ol type="1">
<li><strong>Disabling OneDrive Sync</strong>: Users need to pause or stop OneDrive from syncing these folders.</li>
<li><strong>Running a Restore Default Paths Script</strong>: Execute a script that resets the default paths of user directories back to their original locations on the local drive.</li>
</ol>
</section>
<section id="the-benefits" class="level2">
<h2 class="anchored" data-anchor-id="the-benefits">The Benefits</h2>
<ul>
<li>Restores traditional file paths for ease of access and familiarity.</li>
<li>Reduces dependency on cloud synchronization for essential folders.</li>
<li>Improves system performance by reducing unnecessary sync operations.</li>
</ul>
</section>
<section id="the-downsides" class="level2">
<h2 class="anchored" data-anchor-id="the-downsides">The Downsides</h2>
<ul>
<li>Manual intervention required by users not comfortable with script execution.</li>
<li>Potential data discrepancies if files are not fully synchronized before the change.</li>
</ul>
</section>
<section id="the-road-not-taken" class="level2">
<h2 class="anchored" data-anchor-id="the-road-not-taken">The Road Not Taken</h2>
<p>Alternative solutions like using third-party tools or different cloud services were considered but dismissed due to increased complexity and potential security concerns.</p>
</section>
<section id="the-infrequent-use-case" class="level2">
<h2 class="anchored" data-anchor-id="the-infrequent-use-case">The Infrequent Use Case</h2>
<p>Users who operate primarily offline or have strict data handling policies may find this change particularly beneficial.</p>
</section>
<section id="in-core-and-done-by-us" class="level2">
<h2 class="anchored" data-anchor-id="in-core-and-done-by-us">In Core and Done by Us</h2>
<p>This proposal is to be implemented internally within the V-Sekai development team’s systems before considering broader deployment.</p>
</section>
<section id="status" class="level2">
<h2 class="anchored" data-anchor-id="status">Status</h2>
<p>Status: Accepted <!-- Draft | Proposed | Rejected | Accepted | Deprecated | Superseded by --></p>
</section>
<section id="decision-makers" class="level2">
<h2 class="anchored" data-anchor-id="decision-makers">Decision Makers</h2>
<ul>
<li>V-Sekai development team</li>
</ul>
</section>
<section id="tags" class="level2">
<h2 class="anchored" data-anchor-id="tags">Tags</h2>
<ul>
<li>V-Sekai</li>
</ul>
</section>
<section id="further-reading" class="level2">
<h2 class="anchored" data-anchor-id="further-reading">Further Reading</h2>
<ol type="1">
<li><a href="https://github.com/v-sekai">V-Sekai · GitHub</a> - Official GitHub account for the V-Sekai development community focusing on social VR functionality for the Godot Engine.</li>
<li><a href="https://github.com/v-sekai/v-sekai-game">V-Sekai/v-sekai-game</a> - GitHub page for the V-Sekai open-source project, which brings social VR/VRSNS/metaverse components to the Godot Engine.</li>
<li><a href="https://www.winhelponline.com/blog/windows-10-shell-folders-paths-defaults-restore/">Windows 10/11 User Shell Folders Restore Default Paths</a></li>
</ol>
<p>AI assistant Aria assisted with this article.</p>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20241006-restore-onedrive-shortcut-overrides.html</guid>
  <pubDate>Wed, 11 Dec 2024 15:00:09 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20241001-small-game-tools.html</link>
  <description><![CDATA[ 




<section id="draft-small-v-sekai-creation-tools" class="level1">
<h1>Draft: Small V-Sekai Creation Tools</h1>
<section id="the-context" class="level2">
<h2 class="anchored" data-anchor-id="the-context">The Context</h2>
<p>The Godot Editor now integrates a 2D editor on a screen for VR, which cannot be fully optimized for VR screens like the Meta Quest 3. However, the Quest 3’s multiwindow support offers new possibilities.</p>
</section>
<section id="the-problem-statement" class="level2">
<h2 class="anchored" data-anchor-id="the-problem-statement">The Problem Statement</h2>
<p>We want to create a suite of tools for V-Sekai game development that leverages the capabilities of current hardware without requiring full VR integration.</p>
</section>
<section id="describe-how-your-proposal-will-work-with-code-pseudo-code-mock-ups-or-diagrams" class="level2">
<h2 class="anchored" data-anchor-id="describe-how-your-proposal-will-work-with-code-pseudo-code-mock-ups-or-diagrams">Describe how your proposal will work with code, pseudo-code, mock-ups, or diagrams</h2>
<p>Develop a series of small, efficient tools that can connect remotely to the V-Sekai game project, facilitating world creation and other development tasks from a 2D interface displayed within a VR environment.</p>
</section>
<section id="the-benefits" class="level2">
<h2 class="anchored" data-anchor-id="the-benefits">The Benefits</h2>
<ul>
<li><strong>Enhanced Accessibility</strong>: Developers can use tools within a VR environment without the need for full VR tool conversion, combining comfort with functionality.</li>
<li><strong>Real-Time Interaction</strong>: Enables immediate feedback and interaction with the game world, enhancing development speed and efficiency.</li>
<li><strong>Innovative Approach</strong>: By using a hybrid approach, V-Sekai remains at the cutting edge, integrating new technologies while maintaining usability.</li>
</ul>
</section>
<section id="the-downsides" class="level2">
<h2 class="anchored" data-anchor-id="the-downsides">The Downsides</h2>
<ul>
<li><strong>Technical Challenges</strong>: Creating tools that function seamlessly between 2D and VR environments is complex and may require significant resources.</li>
<li><strong>User Adaptation</strong>: There might be a learning curve as developers adjust to using a 2D interface in a VR context.</li>
<li><strong>Hardware Limitations</strong>: The performance and functionality are still bound by the limitations of existing VR hardware like the Meta Quest 3.</li>
</ul>
</section>
<section id="the-road-not-taken" class="level2">
<h2 class="anchored" data-anchor-id="the-road-not-taken">The Road Not Taken</h2>
<p>Full VR development tools and augmented reality interfaces were considered but deemed not yet viable for our goals due to current technological constraints and development focus.</p>
</section>
<section id="the-infrequent-use-case" class="level2">
<h2 class="anchored" data-anchor-id="the-infrequent-use-case">The Infrequent Use Case</h2>
<p>For developers who prefer traditional desktop-based environments, or where VR integration provides no clear advantage, existing non-VR tools will continue to be supported and developed.</p>
</section>
<section id="in-core-and-done-by-us" class="level2">
<h2 class="anchored" data-anchor-id="in-core-and-done-by-us">In Core and Done by Us</h2>
<p>This initiative aligns with our core mission to innovate within accessible VR and game development tools, and will be developed internally by the V-Sekai team.</p>
</section>
<section id="status" class="level2">
<h2 class="anchored" data-anchor-id="status">Status</h2>
<p>Status: Draft <!-- Draft | Proposed | Rejected | Accepted | Deprecated | Superseded by --></p>
</section>
<section id="decision-makers" class="level2">
<h2 class="anchored" data-anchor-id="decision-makers">Decision Makers</h2>
<ul>
<li>V-Sekai development team</li>
<li>Humbletim</li>
</ul>
</section>
<section id="tags" class="level2">
<h2 class="anchored" data-anchor-id="tags">Tags</h2>
<ul>
<li>V-Sekai</li>
</ul>
</section>
<section id="further-reading" class="level2">
<h2 class="anchored" data-anchor-id="further-reading">Further Reading</h2>
<ol type="1">
<li><a href="https://github.com/v-sekai">V-Sekai · GitHub</a> - Official GitHub account for the V-Sekai development community focusing on social VR functionality for the Godot Engine.</li>
<li><a href="https://github.com/v-sekai/v-sekai-game">V-Sekai/v-sekai-game</a> - GitHub page for the V-Sekai open-source project, which brings social VR/VRSNS/metaverse components to the Godot Engine.</li>
</ol>
<p>AI assistant Aria assisted with this article.</p>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20241001-small-game-tools.html</guid>
  <pubDate>Wed, 11 Dec 2024 15:00:09 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20240914-godot-engine-xr-elite-conference-setup.html</link>
  <description><![CDATA[ 




<section id="accepted-godot-engine-xr-elite-hmd-conference-setup" class="level1">
<h1>Accepted: Godot Engine XR Elite HMD Conference Setup</h1>
<section id="the-context" class="level2">
<h2 class="anchored" data-anchor-id="the-context">The Context</h2>
<p>Fire, an independent developer previously contracted with the Godot Foundation, plans to demonstrate the capabilities of the Godot Engine XR Team’s work on the VIVE headset at an upcoming conference. This setup is crucial for showcasing advanced VR features using the XR Elite Headset.</p>
</section>
<section id="the-problem-statement" class="level2">
<h2 class="anchored" data-anchor-id="the-problem-statement">The Problem Statement</h2>
<p>Setting up a reliable and efficient demonstration environment for the XR Elite Headset at a conference can be challenging due to potential network issues and hardware integration complexities.</p>
</section>
<section id="describe-how-your-proposal-will-work-with-code-pseudo-code-mock-ups-or-diagrams" class="level2">
<h2 class="anchored" data-anchor-id="describe-how-your-proposal-will-work-with-code-pseudo-code-mock-ups-or-diagrams">Describe how your proposal will work with code, pseudo-code, mock-ups, or diagrams</h2>
<p>The proposed setup involves several components to ensure a stable and high-performance demonstration:</p>
<ol type="1">
<li><p><strong>Hardware Connection</strong>:</p>
<ul>
<li>Connect the XR Elite Headset to a USB-C hub.</li>
<li>Attach the Vive Ultimate Tracker dongle and a Belkin USB-C to Gigabit Ethernet Adapter to the hub.</li>
</ul></li>
<li><p><strong>Network Configuration</strong>:</p>
<ul>
<li>Use a wired ethernet connection to avoid Wi-Fi instability common in conference venues.</li>
<li>Set a fixed IP address for the VIVE Business Streaming server using the VBSIpSetting.exe tool.</li>
</ul></li>
<li><p><strong>Software Setup</strong>:</p>
<ul>
<li>Ensure the business streaming server has a physical display connected to prevent the SteamVR overlay issue.</li>
<li>Run SteamVR for VR demonstrations.</li>
</ul></li>
<li><p><strong>Additional Stability Measures</strong>:</p>
<ul>
<li>Disable Wi-Fi on the XR Elite Headset to rely solely on the wired connection.</li>
<li>Consider using a gigabit travel router/switch to manage and shorten routing internally at the venue.</li>
</ul></li>
</ol>
</section>
<section id="the-benefits" class="level2">
<h2 class="anchored" data-anchor-id="the-benefits">The Benefits</h2>
<ul>
<li><strong>Reliability</strong>: Wired connections reduce the risk of connectivity issues during live demonstrations.</li>
<li><strong>Performance</strong>: Direct network connections and optimized settings ensure smooth operation of VR applications.</li>
<li><strong>Professional Presentation</strong>: A stable setup reflects well on the Godot Engine project and its capabilities in VR.</li>
</ul>
</section>
<section id="the-downsides" class="level2">
<h2 class="anchored" data-anchor-id="the-downsides">The Downsides</h2>
<ul>
<li><strong>Complexity</strong>: The setup requires careful configuration and might be daunting for less technical users.</li>
<li><strong>Equipment Dependency</strong>: Relies on specific hardware and software that may not be readily available at all venues.</li>
</ul>
</section>
<section id="the-road-not-taken" class="level2">
<h2 class="anchored" data-anchor-id="the-road-not-taken">The Road Not Taken</h2>
<p>Alternative simpler setups were considered but rejected due to their reliance on less stable wireless connections which could compromise the demonstration’s effectiveness.</p>
</section>
<section id="the-infrequent-use-case" class="level2">
<h2 class="anchored" data-anchor-id="the-infrequent-use-case">The Infrequent Use Case</h2>
<p>In cases where a direct internet connection is unavailable, additional configurations like mobile routers or other networking equipment might be necessary.</p>
</section>
<section id="in-core-and-done-by-us" class="level2">
<h2 class="anchored" data-anchor-id="in-core-and-done-by-us">In Core and Done by Us</h2>
<p>This proposal aligns with our core mission to showcase the best of Godot Engine’s VR capabilities and will be implemented by fire with support from the V-Sekai development team.</p>
</section>
<section id="status" class="level2">
<h2 class="anchored" data-anchor-id="status">Status</h2>
<p>Status: Accepted <!-- Draft | Proposed | Rejected | Accepted | Deprecated | Superseded by --></p>
</section>
<section id="decision-makers" class="level2">
<h2 class="anchored" data-anchor-id="decision-makers">Decision Makers</h2>
<ul>
<li>V-Sekai development team</li>
</ul>
</section>
<section id="tags" class="level2">
<h2 class="anchored" data-anchor-id="tags">Tags</h2>
<ul>
<li>V-Sekai</li>
</ul>
</section>
<section id="further-reading" class="level2">
<h2 class="anchored" data-anchor-id="further-reading">Further Reading</h2>
<ol type="1">
<li><a href="https://github.com/v-sekai">V-Sekai · GitHub</a> - Official GitHub account for the V-Sekai development community focusing on social VR functionality for the Godot Engine.</li>
<li><a href="https://github.com/v-sekai/v-sekai-game">V-Sekai/v-sekai-game</a> - GitHub page for the V-Sekai open-source project, which brings social VR/VRSNS/metaverse components to the Godot Engine.</li>
</ol>
<p>AI assistant Aria assisted with this article.</p>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20240914-godot-engine-xr-elite-conference-setup.html</guid>
  <pubDate>Wed, 11 Dec 2024 15:00:09 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20240905-revised-tracker-configuration-and-constraints.html</link>
  <description><![CDATA[ 




<section id="draft-revised-tracker-configuration-and-constraints-for-htc-vive-xr-elite" class="level1">
<h1>Draft: Revised Tracker Configuration and Constraints for HTC VIVE XR Elite</h1>
<section id="the-context" class="level2">
<h2 class="anchored" data-anchor-id="the-context">The Context</h2>
<p>In virtual reality (VR), precise motion tracking is import for immersive experiences. Effective tracker configuration is essential to enhance interaction within VR environments, specifically for the HTC VIVE XR Elite.</p>
</section>
<section id="the-problem-statement" class="level2">
<h2 class="anchored" data-anchor-id="the-problem-statement">The Problem Statement</h2>
<p>Tracker configurations distribution across available dongles, affects the setup of motion capture in VR applications, particularly with the HTC VIVE XR Elite.</p>
</section>
<section id="describe-how-your-proposal-will-work-with-code-pseudo-code-mock-ups-or-diagrams" class="level2">
<h2 class="anchored" data-anchor-id="describe-how-your-proposal-will-work-with-code-pseudo-code-mock-ups-or-diagrams">Describe how your proposal will work with code, pseudo-code, mock-ups, or diagrams</h2>
<section id="dongle-1-connected-to-htc-vive-xr-elite-hmd" class="level3">
<h3 class="anchored" data-anchor-id="dongle-1-connected-to-htc-vive-xr-elite-hmd">Dongle 1 (connected to HTC VIVE XR Elite HMD)</h3>
<ul>
<li><strong>Hips</strong> (1 tracker)</li>
<li><strong>Foot Right</strong> (1 tracker)</li>
<li><strong>Foot Left</strong> (1 tracker)</li>
<li><strong>Elbow Left</strong> (1 tracker)</li>
<li><strong>Elbow Right</strong> (1 tracker)</li>
</ul>
</section>
<section id="dongle-2-connected-to-pc" class="level3">
<h3 class="anchored" data-anchor-id="dongle-2-connected-to-pc">Dongle 2 (connected to PC)</h3>
<ul>
<li><strong>Knee Right</strong> (1 tracker)</li>
<li><strong>Knee Left</strong> (1 tracker)</li>
<li><strong>Chest</strong> (1 tracker)</li>
<li><strong>Hips</strong> (1 tracker optional)</li>
<li><strong>Chest</strong> (1 tracker optional)</li>
</ul>
</section>
<section id="constraints" class="level3">
<h3 class="anchored" data-anchor-id="constraints">Constraints</h3>
<p>Each dongle supports a maximum of <strong>5 trackers</strong>. This constraint is critical in determining how trackers are distributed between the two dongles to ensure optimal performance without exceeding the connectivity limit, specifically for the HTC VIVE XR Elite.</p>
</section>
<section id="rationale-behind-the-revised-setup" class="level3">
<h3 class="anchored" data-anchor-id="rationale-behind-the-revised-setup">Rationale Behind the Revised Setup</h3>
<section id="dongle-1-hmd" class="level4">
<h4 class="anchored" data-anchor-id="dongle-1-hmd"><strong>Dongle 1 (HMD)</strong></h4>
<ul>
<li><strong>Enhanced Lower Limb Tracking</strong>: By connecting both knee trackers to the HMD dongle, we ensure precise tracking of lower limb movements, which is essential for accurate motion capture in activities that involve significant leg movement.</li>
<li><strong>Upper Extremity Tracking</strong>: Including both elbow trackers on this dongle allows for detailed arm movement tracking, enhancing the realism and responsiveness of upper body interactions in VR.</li>
</ul>
</section>
<section id="dongle-2-pc" class="level4">
<h4 class="anchored" data-anchor-id="dongle-2-pc"><strong>Dongle 2 (PC)</strong></h4>
<ul>
<li><strong>Comprehensive Upper Body Tracking</strong>:
<ul>
<li><strong>Chest and Hips Trackers</strong>: These trackers are crucial for capturing the core movements of the body, providing a stable base for upper body motion tracking.</li>
<li><strong>Dual Foot Tracking</strong>: Placing the foot trackers on the PC-connected dongle ensures that foot movements are captured accurately, which is vital for walking, running, and other foot-based interactions in VR environments.</li>
</ul></li>
</ul>
</section>
</section>
</section>
<section id="the-benefits" class="level2">
<h2 class="anchored" data-anchor-id="the-benefits">The Benefits</h2>
<ul>
<li><strong>Improved Accuracy</strong>: Optimized tracker placement enhances the precision of motion capture.</li>
<li><strong>Enhanced User Experience</strong>: More accurate tracking translates to a more immersive and responsive VR experience.</li>
<li><strong>Scalability</strong>: This setup allows for easy adjustments and scalability as new trackers or technologies become available.</li>
</ul>
</section>
<section id="the-downsides" class="level2">
<h2 class="anchored" data-anchor-id="the-downsides">The Downsides</h2>
<ul>
<li><strong>Complex Setup</strong>: Initial configuration and calibration may be more complex and time-consuming.</li>
<li><strong>Hardware Dependency</strong>: Performance is heavily dependent on the quality and capability of the hardware used.</li>
</ul>
</section>
<section id="the-road-not-taken" class="level2">
<h2 class="anchored" data-anchor-id="the-road-not-taken">The Road Not Taken</h2>
<p>Alternative configurations that involved different distributions of trackers were considered but were not pursued due to potential compromises in tracking accuracy and performance.</p>
</section>
<section id="the-infrequent-use-case" class="level2">
<h2 class="anchored" data-anchor-id="the-infrequent-use-case">The Infrequent Use Case</h2>
<p>In cases where extreme precision is not required, such as in less interactive VR applications, a simpler tracker setup might suffice.</p>
</section>
<section id="in-core-and-done-by-us" class="level2">
<h2 class="anchored" data-anchor-id="in-core-and-done-by-us">In Core and Done by Us</h2>
<p>This proposal aligns with our core mission to push the boundaries of VR technology and will be implemented by our internal development team, focusing on the HTC VIVE XR Elite.</p>
</section>
<section id="status" class="level2">
<h2 class="anchored" data-anchor-id="status">Status</h2>
<p>Status: Draft <!-- Draft | Proposed | Rejected | Accepted | Deprecated | Superseded by --></p>
</section>
<section id="decision-makers" class="level2">
<h2 class="anchored" data-anchor-id="decision-makers">Decision Makers</h2>
<ul>
<li>V-Sekai development team</li>
</ul>
</section>
<section id="tags" class="level2">
<h2 class="anchored" data-anchor-id="tags">Tags</h2>
<ul>
<li>V-Sekai</li>
<li>HTC VIVE XR Elite</li>
</ul>
</section>
<section id="further-reading" class="level2">
<h2 class="anchored" data-anchor-id="further-reading">Further Reading</h2>
<ol type="1">
<li><a href="https://github.com/v-sekai">V-Sekai · GitHub</a> - Official GitHub account for the V-Sekai development community focusing on social VR functionality for the Godot Engine.</li>
<li><a href="https://github.com/v-sekai/v-sekai-game">V-Sekai/v-sekai-game</a> - GitHub page for the V-Sekai open-source project, which brings social VR/VRSNS/metaverse components to the Godot Engine.</li>
</ol>
<p>AI assistant Aria assisted with this article.</p>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20240905-revised-tracker-configuration-and-constraints.html</guid>
  <pubDate>Wed, 11 Dec 2024 15:00:09 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20240830-use-dokku-to-host-vsk-backend.html</link>
  <description><![CDATA[ 




<section id="draft-transition-to-dokku-from-kubernetes-proposal" class="level1">
<h1>Draft: Transition to Dokku from Kubernetes Proposal</h1>
<section id="overview" class="level2">
<h2 class="anchored" data-anchor-id="overview">Overview</h2>
<p>This proposal outlines the transition of our backend services from Kubernetes to Dokku, aiming to reduce complexity and maintenance costs.</p>
</section>
<section id="context" class="level2">
<h2 class="anchored" data-anchor-id="context">Context</h2>
<p>Dokku is a minimalistic, open-source PAAS that provides a cost-effective alternative to Heroku. Our current use of Kubernetes has become prohibitively complex and expensive.</p>
</section>
<section id="problem-statement" class="level2">
<h2 class="anchored" data-anchor-id="problem-statement">Problem Statement</h2>
<p>We aim to migrate our backend services from Kubernetes to Dokku to simplify operations and reduce expenses.</p>
</section>
<section id="implementation-details" class="level2">
<h2 class="anchored" data-anchor-id="implementation-details">Implementation Details</h2>
<section id="services-migration" class="level3">
<h3 class="anchored" data-anchor-id="services-migration">Services Migration</h3>
<ul>
<li><strong>PostgreSQL</strong>: Deploy using the <a href="https://github.com/dokku/dokku-postgres">Dokku PostgreSQL plugin</a>.</li>
<li><strong>File Object Store</strong>: Implement an S3 compatible storage solution within Dokku.</li>
<li><strong>Elixir “Uro” Backend</strong>: Ensure seamless deployment and operation of our Elixir application on Dokku.</li>
<li><strong>Caddy</strong>: Set up Caddy as a web server and reverse proxy for secure HTTP and SSL management.</li>
<li><strong>RabbitMQ</strong>: Integrate RabbitMQ for robust messaging and queuing capabilities.</li>
<li><strong>Backups</strong>: Implement an S3 compatible backup storage solution.</li>
<li><strong>Telemetry</strong>: Use OpenTelemetry for monitoring and tracing by integrating it with Signoz as outlined in <a href="https://signoz.io/blog/opentelemetry-apm/">this guide</a>.</li>
</ul>
</section>
<section id="code-example" class="level3">
<h3 class="anchored" data-anchor-id="code-example">Code Example</h3>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb1-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Install Dokku plugins</span></span>
<span id="cb1-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">dokku</span> plugin:install https://github.com/dokku/dokku-postgres.git postgres</span>
<span id="cb1-3"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">dokku</span> plugin:install https://github.com/dokku/dokku-rabbitmq.git rabbitmq</span>
<span id="cb1-4"></span>
<span id="cb1-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create PostgreSQL service</span></span>
<span id="cb1-6"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">dokku</span> postgres:create my-database</span>
<span id="cb1-7"></span>
<span id="cb1-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create RabbitMQ service</span></span>
<span id="cb1-9"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">dokku</span> rabbitmq:create my-messaging-service</span>
<span id="cb1-10"></span>
<span id="cb1-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Deploy Elixir application</span></span>
<span id="cb1-12"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">git</span> push dokku master</span>
<span id="cb1-13"></span>
<span id="cb1-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Setup OpenTelemetry</span></span>
<span id="cb1-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Follow the specific instructions from the Signoz guide</span></span></code></pre></div>
</section>
</section>
<section id="benefits" class="level2">
<h2 class="anchored" data-anchor-id="benefits">Benefits</h2>
<ul>
<li><strong>Cost Efficiency</strong>: Significant reduction in operational and maintenance costs.</li>
<li><strong>Simplicity</strong>: Streamlined management and deployment processes.</li>
<li><strong>Scalability</strong>: Adequate scaling capabilities without Kubernetes’ overhead.</li>
<li><strong>Security</strong>: Enhanced security features with automatic SSL through Caddy.</li>
<li><strong>Reliability</strong>: Dependable inter-service communication with RabbitMQ.</li>
</ul>
</section>
<section id="potential-downsides" class="level2">
<h2 class="anchored" data-anchor-id="potential-downsides">Potential Downsides</h2>
<ul>
<li><strong>Feature Limitations</strong>: Dokku may not support all Kubernetes features.</li>
<li><strong>Migration Challenges</strong>: Initial hurdles in transferring services and data.</li>
</ul>
</section>
<section id="alternatives-considered" class="level2">
<h2 class="anchored" data-anchor-id="alternatives-considered">Alternatives Considered</h2>
<ul>
<li>Persisting with Kubernetes despite its drawbacks.</li>
<li>Adopting other PAAS solutions like Heroku or AWS Elastic Beanstalk.</li>
</ul>
</section>
<section id="special-considerations" class="level2">
<h2 class="anchored" data-anchor-id="special-considerations">Special Considerations</h2>
<p>Handling very high traffic levels might require additional Dokku configurations, which are inherently simpler in Kubernetes.</p>
</section>
<section id="project-management" class="level2">
<h2 class="anchored" data-anchor-id="project-management">Project Management</h2>
<p>The transition will be managed internally by our development team.</p>
</section>
<section id="current-status" class="level2">
<h2 class="anchored" data-anchor-id="current-status">Current Status</h2>
<p><strong>Status</strong>: Proposed</p>
</section>
<section id="decision-makers" class="level2">
<h2 class="anchored" data-anchor-id="decision-makers">Decision Makers</h2>
<ul>
<li>V-Sekai development team</li>
</ul>
</section>
<section id="tags" class="level2">
<h2 class="anchored" data-anchor-id="tags">Tags</h2>
<ul>
<li><code>V-Sekai</code></li>
</ul>
</section>
<section id="further-information" class="level2">
<h2 class="anchored" data-anchor-id="further-information">Further Information</h2>
<ol type="1">
<li><a href="https://github.com/v-sekai">V-Sekai GitHub</a> - Explore more about V-Sekai’s initiatives on social VR.</li>
<li><a href="https://github.com/v-sekai/v-sekai-game">V-Sekai Game Repository</a> - Official repository for the V-Sekai game project.</li>
<li><a href="https://www.tigrisdata.com/docs/pricing/">TigrisData</a></li>
</ol>
<p><em>Assisted by AI assistant Aria.</em></p>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20240830-use-dokku-to-host-vsk-backend.html</guid>
  <pubDate>Wed, 11 Dec 2024 15:00:09 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20240830-pcie-lane-depletion-thunderbolt-4-issues.html</link>
  <description><![CDATA[ 




<section id="accepted-pci-e-lane-depletion-and-thunderbolt-4-issues" class="level1">
<h1>Accepted: PCI-E Lane Depletion and Thunderbolt 4 Issues</h1>
<section id="the-context" class="level2">
<h2 class="anchored" data-anchor-id="the-context">The Context</h2>
<p>In modern computing, PCI-E lanes are a critical resource for connecting various high-speed components such as GPUs, SSDs, and network cards. However, the number of available PCI-E lanes is finite and can become a bottleneck when multiple high-bandwidth devices are connected. This proposal addresses the issue of PCI-E lane depletion, particularly in systems utilizing Thunderbolt 4.</p>
</section>
<section id="the-problem-statement" class="level2">
<h2 class="anchored" data-anchor-id="the-problem-statement">The Problem Statement</h2>
<p>When all PCI-E slots are utilized, especially with high-bandwidth devices like GPUs and Thunderbolt 4 controllers, users may experience performance degradation or device malfunctions due to insufficient PCI-E lanes. This problem was highlighted by a user who reported that their Thunderbolt 4 connection broke after using their last PCI-E slot.</p>
</section>
<section id="proposal-implementation" class="level2">
<h2 class="anchored" data-anchor-id="proposal-implementation">Proposal Implementation</h2>
<p>To mitigate this issue, it is recommended to keep the last PCI-E slot empty to ensure sufficient lanes for all connected devices.</p>
<pre class="plaintext"><code>+-------------------+
|   CPU             |
|                   |
| PCI-E Lanes    |
+---------+---------+
          |
          v
+---------+---------+
|       PCI-E       |
|      Switch       |
+---------+---------+
          |
          v
+---------+---------+---------+---------+
|   GPU   | Thunderbolt 4 |  NVMe SSD  |
|     |           |        |
+---------+---------+---------+---------+</code></pre>
</section>
<section id="the-benefits" class="level2">
<h2 class="anchored" data-anchor-id="the-benefits">The Benefits</h2>
<ol type="1">
<li><strong>Improved System Stability</strong>: Ensuring sufficient PCI-E lanes for all devices will prevent system crashes and performance issues.</li>
<li><strong>Optimized Resource Allocation</strong>: Users can make informed decisions about which devices to prioritize based on available PCI-E lanes.</li>
<li><strong>Enhanced User Experience</strong>: By avoiding unexpected device failures, users will have a more reliable and predictable computing experience.</li>
</ol>
</section>
<section id="the-downsides" class="level2">
<h2 class="anchored" data-anchor-id="the-downsides">The Downsides</h2>
<ol type="1">
<li><strong>Complexity</strong>: Implementing checks for PCI-E lane availability adds complexity to system configuration and management.</li>
<li><strong>Hardware Limitations</strong>: Users with limited PCI-E lanes may need to upgrade their hardware to fully utilize all desired devices.</li>
</ol>
</section>
<section id="the-road-not-taken" class="level2">
<h2 class="anchored" data-anchor-id="the-road-not-taken">The Road Not Taken</h2>
<p>An alternative approach could be to develop software solutions that dynamically manage PCI-E lane allocation based on real-time usage patterns. However, this would require significant changes to both hardware and software architectures and may not be feasible for all users.</p>
</section>
<section id="the-infrequent-use-case" class="level2">
<h2 class="anchored" data-anchor-id="the-infrequent-use-case">The Infrequent Use Case</h2>
<p>In scenarios where users only utilize a single high-bandwidth device, such as a GPU, PCI-E lane depletion is unlikely to be an issue. This proposal primarily targets power users and professionals with multiple high-bandwidth devices.</p>
</section>
<section id="in-core-and-done-by-us" class="level2">
<h2 class="anchored" data-anchor-id="in-core-and-done-by-us">In Core and Done by Us</h2>
<p>The V-Sekai development team will integrate PCI-E lane checks into the system configuration process, ensuring that users are alerted to potential lane depletion issues before they occur.</p>
</section>
<section id="status" class="level2">
<h2 class="anchored" data-anchor-id="status">Status</h2>
<p>Status: Accepted <!-- Draft | Proposed | Rejected | Accepted | Deprecated | Superseded by --></p>
</section>
<section id="decision-makers" class="level2">
<h2 class="anchored" data-anchor-id="decision-makers">Decision Makers</h2>
<ul>
<li>V-Sekai development team</li>
</ul>
</section>
<section id="tags" class="level2">
<h2 class="anchored" data-anchor-id="tags">Tags</h2>
<ul>
<li>V-Sekai</li>
</ul>
</section>
<section id="further-reading" class="level2">
<h2 class="anchored" data-anchor-id="further-reading">Further Reading</h2>
<ol type="1">
<li><a href="https://github.com/v-sekai">V-Sekai · GitHub</a> - Official GitHub account for the V-Sekai development community focusing on social VR functionality for the Godot Engine.</li>
<li><a href="https://github.com/v-sekai/v-sekai-game">V-Sekai/v-sekai-game</a> - GitHub page for the V-Sekai open-source project, which brings social VR/VRSNS/metaverse components to the Godot Engine.</li>
</ol>
<p>AI assistant Aria assisted with this article.</p>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20240830-pcie-lane-depletion-thunderbolt-4-issues.html</guid>
  <pubDate>Wed, 11 Dec 2024 15:00:09 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20240824-ffmpeg-wav-mic-speaker-play.html</link>
  <description><![CDATA[ 




<section id="draft-ffmpeg-wavemic-and-speakerplay" class="level1">
<h1>Draft: FFMPEG Wave/Mic and Speaker/Play</h1>
<section id="the-context" class="level2">
<h2 class="anchored" data-anchor-id="the-context">The Context</h2>
<p>Testing audio input and output for VOIP applications.</p>
</section>
<section id="the-problem-statement" class="level2">
<h2 class="anchored" data-anchor-id="the-problem-statement">The Problem Statement</h2>
<p>Simulate microphone input and capture speaker output to debug and test audio functionality.</p>
</section>
<section id="describe-how-your-proposal-will-work-with-code-pseudo-code-mock-ups-or-diagrams" class="level2">
<h2 class="anchored" data-anchor-id="describe-how-your-proposal-will-work-with-code-pseudo-code-mock-ups-or-diagrams">Describe how your proposal will work with code, pseudo-code, mock-ups, or diagrams</h2>
<p>The following script uses <code>ffmpeg</code> to either generate a test tone or play a provided WAV file as microphone input and record the speaker output. This setup is designed to work on macOS, Windows, and Linux.</p>
<section id="bash-script-macoslinux" class="level3">
<h3 class="anchored" data-anchor-id="bash-script-macoslinux">Bash Script (macOS/Linux)</h3>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb1-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#!/bin/bash</span></span>
<span id="cb1-2"></span>
<span id="cb1-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define file paths and device IDs</span></span>
<span id="cb1-4"><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">INPUT_WAV</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">""</span>  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Path to an optional input WAV file</span></span>
<span id="cb1-5"><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">OUTPUT_WAV</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"/path/to/output/speaker_output.wav"</span></span>
<span id="cb1-6"><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">MIC_DEVICE</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"plughw:0,0"</span>      <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Replace with your actual mic device ID</span></span>
<span id="cb1-7"><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">SPEAKER_DEVICE</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"plughw:0,0"</span>  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Replace with your actual speaker device ID</span></span>
<span id="cb1-8"><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">DURATION</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>10                   <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Duration in seconds</span></span>
<span id="cb1-9"></span>
<span id="cb1-10"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">[</span> <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">-z</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">$INPUT_WAV</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">]</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">;</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">then</span></span>
<span id="cb1-11">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Generate a test tone and play it as microphone input using ffmpeg</span></span>
<span id="cb1-12">    <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">ffmpeg</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-f</span> lavfi <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-i</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"sine=frequency=1000:duration=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">$DURATION</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-f</span> alsa <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-ac</span> 2 <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-ar</span> 44100 hw:<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">$MIC_DEVICE</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">&amp;</span></span>
<span id="cb1-13"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span></span>
<span id="cb1-14">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Play the provided WAV file as microphone input using ffmpeg</span></span>
<span id="cb1-15">    <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">ffmpeg</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-re</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-i</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">$INPUT_WAV</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-f</span> alsa <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-ac</span> 2 <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-ar</span> 44100 hw:<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">$MIC_DEVICE</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">&amp;</span></span>
<span id="cb1-16"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">fi</span></span>
<span id="cb1-17"></span>
<span id="cb1-18"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Record the speaker output to a WAV file</span></span>
<span id="cb1-19"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">ffmpeg</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-f</span> alsa <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-i</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">$SPEAKER_DEVICE</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-t</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">$DURATION</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-ac</span> 2 <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-ar</span> 44100 <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">$OUTPUT_WAV</span></span>
<span id="cb1-20"></span>
<span id="cb1-21"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Wait for background processes to finish</span></span>
<span id="cb1-22"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">wait</span></span></code></pre></div>
</section>
<section id="batch-script-windows" class="level3">
<h3 class="anchored" data-anchor-id="batch-script-windows">Batch Script (Windows)</h3>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode bat code-with-copy"><code class="sourceCode dosbat"><span id="cb2-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">@</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">echo off</span></span>
<span id="cb2-2"></span>
<span id="cb2-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:: Define file paths and device IDs</span></span>
<span id="cb2-4"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">set</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">INPUT_WAV</span>=  :: Path to an optional input WAV file</span>
<span id="cb2-5"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">set</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">OUTPUT_WAV</span>=C:\path\to\output\speaker_output.wav</span>
<span id="cb2-6"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">set</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">MIC_DEVICE</span>=audio=<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Microphone (Realtek High Definition Audio)"</span>  :: Replace with your actual mic device name</span>
<span id="cb2-7"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">set</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">SPEAKER_DEVICE</span>=audio=<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Speakers (Realtek High Definition Audio)"</span> :: Replace with your actual speaker device name</span>
<span id="cb2-8"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">set</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">DURATION</span>=10  :: Duration in seconds</span>
<span id="cb2-9"></span>
<span id="cb2-10"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span><span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">%</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">INPUT_WAV</span><span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">%</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">==</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">""</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">(</span></span>
<span id="cb2-11">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:: Generate a test tone and play it as microphone input using ffmpeg</span></span>
<span id="cb2-12">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">start</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">/B</span> ffmpeg <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-f</span> lavfi <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-i</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"sine=frequency=1000:duration=</span><span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">%</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">DURATION</span><span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">%</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-f</span> dshow <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-i</span> <span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">%</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">MIC_DEVICE</span><span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">%</span></span>
<span id="cb2-13"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">)</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">(</span></span>
<span id="cb2-14">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:: Play the provided WAV file as microphone input using ffmpeg</span></span>
<span id="cb2-15">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">start</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">/B</span> ffmpeg <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-re</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-i</span> <span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">%</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">INPUT_WAV</span><span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">%</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-f</span> dshow <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-i</span> <span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">%</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">MIC_DEVICE</span><span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">%</span></span>
<span id="cb2-16"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">)</span></span>
<span id="cb2-17"></span>
<span id="cb2-18"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:: Record the speaker output to a WAV file</span></span>
<span id="cb2-19">ffmpeg <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-f</span> dshow <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-i</span> <span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">%</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">SPEAKER_DEVICE</span><span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">%</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-t</span> <span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">%</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">DURATION</span><span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">%</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-ac</span> 2 <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-ar</span> 44100 <span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">%</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">OUTPUT_WAV</span><span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">%</span></span>
<span id="cb2-20"></span>
<span id="cb2-21"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:: Wait for background processes to finish</span></span>
<span id="cb2-22">wait</span></code></pre></div>
</section>
<section id="listing-devices-on-windows-macos-and-linux" class="level3">
<h3 class="anchored" data-anchor-id="listing-devices-on-windows-macos-and-linux">Listing Devices on Windows, macOS, and Linux</h3>
<section id="windows" class="level4">
<h4 class="anchored" data-anchor-id="windows"><strong>Windows</strong></h4>
<p>To list available audio devices on Windows, you can use the following command:</p>
<pre class="batch"><code>ffmpeg -list_devices true -f dshow -i dummy</code></pre>
<p>This will output a list of all available audio devices, which you can then use to replace the <code>MIC_DEVICE</code> and <code>SPEAKER_DEVICE</code> placeholders in the batch script.</p>
</section>
<section id="macos" class="level4">
<h4 class="anchored" data-anchor-id="macos"><strong>macOS</strong></h4>
<p>On macOS, you can list audio devices using the following command:</p>
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb4-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">ffmpeg</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-f</span> avfoundation <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-list_devices</span> true <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-i</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">""</span></span></code></pre></div>
<p>This command will display both video and audio devices. Look for the audio devices and use their indices or names as needed in your scripts.</p>
</section>
<section id="linux" class="level4">
<h4 class="anchored" data-anchor-id="linux"><strong>Linux</strong></h4>
<p>For Linux, to list audio devices using ffmpeg, you can execute the following command:</p>
<div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb5-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">ffmpeg</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-f</span> alsa <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-list_devices</span> true <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-i</span> dummy</span></code></pre></div>
<p>This command will help identify available ALSA audio devices, which can be used similarly to how devices are specified in scripts on other operating systems.</p>
</section>
</section>
<section id="steps" class="level3">
<h3 class="anchored" data-anchor-id="steps">Steps:</h3>
<ol type="1">
<li><p><strong>Define File Paths and Device IDs</strong>:</p>
<ul>
<li><code>INPUT_WAV</code>: Path to an optional input WAV file.</li>
<li><code>OUTPUT_WAV</code>: Path where the recorded speaker output will be saved.</li>
<li><code>MIC_DEVICE</code>: Microphone device ID (replace with actual device ID).</li>
<li><code>SPEAKER_DEVICE</code>: Speaker device ID (replace with actual device ID).</li>
<li><code>DURATION</code>: Duration of the recording in seconds.</li>
</ul></li>
<li><p><strong>Generate a Test Tone or Play Provided WAV File as Microphone Input</strong>:</p>
<ul>
<li>If <code>INPUT_WAV</code> is not provided, use <code>ffmpeg</code> to generate a 1000 Hz sine wave test tone and play it as if it were coming from the microphone.</li>
<li>If <code>INPUT_WAV</code> is provided, use <code>ffmpeg</code> to play the WAV file as if it were coming from the microphone.</li>
</ul></li>
<li><p><strong>Record the Speaker Output</strong>:</p>
<ul>
<li>Use <code>ffmpeg</code> to record the speaker output to a WAV file for the specified duration.</li>
</ul></li>
<li><p><strong>Wait for Background Processes</strong>:</p>
<ul>
<li>Ensure all background processes complete before the script exits.</li>
</ul></li>
</ol>
</section>
</section>
<section id="the-benefits" class="level2">
<h2 class="anchored" data-anchor-id="the-benefits">The Benefits</h2>
<ul>
<li><strong>Automated Testing</strong>: Enables automated testing of VOIP clients.</li>
<li><strong>Versatility</strong>: Can be used to test various VOIP applications like Discord and VRChat.</li>
<li><strong>Prototyping</strong>: Useful for prototyping WebRTC later.</li>
</ul>
</section>
<section id="the-downsides" class="level2">
<h2 class="anchored" data-anchor-id="the-downsides">The Downsides</h2>
<ul>
<li><strong>Complex Setup</strong>: Requires knowledge of audio systems and command-line tools.</li>
<li><strong>Potential Compatibility Issues</strong>: May not work seamlessly across all hardware configurations.</li>
</ul>
</section>
<section id="the-road-not-taken" class="level2">
<h2 class="anchored" data-anchor-id="the-road-not-taken">The Road Not Taken</h2>
<p>Using Godot-specific audio stream players and effects was considered but found to be too closely tied to Godot, limiting broader application testing.</p>
</section>
<section id="the-infrequent-use-case" class="level2">
<h2 class="anchored" data-anchor-id="the-infrequent-use-case">The Infrequent Use Case</h2>
<p>In cases where precise audio sample rate configuration is critical, additional adjustments may be needed to avoid issues.</p>
</section>
<section id="in-core-and-done-by-us" class="level2">
<h2 class="anchored" data-anchor-id="in-core-and-done-by-us">In Core and Done by Us</h2>
<p>This approach aligns with our goal of robust and versatile testing methodologies and will be implemented by our team.</p>
</section>
<section id="status" class="level2">
<h2 class="anchored" data-anchor-id="status">Status</h2>
<p>Status: Draft <!-- Draft | Proposed | Rejected | Accepted | Deprecated | Superseded by --></p>
</section>
<section id="decision-makers" class="level2">
<h2 class="anchored" data-anchor-id="decision-makers">Decision Makers</h2>
<ul>
<li>V-Sekai development team</li>
</ul>
</section>
<section id="tags" class="level2">
<h2 class="anchored" data-anchor-id="tags">Tags</h2>
<ul>
<li>V-Sekai</li>
</ul>
</section>
<section id="further-reading" class="level2">
<h2 class="anchored" data-anchor-id="further-reading">Further Reading</h2>
<ol type="1">
<li><a href="https://github.com/v-sekai">V-Sekai · GitHub</a> - Official GitHub account for the V-Sekai development community focusing on social VR functionality for the Godot Engine.</li>
<li><a href="https://github.com/v-sekai/v-sekai-game">V-Sekai/v-sekai-game</a> - GitHub page for the V-Sekai open-source project, which brings social VR/VRSNS/metaverse components to the Godot Engine.</li>
</ol>
<p>AI assistant Aria assisted with this article.</p>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20240824-ffmpeg-wav-mic-speaker-play.html</guid>
  <pubDate>Wed, 11 Dec 2024 15:00:09 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20240810-steamvr-dongles-separate.html</link>
  <description><![CDATA[ 




<section id="draft-improving-connectivity-for-valve-streamvr-light-house-dongles" class="level1">
<h1>Draft: Improving Connectivity for Valve StreamVR Light House Dongles</h1>
<section id="the-context" class="level2">
<h2 class="anchored" data-anchor-id="the-context">The Context</h2>
<p>Valve StreamVR Light House Dongles are unable to connect.</p>
</section>
<section id="the-problem-statement" class="level2">
<h2 class="anchored" data-anchor-id="the-problem-statement">The Problem Statement</h2>
<p>Valve StreamVR Light House Dongles are unable to connect because of wireless interference if plugged into hubs upright and side by side.</p>
</section>
<section id="describe-how-your-proposal-will-work-with-code-pseudo-code-mock-ups-or-diagrams" class="level2">
<h2 class="anchored" data-anchor-id="describe-how-your-proposal-will-work-with-code-pseudo-code-mock-ups-or-diagrams">Describe how your proposal will work with code, pseudo-code, mock-ups, or diagrams</h2>
<p>Use the supplied HTCVive cradles for the dongles. Keep the dongles upright.</p>
</section>
<section id="the-benefits" class="level2">
<h2 class="anchored" data-anchor-id="the-benefits">The Benefits</h2>
<ul>
<li><strong>Reduced Interference:</strong> By using the supplied cradles and keeping the dongles upright, wireless interference is minimized.</li>
<li><strong>Improved Connectivity:</strong> Ensures stable and reliable connections for the Valve StreamVR Light House Dongles.</li>
<li><strong>User-Friendly:</strong> Simple implementation that leverages existing hardware (HTCVive cradles).</li>
</ul>
</section>
<section id="the-downsides" class="level2">
<h2 class="anchored" data-anchor-id="the-downsides">The Downsides</h2>
<ul>
<li><strong>Additional Space Required:</strong> Using cradles may require more physical space compared to plugging dongles directly into a hub.</li>
<li><strong>Potential Cost:</strong> If users do not already have the HTCVive cradles, they may need to purchase them separately.</li>
</ul>
</section>
<section id="the-road-not-taken" class="level2">
<h2 class="anchored" data-anchor-id="the-road-not-taken">The Road Not Taken</h2>
<ul>
<li><strong>Alternative Positioning:</strong> Exploring other physical arrangements for the dongles without using cradles.</li>
<li><strong>Software Solutions:</strong> Investigating software-based solutions to mitigate wireless interference.</li>
</ul>
</section>
<section id="the-infrequent-use-case" class="level2">
<h2 class="anchored" data-anchor-id="the-infrequent-use-case">The Infrequent Use Case</h2>
<ul>
<li><strong>Limited Setup Scenarios:</strong> Users with unique setups where space constraints make it difficult to use the cradles effectively.</li>
</ul>
</section>
<section id="in-core-and-done-by-us" class="level2">
<h2 class="anchored" data-anchor-id="in-core-and-done-by-us">In Core and Done by Us</h2>
<ul>
<li><strong>Implementation:</strong> The V-Sekai development team will handle the implementation and testing of this proposal.</li>
<li><strong>Documentation:</strong> Detailed instructions and guidelines will be provided to users for setting up their dongles using the cradles.</li>
</ul>
</section>
<section id="status" class="level2">
<h2 class="anchored" data-anchor-id="status">Status</h2>
<p>Status: Draft <!-- Draft | Proposed | Rejected | Accepted | Deprecated | Superseded by --></p>
</section>
<section id="decision-makers" class="level2">
<h2 class="anchored" data-anchor-id="decision-makers">Decision Makers</h2>
<ul>
<li>V-Sekai development team</li>
</ul>
</section>
<section id="tags" class="level2">
<h2 class="anchored" data-anchor-id="tags">Tags</h2>
<ul>
<li>V-Sekai</li>
</ul>
</section>
<section id="further-reading" class="level2">
<h2 class="anchored" data-anchor-id="further-reading">Further Reading</h2>
<ol type="1">
<li><a href="https://github.com/v-sekai">V-Sekai · GitHub</a> - Official GitHub account for the V-Sekai development community focusing on social VR functionality for the Godot Engine.</li>
<li><a href="https://github.com/v-sekai/v-sekai-game">V-Sekai/v-sekai-game</a> is the GitHub page for the V-Sekai open-source project, which brings social VR/VRSNS/metaverse components to the Godot Engine.</li>
</ol>
<p>AI assistant Aria assisted with this article.</p>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20240810-steamvr-dongles-separate.html</guid>
  <pubDate>Wed, 11 Dec 2024 15:00:09 GMT</pubDate>
</item>
</channel>
</rss>
