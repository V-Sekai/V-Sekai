<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>V-Sekai - Manuals</title>
<link>https://v-sekai.github.io/manuals/decisions.html</link>
<atom:link href="https://v-sekai.github.io/manuals/decisions.xml" rel="self" type="application/rss+xml"/>
<description></description>
<generator>quarto-1.3.433</generator>
<lastBuildDate>Wed, 19 Jul 2023 23:08:35 GMT</lastBuildDate>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/present-proposal-template.html</link>
  <description><![CDATA[ 



<section id="this-enhancement-solves-a-v-sekai-limitation" class="level1">
<h1>This enhancement solves a V-Sekai limitation</h1>
<section id="metadata" class="level2">
<h2 class="anchored" data-anchor-id="metadata">Metadata</h2>
<ul>
<li>Status: proposed <!-- draft | proposed | rejected | accepted | deprecated | superseded by --></li>
<li>Deciders: V-Sekai</li>
<li>Tags: V-Sekai</li>
</ul>
</section>
<section id="context-and-problem-statement" class="level2">
<h2 class="anchored" data-anchor-id="context-and-problem-statement">Context and Problem Statement</h2>
</section>
<section id="proposed-solution" class="level2">
<h2 class="anchored" data-anchor-id="proposed-solution">Proposed Solution</h2>
</section>
<section id="implementation" class="level2">
<h2 class="anchored" data-anchor-id="implementation">Implementation</h2>
</section>
<section id="positive-consequences" class="level2">
<h2 class="anchored" data-anchor-id="positive-consequences">Positive Consequences</h2>
</section>
<section id="negative-consequences" class="level2">
<h2 class="anchored" data-anchor-id="negative-consequences">Negative Consequences</h2>
</section>
<section id="option-graveyard" class="level2">
<h2 class="anchored" data-anchor-id="option-graveyard">Option graveyard</h2>
</section>
<section id="if-this-enhancement-will-be-used-infrequently-can-it-be-worked-around-with-a-few-lines-of-script" class="level2">
<h2 class="anchored" data-anchor-id="if-this-enhancement-will-be-used-infrequently-can-it-be-worked-around-with-a-few-lines-of-script">If this enhancement will be used infrequently, can it be worked around with a few lines of script?</h2>
</section>
<section id="is-there-a-reason-why-this-should-be-core-and-done-by-us" class="level2">
<h2 class="anchored" data-anchor-id="is-there-a-reason-why-this-should-be-core-and-done-by-us">Is there a reason why this should be core and done by us?</h2>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<ul>
<li><a href="https://v-sekai.org/">V-Sekai</a> <!-- - This article [is / or is not] assisted by AI. --></li>
</ul>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/present-proposal-template.html</guid>
  <pubDate>Wed, 19 Jul 2023 23:08:35 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20230719-pose-kusudama-constraints-in-vr.html</link>
  <description><![CDATA[ 



<section id="enhancing-the-many-bone-ik-configuration" class="level1">
<h1>Enhancing the Many Bone IK Configuration</h1>
<section id="metadata" class="level2">
<h2 class="anchored" data-anchor-id="metadata">Metadata</h2>
<ul>
<li>Status: proposed</li>
<li>Deciders: V-Sekai</li>
<li>Tags: V-Sekai, VR, Game Development</li>
</ul>
</section>
<section id="context-and-problem-statement" class="level2">
<h2 class="anchored" data-anchor-id="context-and-problem-statement">Context and Problem Statement</h2>
<p>We have identified a limitation in the V-Sekai platform where there are too many variables to pose the kusudama constraints on the desktop. We propose to overcome this limitation by introducing a VR mode.</p>
</section>
<section id="proposed-solution" class="level2">
<h2 class="anchored" data-anchor-id="proposed-solution">Proposed Solution</h2>
<p>Our solution involves creating a VR mode specifically for posing Many Bone IK kusudama constraints. The steps for implementation are as follows:</p>
<ol type="1">
<li>Develop a VR controller.</li>
<li>Implement multiplayer functionality.</li>
<li>Adjust the kusudama constraint attributes to match posing.</li>
</ol>
</section>
<section id="implementation" class="level2">
<h2 class="anchored" data-anchor-id="implementation">Implementation</h2>
<ol type="1">
<li>Investigate Saracen’s VR networking prototype.</li>
<li>Rebuild character posing without tracking the physical sensors</li>
<li>Apply Many Bone IK</li>
<li>Adjust for quality</li>
<li>Complete configuration</li>
</ol>
<p>Assigning physical sensors to IK trackers is not in this milestone.</p>
</section>
<section id="option-graveyard" class="level2">
<h2 class="anchored" data-anchor-id="option-graveyard">Option Graveyard</h2>
<ol type="1">
<li><p><strong>Desktop Mode Enhancement:</strong> Initially, we considered enhancing the desktop mode to handle the kusudama constraints better. However, this option was discarded due to the inherent limitations of the desktop interface for such complex interactions.</p></li>
<li><p><strong>Use of External Tools:</strong> Another option was to use external tools or plugins specifically designed for handling Many Bone IK kusudama constraints. This option was rejected because it would require users to learn and manage additional software, which could lead to a fragmented user experience.</p></li>
<li><p><strong>Simplified Kusudama Constraints:</strong> We also thought about simplifying the kusudama constraints to make them more manageable on the desktop. But this option was discarded as it would limit the capabilities and flexibility that our platform currently offers.</p></li>
<li><p><strong>Automated Posing:</strong> An automated system for posing the kusudama constraints was also considered. However, this option was rejected because it would take away control from the users, potentially leading to less satisfactory results.</p></li>
<li><p><strong>Tutorials and Guides:</strong> Providing extensive tutorials and guides to help users navigate the complexity of posing kusudama constraints on the desktop was another option. This was discarded because it doesn’t address the core issue - the difficulty of managing these constraints on a desktop interface.</p></li>
</ol>
</section>
<section id="negative-consequences" class="level2">
<h2 class="anchored" data-anchor-id="negative-consequences">Negative Consequences</h2>
<ul>
<li>Increased complexity in game development.</li>
<li>Potential need for more resources (time, manpower, etc.) for implementation and testing.</li>
</ul>
</section>
<section id="option-graveyard-1" class="level2">
<h2 class="anchored" data-anchor-id="option-graveyard-1">Option graveyard</h2>
<p>This section is reserved for options considered but rejected.</p>
</section>
<section id="if-this-enhancement-will-be-used-infrequently-can-it-be-worked-around-with-a-few-lines-of-script" class="level2">
<h2 class="anchored" data-anchor-id="if-this-enhancement-will-be-used-infrequently-can-it-be-worked-around-with-a-few-lines-of-script">If this enhancement will be used infrequently, can it be worked around with a few lines of script?</h2>
<p>Posing the avatar is the first interaction a user has when entering our virtual world, V-Sekai. This underlines the necessity of investing in this enhancement to ensure a seamless and engaging user experience right from their first interaction with our platform.</p>
</section>
<section id="is-there-a-reason-why-this-should-be-core-and-done-by-us" class="level2">
<h2 class="anchored" data-anchor-id="is-there-a-reason-why-this-should-be-core-and-done-by-us">Is there a reason why this should be core and done by us?</h2>
<p>Pose quality is crucial to us. As the creators of V-Sekai, we have an unparalleled understanding of our platform’s limitations and potential improvements. This insight puts us in a unique position to enhance the pose quality in a way that aligns with our users’ needs and expectations. Therefore, it is essential that we undertake this enhancement.</p>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<ul>
<li><a href="https://v-sekai.org/">V-Sekai</a></li>
</ul>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20230719-pose-kusudama-constraints-in-vr.html</guid>
  <pubDate>Wed, 19 Jul 2023 23:08:35 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20230719-dual-databases-cockroachdb-khepri.html</link>
  <description><![CDATA[ 



<section id="game-simulation-server-sidekick-process" class="level1">
<h1>Game simulation server sidekick process</h1>
<section id="metadata" class="level2">
<h2 class="anchored" data-anchor-id="metadata">Metadata</h2>
<ul>
<li>Status: proposed</li>
<li>Deciders: V-Sekai</li>
<li>Tags: V-Sekai, Godot Engine, khepri, elixir</li>
</ul>
</section>
<section id="context-and-problem-statement" class="level2">
<h2 class="anchored" data-anchor-id="context-and-problem-statement">Context and Problem Statement</h2>
<p>We want to provide each game server a sidekick process that restarts Godot Engine on crash and acts as a local processor before upload to the source of truth backend database. This will ensure continuous gameplay and data integrity.</p>
</section>
<section id="proposed-solution" class="level2">
<h2 class="anchored" data-anchor-id="proposed-solution">Proposed Solution</h2>
<p>We propose to use khepri for sidekick server data with an elixir frontend.</p>
<p>Khepri provides robustness and reliability while Elixir offers scalability and fault-tolerance.</p>
</section>
<section id="implementation" class="level2">
<h2 class="anchored" data-anchor-id="implementation">Implementation</h2>
<ol type="1">
<li>Develop a sidekick process using khepri that monitors the Godot Engine.</li>
<li>In case of a crash, the sidekick process should be able to restart the Godot Engine.</li>
<li>The sidekick process should also act as a local processor for game data before it’s uploaded to the backend database.</li>
<li>Implement an Elixir frontend to interact with the sidekick process.</li>
</ol>
</section>
<section id="positive-consequences" class="level2">
<h2 class="anchored" data-anchor-id="positive-consequences">Positive Consequences</h2>
<ul>
<li>Improved game server stability.</li>
<li>Continuous gameplay even in the event of a crash.</li>
<li>Ensured data integrity before upload to the backend database.</li>
</ul>
</section>
<section id="negative-consequences" class="level2">
<h2 class="anchored" data-anchor-id="negative-consequences">Negative Consequences</h2>
<ul>
<li>Additional development time and resources required.</li>
<li>Potential complexity in managing the sidekick process.</li>
</ul>
</section>
<section id="option-graveyard" class="level2">
<h2 class="anchored" data-anchor-id="option-graveyard">Option graveyard</h2>
<ol type="1">
<li><p><strong>Using a simple watchdog script:</strong> A simple script that monitors the Godot Engine and restarts it in case of a crash. This was rejected due to its inability to act as a local processor for game data before upload.</p></li>
<li><p><strong>Relying on third-party services:</strong> There are several third-party services that offer process monitoring and automatic restarts. However, these were rejected due to potential issues with customization, cost, and data privacy.</p></li>
<li><p><strong>Building a custom solution from scratch:</strong> While this would give us the most control, it was deemed too resource-intensive and unnecessary given the existence of suitable tools like khepri and Elixir.</p></li>
<li><p><strong>Do nothing:</strong> The option to maintain the status quo was considered but ultimately rejected due to the negative impact on user experience and data integrity.</p></li>
</ol>
</section>
<section id="if-this-enhancement-will-be-used-infrequently-can-it-be-worked-around-with-a-few-lines-of-script" class="level2">
<h2 class="anchored" data-anchor-id="if-this-enhancement-will-be-used-infrequently-can-it-be-worked-around-with-a-few-lines-of-script">If this enhancement will be used infrequently, can it be worked around with a few lines of script?</h2>
<p>No, this enhancement is fundamental to the stability of the game servers and cannot be achieved with a simple script workaround.</p>
</section>
<section id="is-there-a-reason-why-this-should-be-core-and-done-by-us" class="level2">
<h2 class="anchored" data-anchor-id="is-there-a-reason-why-this-should-be-core-and-done-by-us">Is there a reason why this should be core and done by us?</h2>
<p>Yes, as this directly impacts the user experience and the integrity of our game data, it is crucial that we have full control over its implementation and maintenance.</p>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<ul>
<li><a href="https://v-sekai.org/">V-Sekai</a> <!-- - This article [is / or is not] assisted by AI. --></li>
</ul>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20230719-dual-databases-cockroachdb-khepri.html</guid>
  <pubDate>Wed, 19 Jul 2023 23:08:35 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20230716-enhancing-avatar-creation-process-02-advanced.html</link>
  <description><![CDATA[ 



<section id="enhancing-avatar-creation-process-in-v-sekai-advanced" class="level1">
<h1>Enhancing Avatar Creation Process in V-Sekai Advanced</h1>
<section id="metadata" class="level2">
<h2 class="anchored" data-anchor-id="metadata">Metadata</h2>
<ul>
<li>Status: proposed</li>
<li>Deciders: V-Sekai</li>
<li>Tags: V-Sekai</li>
</ul>
</section>
<section id="context-and-problem-statement" class="level2">
<h2 class="anchored" data-anchor-id="context-and-problem-statement">Context and Problem Statement</h2>
<p>V-Sekai currently has limitations when it comes to creating avatars with specific features and customizations. This can be a hindrance for users who want to have more control over the appearance of their avatars. To address this, we propose an enhancement that introduces various tools and techniques to overcome these limitations and provide a more comprehensive avatar creation process.</p>
</section>
<section id="proposed-solution" class="level2">
<h2 class="anchored" data-anchor-id="proposed-solution">Proposed Solution</h2>
<p>Here is a list of raw processes to be broken down.</p>
<section id="to-create-a-source-filter-sink-pipeline-system-for-this-project-we-can-use-the-following-mime-labels" class="level3">
<h3 class="anchored" data-anchor-id="to-create-a-source-filter-sink-pipeline-system-for-this-project-we-can-use-the-following-mime-labels">To create a source, filter, sink pipeline system for this project, we can use the following mime labels:</h3>
<ol type="1">
<li><p>Source: The source will provide the initial avatar model and any additional assets required. The input mime type for the source could be <code>application/gltf+json</code> or <code>model/gltf+json</code> if the avatar is in GLTF format, or <code>image/png</code> or <code>image/svg+xml</code> if the avatar is provided as a 2D image.</p></li>
<li><p>Filter: The filter will handle all the customization steps mentioned above. It will take the input from the source and apply the necessary modifications to create the desired avatar. The input mime type for the filter would be the same as the output mime type of the source, depending on whether the avatar is in GLTF format or represented as an image.</p></li>
<li><p>Sink: The sink will receive the customized avatar from the filter and store it as the final output. For this project, the sink should support both PNG and SVG images for 2D avatars, and GLTF for 3D avatars. Therefore, the output mime types for the sink would be <code>image/png</code> or <code>image/svg+xml</code> for 2D avatars, and <code>application/gltf+json</code> or <code>model/gltf+json</code> for 3D avatars.</p></li>
</ol>
<p>Note: To avoid lossy formats, we are using PNG or SVG for 2D images and GLTF for 3D formats. PNG and SVG are lossless image formats, while GLTF is a lossless 3D format that preserves the fidelity of the avatar model.</p>
</section>
<section id="advanced-customization-steps" class="level3">
<h3 class="anchored" data-anchor-id="advanced-customization-steps">Advanced Customization Steps:</h3>
<p>Here are the converted inputs and outputs in the xstate format for each step:</p>
<ol type="1">
<li><strong>Importing the avatar into Godot Engine and “Project Mirage”:</strong>
<ul>
<li>Input: <code>.vrm</code> file</li>
<li>Output: <code>.vrm</code> file</li>
</ul></li>
<li><strong>Refining the imported avatar:</strong>
<ul>
<li>Input: <code>.vrm</code> file</li>
<li>Output: <code>.vrm</code> file</li>
</ul></li>
<li><strong>Converting spring bone to physical simulation bones and colliders:</strong>
<ul>
<li>Input: <code>.vrm</code> file</li>
<li>Output: assetpackage file</li>
</ul></li>
<li><strong>Addressing painting errors:</strong>
<ul>
<li>Input: <code>.vrm</code> file</li>
<li>Output: <code>.vrm</code> file</li>
</ul></li>
<li><strong>Choosing a material:</strong>
<ul>
<li>Input: <code>.vrm</code> file</li>
<li>Output: <code>.vrm</code> file</li>
</ul></li>
<li><strong>Resolving issues with materials and bones:</strong>
<ul>
<li>Input: <code>.vrm</code> file</li>
<li>Output: <code>.vrm</code> file</li>
</ul></li>
<li><strong>Correcting colors and addressing pleated folds:</strong>
<ul>
<li>Input: <code>.vrm</code> file</li>
<li>Output: <code>.vrm</code> file</li>
</ul></li>
<li><strong>Creating complex geometric structures:</strong>
<ul>
<li>Input: <code>.vrm</code> file</li>
<li>Output: <code>.vrm</code> file</li>
</ul></li>
<li><strong>Utilizing Vroid Hub’s hair painter and mesh generator:</strong></li>
</ol>
<ul>
<li>Input: <code>.vrm</code> file</li>
<li>Output: <code>.vrm</code> enhanced data</li>
</ul>
<ol start="11" type="1">
<li><strong>Adding facial expressions for motion capture:</strong></li>
</ol>
<ul>
<li>Input: <code>.vrm</code> file</li>
<li>Output: <code>.gltf</code> motion capture data</li>
</ul>
<ol start="12" type="1">
<li><strong>Setting up motion capture:</strong></li>
</ol>
<ul>
<li>Input: <code>.vrm</code> file</li>
<li>Output: vrm animations data stored as <code>.gltf</code>.</li>
</ul>
</section>
</section>
<section id="positive-consequences" class="level2">
<h2 class="anchored" data-anchor-id="positive-consequences">Positive Consequences</h2>
<ul>
<li>Users will be able to create highly customizable avatars with specific features.</li>
<li>The avatar creation process will be enhanced with a variety of tools and techniques.</li>
<li>Detailed customization of colors, clothing, accessories, and facial expressions will be possible.</li>
<li>Motion capture capabilities can be integrated for more realistic animations.</li>
</ul>
</section>
<section id="negative-consequences" class="level2">
<h2 class="anchored" data-anchor-id="negative-consequences">Negative Consequences</h2>
<ul>
<li>The implementation process is complex and may require advanced technical skills from users.</li>
<li>Some steps, like creating a 3D model of the back of the avatar, may not always be successful.</li>
<li>Painting errors and other imperfections may remain in the final avatar.</li>
</ul>
</section>
<section id="option-graveyard" class="level2">
<h2 class="anchored" data-anchor-id="option-graveyard">Option graveyard</h2>
<ul>
<li>Excessive complexity or technical requirements: We want the avatar creation process to be user-friendly and accessible to a wide range of users, so any options that require advanced technical skills or have excessively complex customization controls will not be included.</li>
</ul>
</section>
<section id="if-this-enhancement-will-be-used-infrequently-can-it-be-worked-around-with-a-few-lines-of-script" class="level2">
<h2 class="anchored" data-anchor-id="if-this-enhancement-will-be-used-infrequently-can-it-be-worked-around-with-a-few-lines-of-script">If this enhancement will be used infrequently, can it be worked around with a few lines of script?</h2>
<p>No, the proposed enhancement involves a multi-step process that cannot be easily replicated with just a few lines of script.</p>
</section>
<section id="is-there-a-reason-why-this-should-be-core-and-done-by-us" class="level2">
<h2 class="anchored" data-anchor-id="is-there-a-reason-why-this-should-be-core-and-done-by-us">Is there a reason why this should be core and done by us?</h2>
<p>The proposed enhancement addresses the limitations in V-Sekai’s avatar creation process, providing users with a comprehensive solution for creating highly customizable avatars. By implementing these tools and techniques within the platform, V-Sekai can offer a more robust and user-friendly experience for its community.</p>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<ul>
<li><a href="https://v-sekai.org/">V-Sekai</a></li>
</ul>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20230716-enhancing-avatar-creation-process-02-advanced.html</guid>
  <pubDate>Wed, 19 Jul 2023 23:08:35 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20230716-enhancing-avatar-creation-process-01-regular.html</link>
  <description><![CDATA[ 



<section id="enhancing-avatar-creation-process-in-v-sekai-regular" class="level1">
<h1>Enhancing Avatar Creation Process in V-Sekai Regular</h1>
<section id="metadata" class="level2">
<h2 class="anchored" data-anchor-id="metadata">Metadata</h2>
<ul>
<li>Status: proposed</li>
<li>Deciders: V-Sekai</li>
<li>Tags: V-Sekai</li>
</ul>
</section>
<section id="context-and-problem-statement" class="level2">
<h2 class="anchored" data-anchor-id="context-and-problem-statement">Context and Problem Statement</h2>
<p>V-Sekai currently has limitations when it comes to creating avatars with specific features and customizations. This can be a hindrance for users who want to have more control over the appearance of their avatars. To address this, we propose an enhancement that introduces various tools and techniques to overcome these limitations and provide a more comprehensive avatar creation process.</p>
</section>
<section id="proposed-solution" class="level2">
<h2 class="anchored" data-anchor-id="proposed-solution">Proposed Solution</h2>
<p>Here is a list of raw processes to be broken down.</p>
<section id="avatar-creation-steps" class="level3">
<h3 class="anchored" data-anchor-id="avatar-creation-steps">Avatar Creation Steps:</h3>
<p>To implement the requested changes, here are the modified instructions:</p>
<ol type="1">
<li><strong>Creating the avatar face:</strong> Utilizes digital drawing techniques to design and create the facial features of the avatar.
<ul>
<li>Input mime type: None</li>
<li>Output mime type: Digital drawing/image file (e.g., PNG, SVG)</li>
</ul></li>
<li><strong>Changing colors:</strong> Utilizes a digital paintbrush tool like Penpot to modify and customize the colors of the avatar.
<ul>
<li>Input mime type: Digital drawing/image file (e.g., PNG, SVG)</li>
<li>Output mime type: Digital drawing/image file (e.g., PNG, SVG)</li>
</ul></li>
<li><strong>Selecting the best-looking avatars:</strong> Evaluates and chooses the most visually appealing avatars from a pool of options.
<ul>
<li>Input mime type: Digital drawing/image file (e.g., PNG, SVG)</li>
<li>Output mime type: Digital drawing/image file (e.g., PNG, SVG)</li>
</ul></li>
<li><strong>Removing the background image:</strong> Removes the background image to make rework easier. May provide worse results with edge details.
<ul>
<li>Input mime type: Digital drawing/image file (e.g., PNG, SVG)</li>
<li>Output mime type: Digital drawing/image file (e.g., PNG, SVG)</li>
</ul></li>
<li><strong>Adding a body:</strong> Incorporates a body to the avatar using Blender’s CC0 base mesh or a similar tool.
<ul>
<li>Input mime type: Digital drawing/image file (e.g., PNG, SVG)</li>
<li>Output mime type: Digital drawing/image file (e.g., PNG, SVG)</li>
</ul></li>
<li><strong>Creating a 3D model of the back of the avatar:</strong> If feasible, attempts to create a 3D model of the back of the avatar for a more comprehensive representation.
<ul>
<li>Input mime type: Digital drawing/image file (e.g., PNG, SVG)</li>
<li>Output mime type: Digital drawing/image file (e.g., PNG, SVG)</li>
</ul></li>
<li><strong>Simplifying images:</strong> Uses a tool to simplify and refine the entire avatar image as a whole, removing any unnecessary image details or complexities.
<ul>
<li>Input mime type: Digital drawing/image file (e.g., PNG, SVG)</li>
<li>Output mime type: Digital drawing/image file (e.g., PNG, SVG)</li>
</ul></li>
<li><strong>Adding clothing and accessories:</strong> Enhances the avatar by adding clothing and accessories using tools like Vroid Hub.
<ul>
<li>Input mime type: Digital drawing/image file (e.g., PNG, SVG)</li>
<li>Output mime type: Digital drawing/image file (e.g., PNG, SVG)</li>
</ul></li>
<li><strong>Placing the 2D image as a reference:</strong> Positions the 2D reference image in front of the 3D model to serve as a visual guide during customization.
<ul>
<li>Input mime type: Digital drawing/image file (e.g., PNG, SVG), 3D model file (e.g., GLTF)</li>
<li>Output mime type: 3D model file (e.g., GLTF), Digital image file (e.g., PNG, SVG)</li>
</ul></li>
<li><strong>Capturing and enhancing images:</strong> Captures images from various angles using a camera and enhances them to improve the overall quality.</li>
</ol>
<ul>
<li>Input mime type: Digital drawing/image file (e.g., PNG, SVG)</li>
<li>Output mime type: Digital image file (e.g., PNG, SVG)</li>
</ul>
<ol start="11" type="1">
<li><strong>Generating text captions:</strong> Creates descriptive text captions for the captured images to provide additional context or information.</li>
</ol>
<ul>
<li>Input mime type: Digital image file (e.g., PNG, SVG)</li>
<li>Output mime type: Text file (e.g., TXT)</li>
</ul>
<ol start="12" type="1">
<li><strong>Using a 2D reference image in Blender:</strong> Uses a 2D reference image within Blender to guide the customization process.</li>
</ol>
<ul>
<li>Input mime type: Digital drawing/image file (e.g., PNG, SVG)</li>
<li>Output mime type: 3D model file (e.g., GLTF), Digital image file (e.g., PNG, SVG)</li>
</ul>
</section>
</section>
<section id="positive-consequences" class="level2">
<h2 class="anchored" data-anchor-id="positive-consequences">Positive Consequences</h2>
<ul>
<li>Users will be able to create highly customizable avatars with specific features.</li>
<li>The avatar creation process will be enhanced with a variety of tools and techniques.</li>
<li>Detailed customization of colors, clothing, accessories, and facial expressions will be possible.</li>
<li>Motion capture capabilities can be integrated for more realistic animations.</li>
</ul>
</section>
<section id="negative-consequences" class="level2">
<h2 class="anchored" data-anchor-id="negative-consequences">Negative Consequences</h2>
<ul>
<li>The implementation process is complex and may require advanced technical skills from users.</li>
<li>Some steps, like creating a 3D model of the back of the avatar, may not always be successful.</li>
<li>Painting errors and other imperfections may remain in the final avatar.</li>
</ul>
</section>
<section id="option-graveyard" class="level2">
<h2 class="anchored" data-anchor-id="option-graveyard">Option graveyard</h2>
<ul>
<li>Excessive complexity or technical requirements: We want the avatar creation process to be user-friendly and accessible to a wide range of users, so any options that require advanced technical skills or have excessively complex customization controls will not be included.</li>
</ul>
</section>
<section id="if-this-enhancement-will-be-used-infrequently-can-it-be-worked-around-with-a-few-lines-of-script" class="level2">
<h2 class="anchored" data-anchor-id="if-this-enhancement-will-be-used-infrequently-can-it-be-worked-around-with-a-few-lines-of-script">If this enhancement will be used infrequently, can it be worked around with a few lines of script?</h2>
<p>No, the proposed enhancement involves a multi-step process that cannot be easily replicated with just a few lines of script.</p>
</section>
<section id="is-there-a-reason-why-this-should-be-core-and-done-by-us" class="level2">
<h2 class="anchored" data-anchor-id="is-there-a-reason-why-this-should-be-core-and-done-by-us">Is there a reason why this should be core and done by us?</h2>
<p>The proposed enhancement addresses the limitations in V-Sekai’s avatar creation process, providing users with a comprehensive solution for creating highly customizable avatars. By implementing these tools and techniques within the platform, V-Sekai can offer a more robust and user-friendly experience for its community.</p>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<ul>
<li><a href="https://v-sekai.org/">V-Sekai</a></li>
<li><a href="https://civitai.com/models/58390/detail-tweaker-lora-lora">Detail Tweaker</a></li>
<li><a href="https://github.com/gfodor/instructblip-replicate">InstructBLIP: Towards General-purpose Vision-Language Models with Instruction Tuning</a></li>
<li><a href="https://github.com/bigscience-workshop/petals">Petals</a></li>
</ul>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20230716-enhancing-avatar-creation-process-01-regular.html</guid>
  <pubDate>Wed, 19 Jul 2023 23:08:35 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20230701-vsekai-broken-down-goals.html</link>
  <description><![CDATA[ 



<section id="v-sekai-feature-enhancement-proposal" class="level1">
<h1>V-Sekai Feature Enhancement Proposal</h1>
<section id="metadata" class="level2">
<h2 class="anchored" data-anchor-id="metadata">Metadata</h2>
<ul>
<li><strong>Status</strong>: Proposed</li>
<li><strong>Deciders</strong>: V-Sekai</li>
<li><strong>Tags</strong>: V-Sekai, ai summarized</li>
</ul>
</section>
<section id="context-and-problem-statement" class="level2">
<h2 class="anchored" data-anchor-id="context-and-problem-statement">Context and Problem Statement</h2>
<p>We are developing a virtual reality platform, V-Sekai. To ensure the platform meets user needs and expectations, we have identified several features that need to be implemented. These features have been categorized based on their priority and necessity for the initial release.</p>
</section>
<section id="proposed-solution" class="level2">
<h2 class="anchored" data-anchor-id="proposed-solution">Proposed Solution</h2>
<p>The features have been organized into three categories: Must-Have, Nice-to-Have, and Out of Scope Initially. The priority within each category reflects the relative importance of the features for an initial release.</p>
<section id="must-have-features" class="level3">
<h3 class="anchored" data-anchor-id="must-have-features">Must-Have Features</h3>
<table class="table">
<colgroup>
<col style="width: 32%">
<col style="width: 25%">
<col style="width: 41%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">Priority</th>
<th style="text-align: left;">Feature</th>
<th style="text-align: left;">Dependencies</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">1</td>
<td style="text-align: left;">Environment (scene loading, world hosting, instancing)</td>
<td style="text-align: left;">None</td>
</tr>
<tr class="even">
<td style="text-align: center;">2</td>
<td style="text-align: left;">Web requests to servers (HTTP/WebSocket API)</td>
<td style="text-align: left;">Environment</td>
</tr>
<tr class="odd">
<td style="text-align: center;">3</td>
<td style="text-align: left;">Person to person interaction (avatars, animation, synchronization)</td>
<td style="text-align: left;">Environment</td>
</tr>
<tr class="even">
<td style="text-align: center;">4</td>
<td style="text-align: left;">Interaction with the world (interactive elements, physics)</td>
<td style="text-align: left;">Environment</td>
</tr>
</tbody>
</table>
</section>
<section id="nice-to-have-features" class="level3">
<h3 class="anchored" data-anchor-id="nice-to-have-features">Nice-to-Have Features</h3>
<table class="table">
<colgroup>
<col style="width: 32%">
<col style="width: 25%">
<col style="width: 41%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">Priority</th>
<th style="text-align: left;">Feature</th>
<th style="text-align: left;">Dependencies</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">5</td>
<td style="text-align: left;">Collaboration features (doodling, modeling, content loading)</td>
<td style="text-align: left;">Environment, Person to person interaction</td>
</tr>
<tr class="even">
<td style="text-align: center;">6</td>
<td style="text-align: left;">Static content creation in editor (import avatars, create worlds)</td>
<td style="text-align: left;">Environment</td>
</tr>
<tr class="odd">
<td style="text-align: center;">7</td>
<td style="text-align: left;">Shareable content (inventory)</td>
<td style="text-align: left;">Environment, Static content creation in editor</td>
</tr>
<tr class="even">
<td style="text-align: center;">8</td>
<td style="text-align: left;">Local API for extending platform</td>
<td style="text-align: left;">Environment, Web requests to servers</td>
</tr>
<tr class="odd">
<td style="text-align: center;">9</td>
<td style="text-align: left;">Video playback</td>
<td style="text-align: left;">Environment</td>
</tr>
<tr class="even">
<td style="text-align: center;">10</td>
<td style="text-align: left;">Support for proprietary video hosting</td>
<td style="text-align: left;">Video playback</td>
</tr>
</tbody>
</table>
</section>
<section id="out-of-scope-initially" class="level3">
<h3 class="anchored" data-anchor-id="out-of-scope-initially">Out of Scope Initially</h3>
<table class="table">
<colgroup>
<col style="width: 32%">
<col style="width: 25%">
<col style="width: 41%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">Priority</th>
<th style="text-align: left;">Feature</th>
<th style="text-align: left;">Dependencies</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">11</td>
<td style="text-align: left;">Text chat</td>
<td style="text-align: left;">Environment, Person to person interaction</td>
</tr>
<tr class="even">
<td style="text-align: center;">12</td>
<td style="text-align: left;">Screen sharing (OBS)</td>
<td style="text-align: left;">Environment, Person to person interaction</td>
</tr>
<tr class="odd">
<td style="text-align: center;">13</td>
<td style="text-align: left;">Modeling and 3D Creation (Blender)</td>
<td style="text-align: left;">Environment, Static content creation in editor</td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="implementation" class="level2">
<h2 class="anchored" data-anchor-id="implementation">Implementation</h2>
<p>The implementation details will be determined once the proposal is accepted and the features are finalized.</p>
</section>
<section id="positive-consequences" class="level2">
<h2 class="anchored" data-anchor-id="positive-consequences">Positive Consequences</h2>
<ul>
<li>A well-structured and prioritized feature list will guide development efforts.</li>
<li>Clear categorization helps manage stakeholder expectations about what will be included in the initial release.</li>
</ul>
</section>
<section id="negative-consequences" class="level2">
<h2 class="anchored" data-anchor-id="negative-consequences">Negative Consequences</h2>
<ul>
<li>Some features may require more time and resources than initially estimated.</li>
<li>Stakeholders may have different opinions on the priority of certain features.</li>
</ul>
</section>
<section id="option-graveyard" class="level2">
<h2 class="anchored" data-anchor-id="option-graveyard">Option Graveyard</h2>
<p>This section will include any options considered but ultimately rejected during the decision-making process.</p>
</section>
<section id="if-this-enhancement-will-be-used-infrequently-can-it-be-worked-around-with-a-few-lines-of-script" class="level2">
<h2 class="anchored" data-anchor-id="if-this-enhancement-will-be-used-infrequently-can-it-be-worked-around-with-a-few-lines-of-script">If this enhancement will be used infrequently, can it be worked around with a few lines of script?</h2>
<p>This question will be addressed during the implementation phase for each feature.</p>
</section>
<section id="is-there-a-reason-why-this-should-be-core-and-done-by-us" class="level2">
<h2 class="anchored" data-anchor-id="is-there-a-reason-why-this-should-be-core-and-done-by-us">Is there a reason why this should be core and done by us?</h2>
<p>As these features form the core functionality of the V-Sekai platform, they should be developed by our team to ensure quality and consistency.</p>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<ul>
<li><a href="https://v-sekai.org/">V-Sekai</a></li>
</ul>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20230701-vsekai-broken-down-goals.html</guid>
  <pubDate>Wed, 19 Jul 2023 23:08:35 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20230630-vsekai-goal-meeting.html</link>
  <description><![CDATA[ 



<section id="v-sekai-meeting---friday-june-30-2023" class="level1">
<h1>V-Sekai Meeting - Friday, June 30, 2023</h1>
<p>Original pad (90 day expiration): https://pad.sfconservancy.org/p/v-sekai-goals-meet-2023-06-30.md /timeslider#937</p>
<section id="context-and-problem-statement" class="level2">
<h2 class="anchored" data-anchor-id="context-and-problem-statement">Context and Problem Statement</h2>
<p>Meeting goal: determine what we can feasibly build and what we can enable others to build.</p>
</section>
<section id="principles" class="level2">
<h2 class="anchored" data-anchor-id="principles">Principles</h2>
<ul>
<li>Optimally piggybacking on systems others have built / are maintaining.</li>
<li>Build things we would want to use</li>
</ul>
</section>
<section id="foundational-runtime-features-provided-by-the-platform" class="level2">
<h2 class="anchored" data-anchor-id="foundational-runtime-features-provided-by-the-platform">Foundational Runtime Features (Provided by the Platform)</h2>
<section id="environment" class="level3">
<h3 class="anchored" data-anchor-id="environment">Environment</h3>
<ul>
<li>Scene loading support</li>
<li>World hosting (network protocol)</li>
<li>Instancing: Holepunching (users host?) and relay system and Multi-instance server system?</li>
</ul>
</section>
<section id="person-to-person-interaction" class="level3">
<h3 class="anchored" data-anchor-id="person-to-person-interaction">Person to person interaction</h3>
<ul>
<li>Avatar support</li>
<li>Avatar animation system</li>
<li>VoIP (voice communication)</li>
<li>IK synchronization and other player / avatar synchronization</li>
<li>Object parenting support (chairs)</li>
</ul>
</section>
<section id="interaction-with-the-world" class="level3">
<h3 class="anchored" data-anchor-id="interaction-with-the-world">Interaction with the World</h3>
<ul>
<li>Interactive elements</li>
<li>Grabbable objects</li>
<li>Buttons</li>
<li>Physics</li>
</ul>
</section>
<section id="additional-features" class="level3">
<h3 class="anchored" data-anchor-id="additional-features">Additional Features</h3>
<ul>
<li>Doodling (with a builtin script to save to a file)</li>
<li>Cameras (take a picture - screenshot?)</li>
<li>Mirrors + camera</li>
<li>Video player (static + playback of videos without a duration aka live) libvlc or ffmpeg</li>
<li>Local API (http OR jsonrpc OR local pipe OR OSC etc.) for Extending the Platform
<ul>
<li>Allow users to write scripts and plugins for V-Sekai</li>
<li>Or allow a local user to write custom GDScript into V-Sekai</li>
<li>API to create an object.</li>
<li>Determine RPCs or functions to expose)</li>
</ul></li>
</ul>
</section>
</section>
<section id="web-requests-http-or-websocket-to-servers" class="level2">
<h2 class="anchored" data-anchor-id="web-requests-http-or-websocket-to-servers">Web Requests (HTTP or WebSocket) to Servers</h2>
<ul>
<li>Needs API or scripting language.</li>
</ul>
</section>
<section id="foundational-static-content-creationsdk-features-in-the-editor" class="level2">
<h2 class="anchored" data-anchor-id="foundational-static-content-creationsdk-features-in-the-editor">Foundational Static Content Creation/SDK Features (in the Editor)</h2>
<ul>
<li>VRM import (avatars)</li>
<li>Godot editor</li>
<li>World creation</li>
<li>Uploading / sharing content items to an inventory.</li>
</ul>
</section>
<section id="features-that-we-can-interface-with-third-parties" class="level2">
<h2 class="anchored" data-anchor-id="features-that-we-can-interface-with-third-parties">Features that We Can interface with Third Parties</h2>
<ul>
<li>Screen sharing (OBS)</li>
<li>Modeling and 3D Creation (Blender)</li>
</ul>
</section>
<section id="features-that-we-can-enable-platform-developers-to-build" class="level2">
<h2 class="anchored" data-anchor-id="features-that-we-can-enable-platform-developers-to-build">Features that We Can Enable Platform Developers to Build</h2>
<ul>
<li>Text chat</li>
<li>Collaboration features / meeting spaces
<ul>
<li>Doodling</li>
<li>3D doodling/modeling tools sketch</li>
<li>Saving and loading of content at runtime</li>
</ul></li>
<li>Support for proprietary video hosting websites</li>
</ul>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<ul>
<li><a href="https://v-sekai.org/">V-Sekai</a></li>
</ul>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20230630-vsekai-goal-meeting.html</guid>
  <pubDate>Wed, 19 Jul 2023 23:08:35 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20230626-godot-vrm1-addon.html</link>
  <description><![CDATA[ 



<section id="ship-godot-engine-vrm1-to-solve-portable-humanoid-avatars" class="level1">
<h1>Ship Godot Engine VRM1 to solve portable humanoid avatars</h1>
<section id="metadata" class="level2">
<h2 class="anchored" data-anchor-id="metadata">Metadata</h2>
<ul>
<li>Status: proposed <!-- draft | proposed | rejected | accepted | deprecated | superseded by --></li>
<li>Deciders: V-Sekai, fire, lyuma</li>
<li>Tags: V-Sekai, ai copilot</li>
</ul>
</section>
<section id="context-and-problem-statement" class="level2">
<h2 class="anchored" data-anchor-id="context-and-problem-statement">Context and Problem Statement</h2>
<p>Have portable humanoid avatars.</p>
</section>
<section id="proposed-solution" class="level2">
<h2 class="anchored" data-anchor-id="proposed-solution">Proposed Solution</h2>
<p>Ship Godot Engine VRM1 to Godot Engine asset Library.</p>
</section>
<section id="implementation" class="level2">
<h2 class="anchored" data-anchor-id="implementation">Implementation</h2>
<ol type="1">
<li>Implement basic humanoid avatar functionality such as rigging, animation, and basic physics through VRM1 spring bones.</li>
<li>Implement support for both MToon1 and MToon0 materials, which provide a physically-based rendering approach for anime-style graphics.</li>
<li>Implement support for the glTF PBR material type, which provides a more physically-based rendering approach for realistic graphics.</li>
<li>Implement facial expressions, eye tracking, and lip syncing for a more immersive experience.</li>
<li>Implement export by copying the import code in reverse, and refine it over time.</li>
<li>Use the VRM spec’s suggested algorithm for implementing first-person view, which eliminates the need for head scaling.</li>
<li>Prioritize necessary features and say no to suggestions that are not necessary to avoid feature bloat.</li>
<li>Do not implement AnimationTree for this proposal.</li>
</ol>
</section>
<section id="positive-consequences" class="level2">
<h2 class="anchored" data-anchor-id="positive-consequences">Positive Consequences</h2>
<ul>
<li>Portable humanoid avatars can be easily created and used in Godot Engine projects.</li>
<li>The addition of MToon1 material support provides a physically-based rendering approach for anime-style graphics.</li>
<li>Facial expressions, eye tracking, and lip syncing enhance the immersive experience for users.</li>
<li>Export functionality allows for easy sharing of avatars between projects and with other users.</li>
<li>The use of the VRM spec’s suggested algorithm for implementing first-person view simplifies the implementation process.</li>
</ul>
</section>
<section id="negative-consequences" class="level2">
<h2 class="anchored" data-anchor-id="negative-consequences">Negative Consequences</h2>
<ul>
<li>The implementation of these features may require additional development time and resources.</li>
<li>The addition of new features may increase the complexity of the codebase and require additional maintenance.</li>
<li>The use of the MToon1 material may require additional GPU resources and may not be suitable for low-end hardware.</li>
<li>The implementation of facial expressions, eye tracking, and lip syncing may require additional hardware or software support.</li>
</ul>
</section>
<section id="option-graveyard" class="level2">
<h2 class="anchored" data-anchor-id="option-graveyard">Option graveyard</h2>
<p>We are not implementing support for other material types beyond MToon0, MToon1 and gltf PBR, which could limit the range of visual styles that can be achieved with Godot Engine.</p>
</section>
<section id="if-this-enhancement-will-be-used-infrequently-can-it-be-worked-around-with-a-few-lines-of-script" class="level2">
<h2 class="anchored" data-anchor-id="if-this-enhancement-will-be-used-infrequently-can-it-be-worked-around-with-a-few-lines-of-script">If this enhancement will be used infrequently, can it be worked around with a few lines of script?</h2>
<p>It is unlikely that these enhancements can be easily worked around with a few lines of script, as they require significant development effort and integration with the Godot Engine codebase.</p>
</section>
<section id="is-there-a-reason-why-this-should-be-core-and-done-by-us" class="level2">
<h2 class="anchored" data-anchor-id="is-there-a-reason-why-this-should-be-core-and-done-by-us">Is there a reason why this should be core and done by us?</h2>
<ul>
<li>Portable humanoid avatars are a key feature for many Godot Engine projects, and the ability to easily create and use them is important for the success of the engine.</li>
<li>The addition of MToon1 material support and other enhancements will improve the quality and visual fidelity of Godot Engine projects.</li>
<li>By implementing these features in-house, we can ensure that they are well-integrated with the Godot Engine codebase and meet our quality standards.</li>
</ul>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<ul>
<li><a href="https://v-sekai.org/">V-Sekai</a></li>
<li>https://github.com/vrm-c/vrm-specification</li>
<li>https://github.com/vrm-c/vrm-specification/blob/master/specification/VRMC_vrm-1.0/firstPerson.md#meshannotationauto-algorithm</li>
</ul>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20230626-godot-vrm1-addon.html</guid>
  <pubDate>Wed, 19 Jul 2023 23:08:35 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20230624-v-sekai-roadmap.html</link>
  <description><![CDATA[ 



<section id="v-sekai-roadmap-and-goals-2023-06-24" class="level1">
<h1>V-Sekai Roadmap and Goals 2023-06-24</h1>
<section id="metadata" class="level3">
<h3 class="anchored" data-anchor-id="metadata">Metadata</h3>
<ul>
<li>Status: accepted</li>
<li>Deciders: V-Sekai, fire</li>
<li>Tags: V-Sekai, chatgpt4 summary,</li>
</ul>
</section>
<section id="context-and-problem-statement" class="level3">
<h3 class="anchored" data-anchor-id="context-and-problem-statement">Context and Problem Statement</h3>
<p>What is the V-Sekai Roadmap and Goals?</p>
</section>
<section id="describe-the-proposed-option-and-how-it-helps-to-overcome-the-problem-or-limitation" class="level3">
<h3 class="anchored" data-anchor-id="describe-the-proposed-option-and-how-it-helps-to-overcome-the-problem-or-limitation">Describe the proposed option and how it helps to overcome the problem or limitation</h3>
<p>The roadmap presented here is short-term.</p>
</section>
<section id="describe-how-your-proposal-will-work-with-code-pseudo-code-mock-ups-or-diagrams" class="level3">
<h3 class="anchored" data-anchor-id="describe-how-your-proposal-will-work-with-code-pseudo-code-mock-ups-or-diagrams">Describe how your proposal will work with code, pseudo-code, mock-ups, or diagrams</h3>
<p>By avoiding work on User Generated Content (UGC) and world building, we can prioritize the three main states in the roadmap: “World / Avatar Performance” (WAP), “Networking” (NET), and “UI/UX”. This allows the team to focus on the core aspects of V-Sekai and achieve the goals more efficiently.</p>
<ol type="1">
<li><strong>Monitoring and Logging System Test</strong>:
<ol type="1">
<li>Setup logging framework</li>
<li>Configure monitoring system</li>
<li>Create a dashboard</li>
</ol></li>
<li><strong>Test Environment with Simulated Data Test</strong>:
<ol type="1">
<li>Create test scenarios</li>
<li>Generate simulated data</li>
<li>Configure test environment</li>
<li>Execute test scenarios</li>
<li>Analyze test results</li>
</ol></li>
</ol>
</section>
<section id="positive-consequences" class="level3">
<h3 class="anchored" data-anchor-id="positive-consequences">Positive Consequences</h3>
<ul>
<li>Easier creation of V-Sekai.</li>
<li>Focused development on core aspects.</li>
</ul>
</section>
<section id="negative-consequences" class="level3">
<h3 class="anchored" data-anchor-id="negative-consequences">Negative Consequences</h3>
<ul>
<li>Potential overhead challenges.</li>
</ul>
</section>
<section id="option-graveyard" class="level3">
<h3 class="anchored" data-anchor-id="option-graveyard">Option graveyard</h3>
<ul>
<li>Waiting for Godot Engine 4.2 instead of assisting with 4.1 features.</li>
</ul>
</section>
<section id="if-this-enhancement-will-be-used-infrequently-can-it-be-worked-around-with-a-few-lines-of-script" class="level3">
<h3 class="anchored" data-anchor-id="if-this-enhancement-will-be-used-infrequently-can-it-be-worked-around-with-a-few-lines-of-script">If this enhancement will be used infrequently, can it be worked around with a few lines of script?</h3>
<p>No.&nbsp;This is a process.</p>
</section>
<section id="is-there-a-reason-why-this-should-be-core-and-done-by-us" class="level3">
<h3 class="anchored" data-anchor-id="is-there-a-reason-why-this-should-be-core-and-done-by-us">Is there a reason why this should be core and done by us?</h3>
<p>This is a core process for V-Sekai.</p>
</section>
<section id="references" class="level3">
<h3 class="anchored" data-anchor-id="references">References</h3>
<ul>
<li><a href="https://v-sekai.org/">V-Sekai</a></li>
</ul>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20230624-v-sekai-roadmap.html</guid>
  <pubDate>Wed, 19 Jul 2023 23:08:35 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20230623-fdn-reverb-solution.html</link>
  <description><![CDATA[ 



<section id="implementing-feedback-delay-networks-for-enhanced-audio-reverb-simulation-in-v-sekai" class="level1">
<h1>Implementing Feedback Delay Networks for Enhanced Audio Reverb Simulation in V-Sekai</h1>
<section id="metadata" class="level2">
<h2 class="anchored" data-anchor-id="metadata">Metadata</h2>
<ul>
<li>Status: proposed</li>
<li>Deciders: V-Sekai, ellenhp, fire</li>
<li>Tags: V-Sekai, ai assisted</li>
</ul>
</section>
<section id="context-and-problem-statement" class="level2">
<h2 class="anchored" data-anchor-id="context-and-problem-statement">Context and Problem Statement</h2>
<p>The problem of simulating audio reverb in Godot Engine 4 involves accurately modeling the way sound waves propagate, reflect, and interact within a given environment. This requires sampling a chaotic 7-dimensional space every frame, either through precomputation or real-time processing. The complexity arises from the fact that sound behaves more like light with intense diffraction, making it impossible to rasterize.</p>
</section>
<section id="proposed-solution" class="level2">
<h2 class="anchored" data-anchor-id="proposed-solution">Proposed Solution</h2>
<p>Implement Feedback Delay Networks (FDNs) for artificial reverberation. FDNs consist of multiple delay lines connected in a feedback loop with a mixing matrix. The output is a combination of the input signal and the delayed signals.</p>
<section id="steps" class="level3">
<h3 class="anchored" data-anchor-id="steps">Steps:</h3>
<ol type="1">
<li>Choose the number of delay lines and their lengths based on the desired reverberation time and room characteristics.</li>
<li>Implement a mixing matrix to control the energy distribution between the delay lines.</li>
<li>Create a feedback loop by connecting the outputs of the delay lines to the inputs through the mixing matrix.</li>
<li>Combine the input signal with the delayed signals to produce the reverberated output.</li>
</ol>
</section>
</section>
<section id="implementation" class="level2">
<h2 class="anchored" data-anchor-id="implementation">Implementation</h2>
<pre class="gdscript"><code>class_name FDN
extends Node

var num_delay_lines : int
var delay_lines : Array
var mixing_matrix : Array
var room_characteristics : Dictionary

func _init(num_delay_lines: int, delay_lengths: Array, mixing_matrix: Array, room_characteristics: Dictionary):
    self.num_delay_lines = num_delay_lines
    self.delay_lines = []
    for length in delay_lengths:
        self.delay_lines.append(DelayLine.new(length))
    self.mixing_matrix = mixing_matrix
    self.room_characteristics = room_characteristics

func process(input_signal: float) -&gt; float:
    # Step 1: Calculate the output of each delay line
    var delay_outputs = []
    for dl in self.delay_lines:
        delay_outputs.append(dl.process(input_signal))

    # Step 2: Apply the room characteristics to the delay line outputs
    var processed_outputs = apply_room_characteristics(delay_outputs)

    # Step 3: Apply the mixing matrix to the processed delay line outputs
    var mixed_outputs = apply_mixing_matrix(processed_outputs)

    # Step 4: Update the delay lines with the mixed outputs
    for i in range(self.num_delay_lines):
        self.delay_lines[i].update(mixed_outputs[i])

    # Step 5: Combine the input signal with the delayed signals
    var output_signal = input_signal + sum(mixed_outputs)
    return output_signal

func apply_room_characteristics(delay_outputs: Array) -&gt; Array:
    var processed_outputs = []
    for i in range(len(delay_outputs)):
        processed_output = delay_outputs[i] * room_characteristics["absorption"][i]
        processed_outputs.append(processed_output)
    return processed_outputs

func apply_mixing_matrix(delay_outputs: Array) -&gt; Array:
    # TODO: Implement the mixing matrix application logic
    pass</code></pre>
</section>
<section id="positive-consequences" class="level2">
<h2 class="anchored" data-anchor-id="positive-consequences">Positive Consequences</h2>
<ul>
<li>Improved audio reverb simulation</li>
<li>More realistic sound propagation and interaction within environments</li>
<li>Smarter estimation of long reverb times</li>
</ul>
</section>
<section id="negative-consequences" class="level2">
<h2 class="anchored" data-anchor-id="negative-consequences">Negative Consequences</h2>
<ul>
<li>Increased computational complexity</li>
<li>Potential performance impact on real-time processing</li>
</ul>
</section>
<section id="option-graveyard" class="level2">
<h2 class="anchored" data-anchor-id="option-graveyard">Option graveyard</h2>
<ul>
<li>Generalized Dijkstra Pathfinding</li>
<li>DWN (Digital Waveguide Network): A method for simulating audio reverb by modeling sound propagation as waves traveling along waveguides with bidirectional delay lines and scattering junctions.</li>
<li>Ray tracing can be used to simulate sound propagation in 3D environments. It involves casting rays from the sound source and tracing their paths as they interact with the environment (reflect, refract, and diffract). By calculating the time delay and attenuation of each ray reaching the listener, you can generate an impulse response that represents the acoustic properties of the space.</li>
<li>Convolution reverb is a technique that uses recorded impulse responses (IRs) of real spaces or digital simulations to recreate the reverberation characteristics of those spaces. The process involves convolving the dry audio signal with the impulse response to produce the reverberated audio.</li>
</ul>
</section>
<section id="if-this-enhancement-will-be-used-infrequently-can-it-be-worked-around-with-a-few-lines-of-script" class="level2">
<h2 class="anchored" data-anchor-id="if-this-enhancement-will-be-used-infrequently-can-it-be-worked-around-with-a-few-lines-of-script">If this enhancement will be used infrequently, can it be worked around with a few lines of script?</h2>
<p>No, implementing FDNs requires a more complex algorithm and cannot be achieved with just a few lines of script.</p>
</section>
<section id="is-there-a-reason-why-this-should-be-core-and-done-by-us" class="level2">
<h2 class="anchored" data-anchor-id="is-there-a-reason-why-this-should-be-core-and-done-by-us">Is there a reason why this should be core and done by us?</h2>
<p>Yes, as it directly impacts the audio experience within V-Sekai environments, it should be a core feature to ensure consistent and high-quality audio reverb simulation.</p>
</section>
<section id="glossary-implementing-feedback-delay-networks-for-enhanced-audio-reverb-simulation-in-v-sekai" class="level2">
<h2 class="anchored" data-anchor-id="glossary-implementing-feedback-delay-networks-for-enhanced-audio-reverb-simulation-in-v-sekai">Glossary: Implementing Feedback Delay Networks for Enhanced Audio Reverb Simulation in V-Sekai</h2>
<ul>
<li><strong>V-Sekai</strong>: A virtual reality platform that allows users to create and explore immersive environments.</li>
<li><strong>Godot Engine 4</strong>: An open-source game engine used for creating 2D and 3D games and interactive applications.</li>
<li><strong>Audio Reverb</strong>: The persistence of sound in a particular space after the original sound has stopped, caused by reflections off surfaces within the environment.</li>
<li><strong>Feedback Delay Networks (FDNs)</strong>: A method for simulating artificial reverberation using multiple delay lines connected in a feedback loop with a mixing matrix.</li>
<li><strong>Delay Line</strong>: A digital signal processing technique that introduces a time delay to an input signal, often used in audio effects such as reverb and echo.</li>
<li><strong>Mixing Matrix</strong>: A mathematical construct used to control the energy distribution between the delay lines in an FDN.</li>
<li><strong>Room Characteristics</strong>: Acoustic properties of a room or environment, such as absorption, reflection, and diffusion, which affect how sound propagates within the space.</li>
<li><strong>Reverberation Time</strong>: The time it takes for the sound level in a room to decrease by 60 decibels after the sound source has stopped.</li>
<li><strong>Digital Waveguide Network (DWN)</strong>: An alternative method for simulating audio reverb by modeling sound propagation as waves traveling along waveguides with bidirectional delay lines and scattering junctions.</li>
<li><strong>Ray Tracing</strong>: A technique used to simulate sound propagation in 3D environments by casting rays from the sound source and tracing their paths as they interact with the environment (reflect, refract, and diffract).</li>
<li><strong>Convolution Reverb</strong>: A technique that uses recorded impulse responses (IRs) of real spaces or digital simulations to recreate the reverberation characteristics of those spaces by convolving the dry audio signal with the impulse response.</li>
<li><strong>Impulse Response (IR)</strong>: A recording or simulation of the acoustic properties of a space, used in convolution reverb to recreate the reverberation characteristics of that space.</li>
</ul>
</section>
<section id="computational-and-io-complexity-an-example" class="level2">
<h2 class="anchored" data-anchor-id="computational-and-io-complexity-an-example">Computational and I/O Complexity: An Example</h2>
<p>Let’s consider an example of implementing a Feedback Delay Network (FDN) for audio reverb simulation with 8 delay lines. We will analyze the computational and I/O complexity involved in this specific case.</p>
<section id="fdn-reverb-claims-may-need-to-be-verified" class="level3">
<h3 class="anchored" data-anchor-id="fdn-reverb-claims-may-need-to-be-verified">FDN reverb claims may need to be verified</h3>
<ol type="1">
<li>For a medium-quality reverb effect, let’s consider using 8 delay lines in the FDN.</li>
<li>For an 8x8 matrix, there are 64 multiplications and 56 additions required for each sample.</li>
<li>Overall, the computational complexity for a medium-quality reverb effect with 8 delay lines is manageable for most modern CPUs and can be efficiently processed in real-time.</li>
<li>In summary, implementing a medium-quality reverb effect using an FDN with 8 delay lines has a manageable computational and I/O complexity, making it suitable for real-time processing on most modern hardware.</li>
</ol>
</section>
<section id="computational-complexity" class="level3">
<h3 class="anchored" data-anchor-id="computational-complexity">Computational Complexity</h3>
<p>For a medium-quality reverb effect, let’s consider using 8 delay lines in the FDN. The main components contributing to the computational complexity are:</p>
<ol type="1">
<li><p><strong>Delay Lines</strong>: Each delay line requires memory for storing the delayed samples and computations for updating the delay buffer. For 8 delay lines, the complexity scales linearly with the number of delay lines.</p></li>
<li><p><strong>Matrix Mixing</strong>: The mixing matrix combines the outputs of the delay lines in a specific way to create the desired reverb effect. For an 8x8 matrix, there are 64 multiplications and 56 additions required for each sample.</p></li>
<li><p><strong>Feedback and Input/Output Processing</strong>: Additional processing, such as filtering or gain adjustments, may be applied to the input, output, or feedback paths. This complexity depends on the specific filters or processing used but is generally proportional to the number of delay lines.</p></li>
</ol>
<p>Overall, the computational complexity for a medium-quality reverb effect with 8 delay lines is manageable for most modern CPUs and can be efficiently processed in real-time.</p>
</section>
<section id="io-complexity" class="level3">
<h3 class="anchored" data-anchor-id="io-complexity">I/O Complexity</h3>
<p>The I/O complexity refers to the amount of data that needs to be read from and written to memory during the processing of the reverb effect. In the case of an FDN with 8 delay lines, the I/O complexity is mainly determined by:</p>
<ol type="1">
<li><p><strong>Reading and Writing Delay Line Buffers</strong>: Each delay line requires reading and writing operations for updating the delay buffer. The I/O complexity scales linearly with the number of delay lines.</p></li>
<li><p><strong>Input and Output Audio Data</strong>: The audio input data must be read, processed, and combined with the output of the FDN to generate the final reverberated audio signal. The I/O complexity for input and output audio data is generally low compared to the delay line buffer operations.</p></li>
</ol>
<p>In summary, implementing a medium-quality reverb effect using an FDN with 8 delay lines has a manageable computational and I/O complexity, making it suitable for real-time processing on most modern hardware.</p>


</section>
</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20230623-fdn-reverb-solution.html</guid>
  <pubDate>Wed, 19 Jul 2023 23:08:35 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20230620-t5-jsonformer-xstate.html</link>
  <description><![CDATA[ 



<section id="large-language-model-t5-generating-xstate-json-reliabily-for-digital-beings" class="level1">
<h1>Large language model t5 generating xstate json reliabily for digital beings</h1>
<section id="metadata" class="level2">
<h2 class="anchored" data-anchor-id="metadata">Metadata</h2>
<ul>
<li>Status: proposed</li>
<li>Deciders: V-Sekai</li>
<li>Tags: V-Sekai</li>
</ul>
</section>
<section id="context-and-problem-statement" class="level2">
<h2 class="anchored" data-anchor-id="context-and-problem-statement">Context and Problem Statement</h2>
<p>V-Sekai is facing a limitation that requires a solution to convert natural language text into XState JSON format for executing behavior statecharts for digital beings. This can be achieved by using the T5 (Text-to-Text Transfer Transformer) model with JSON-former for XState in Godot Engine 4.0.</p>
</section>
<section id="proposed-solution" class="level2">
<h2 class="anchored" data-anchor-id="proposed-solution">Proposed Solution</h2>
<p>The proposed solution involves using the T5 model to generate text based on input text and then converting the generated text into XState JSON format, all within the Godot Engine 4.0 environment.</p>
</section>
<section id="implementation" class="level2">
<h2 class="anchored" data-anchor-id="implementation">Implementation</h2>
<p>To use T5 (Text-to-Text Transfer Transformer) with JSON-former for XState in Godot Engine 4.0, you’ll need to follow these steps:</p>
<ol type="1">
<li><strong>Load the necessary libraries</strong></li>
</ol>
<pre class="gd"><code>var transformers = preload("res://path/to/transformers.gd")
var torch = preload("res://path/to/torch.gd")</code></pre>
<ol start="2" type="1">
<li><strong>Load the T5 model and tokenizer</strong></li>
</ol>
<pre class="gd"><code>var model_name = "t5-small"
var tokenizer = transformers.load_T5Tokenizer(model_name)
var model = transformers.load_T5ForConditionalGeneration(model_name)</code></pre>
<ol start="3" type="1">
<li><strong>Create a function to generate text using T5</strong></li>
</ol>
<pre class="gd"><code>func generate_text(input_text: String) -&gt; String:
    var input_ids = tokenizer.encode(input_text)
    var outputs = model.generate(input_ids)
    var generated_text = tokenizer.decode(outputs[0])
    return generated_text</code></pre>
<ol start="4" type="1">
<li><strong>Create a function to replace placeholders in T5 output</strong></li>
</ol>
<pre class="gd"><code>func replace_placeholders(text: String) -&gt; String:
    var formatted_text = text.replace("&lt;extra_id_0&gt;", "event").replace("&lt;extra_id_1&gt;", "state")
    return formatted_text</code></pre>
<ol start="5" type="1">
<li><strong>Create a function to parse JSON from formatted text</strong></li>
</ol>
<pre class="gd"><code>func parse_JSON(formatted_text: String) -&gt; Dictionary:
    var json_object = JSON.parse(formatted_text).result
    return json_object</code></pre>
<ol start="6" type="1">
<li><strong>Create a function to convert T5 output to XState JSON format</strong></li>
</ol>
<pre class="gd"><code>func t5_to_jsonformer_xstate(text: String) -&gt; Dictionary:
    var formatted_text = replace_placeholders(text)
    var json_object = parse_JSON(formatted_text)
    return json_object</code></pre>
<ol start="7" type="1">
<li><strong>Use the functions to generate XState JSON</strong></li>
</ol>
<pre class="gd"><code>func _ready():
    var input_text = "your input text here"
    var t5_output = generate_text(input_text)
    var xstate_json = t5_to_jsonformer_xstate(t5_output)
    print(xstate_json)</code></pre>
<p>This will give you the XState JSON format for the given input text. Note that the T5 model might need to be fine-tuned on a dataset specific to your use case to generate accurate XState JSON representations.</p>
</section>
<section id="positive-consequences" class="level2">
<h2 class="anchored" data-anchor-id="positive-consequences">Positive Consequences</h2>
<ul>
<li>Automates the process of converting natural language text into XState JSON format within the Godot Engine 4.0 environment.</li>
<li>Reduces manual effort and potential errors in creating XState JSON representations.</li>
</ul>
</section>
<section id="negative-consequences" class="level2">
<h2 class="anchored" data-anchor-id="negative-consequences">Negative Consequences</h2>
<ul>
<li>The T5 model may require fine-tuning on a specific dataset to generate accurate XState JSON representations.</li>
<li>There might be limitations in understanding complex or ambiguous input text.</li>
</ul>
</section>
<section id="option-graveyard" class="level2">
<h2 class="anchored" data-anchor-id="option-graveyard">Option graveyard</h2>
<p>Here are some option graveyard items for the proposal:</p>
<ol type="1">
<li><p><strong>Using rule-based natural language processing (NLP) techniques</strong></p>
<ul>
<li>Pros:
<ul>
<li>Easier to implement and understand.</li>
<li>No need for training data or fine-tuning.</li>
</ul></li>
<li>Cons:
<ul>
<li>Limited in handling complex or ambiguous input text.</li>
<li>Requires manual updates to rules as new use cases emerge.</li>
</ul></li>
</ul></li>
<li><p><strong>Using other pre-trained NLP models (e.g., GPT-3, BERT)</strong></p>
<ul>
<li>Pros:
<ul>
<li>Can leverage existing state-of-the-art NLP models.</li>
<li>May provide better performance on certain tasks.</li>
</ul></li>
<li>Cons:
<ul>
<li>May require additional fine-tuning or adaptation for the specific task.</li>
<li>Some models may have higher computational requirements or costs.</li>
</ul></li>
</ul></li>
<li><p><strong>Creating a custom NLP model from scratch</strong></p>
<ul>
<li>Pros:
<ul>
<li>Tailored specifically for the task of converting natural language text into XState JSON format.</li>
<li>Potential for better performance if designed well.</li>
</ul></li>
<li>Cons:
<ul>
<li>Requires significant time and effort to develop, train, and maintain.</li>
<li>May not perform as well as existing state-of-the-art models.</li>
</ul></li>
</ul></li>
<li><p><strong>Using an external API or service for natural language understanding</strong></p>
<ul>
<li>Pros:
<ul>
<li>Offloads the complexity of NLP to an external service.</li>
<li>Can potentially leverage more advanced NLP techniques.</li>
</ul></li>
<li>Cons:
<ul>
<li>Introduces dependency on an external service.</li>
<li>May incur additional costs or usage limitations.</li>
</ul></li>
</ul></li>
</ol>
<p>These options were considered but ultimately discarded in favor of using the T5 model with JSON-former for XState in Godot Engine 4.0 due to its balance of performance, ease of implementation, and adaptability to the specific task.</p>
</section>
<section id="if-this-enhancement-will-be-used-infrequently-can-it-be-worked-around-with-a-few-lines-of-script" class="level2">
<h2 class="anchored" data-anchor-id="if-this-enhancement-will-be-used-infrequently-can-it-be-worked-around-with-a-few-lines-of-script">If this enhancement will be used infrequently, can it be worked around with a few lines of script?</h2>
<p>The proposed solution requires more than a few lines of script and involves using a pre-trained model (T5) to generate the desired output within the Godot Engine 4.0 environment.</p>
</section>
<section id="is-there-a-reason-why-this-should-be-core-and-done-by-us" class="level2">
<h2 class="anchored" data-anchor-id="is-there-a-reason-why-this-should-be-core-and-done-by-us">Is there a reason why this should be core and done by us?</h2>
<p>Implementing this solution as part of the core functionality can help V-Sekai users automate the process of generating XState JSON representations from natural language text within the Godot Engine 4.0 environment, improving efficiency and reducing manual effort.</p>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<ul>
<li><a href="https://v-sekai.org/">V-Sekai</a></li>
<li><a href="https://godotengine.org/">Godot Engine</a></li>
<li><a href="https://docs.godotengine.org/en/stable/getting_started/scripting/gdscript/gdscript_basics.html">GDScript documentation</a></li>
<li><a href="https://arxiv.org/abs/1910.10683">T5 (Text-to-Text Transfer Transformer)</a></li>
<li><a href="https://huggingface.co/transformers/">Transformers library</a></li>
<li><a href="https://xstate.js.org/docs/">XState documentation</a></li>
</ul>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20230620-t5-jsonformer-xstate.html</guid>
  <pubDate>Wed, 19 Jul 2023 23:08:35 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20230620-doi-github.html</link>
  <description><![CDATA[ 



<section id="a-potential-solution-for-v-sekais-identifier-assignment-challenge" class="level1">
<h1>A Potential Solution for V-Sekai’s Identifier Assignment Challenge</h1>
<section id="metadata" class="level2">
<h2 class="anchored" data-anchor-id="metadata">Metadata</h2>
<ul>
<li>Status: proposed</li>
<li>Deciders: V-Sekai, fire</li>
<li>Tags: V-Sekai, AI-augmented</li>
</ul>
</section>
<section id="context-and-problem-statement" class="level2">
<h2 class="anchored" data-anchor-id="context-and-problem-statement">Context and Problem Statement</h2>
<p>V-Sekai requires a method to assign permanent Digital Object Identifiers (DOIs) to their digital artifacts.</p>
</section>
<section id="suggested-solution" class="level2">
<h2 class="anchored" data-anchor-id="suggested-solution">Suggested Solution</h2>
<p>Leverage Github and Zenodo to create a permanent DOI for V-Sekai’s data and code.</p>
</section>
<section id="implementation" class="level2">
<h2 class="anchored" data-anchor-id="implementation">Implementation</h2>
<p>Follow these steps in the guide below:</p>
<ol type="1">
<li>Set up a Github Repository</li>
<li>Connect Github to Zenodo</li>
<li>Activate Github Repository in Zenodo</li>
<li>Generate a Release in Github</li>
<li>Obtain Your DOI from Zenodo</li>
<li>Showcase DOI Badge in Github README (optional)</li>
</ol>
</section>
<section id="positive-consequences" class="level2">
<h2 class="anchored" data-anchor-id="positive-consequences">Positive Consequences</h2>
<ul>
<li>Persistent DOIs for data and code</li>
<li>Effortless referencing of repositories across browsers</li>
<li>Enhanced visibility and accessibility of V-Sekai’s digital artifacts</li>
</ul>
</section>
<section id="negative-consequences" class="level2">
<h2 class="anchored" data-anchor-id="negative-consequences">Negative Consequences</h2>
<ul>
<li>Necessitates managing multiple platforms (Github and Zenodo)</li>
<li>Possible learning curve for users unfamiliar with Github and Zenodo</li>
</ul>
</section>
<section id="alternative-options" class="level2">
<h2 class="anchored" data-anchor-id="alternative-options">Alternative Options</h2>
<ol type="1">
<li><p><strong>Utilizing Figshare</strong>: Figshare is an alternative platform that enables assigning DOIs to digital artifacts. However, its integration with Github may not be as smooth as Zenodo’s.</p></li>
<li><p><strong>Manual DOI registration</strong>: Manually registering a DOI through agencies like DataCite or CrossRef. This option can be labor-intensive and might involve additional fees.</p></li>
<li><p><strong>Depending on publisher-assigned DOIs</strong>: Some publishers allocate DOIs to supplementary materials during article publication. However, this option relies on the publisher’s policies and may not encompass all digital artifacts.</p></li>
<li><p><strong>Employing institutional repositories</strong>: Certain institutions provide their own repositories for hosting digital artifacts and assigning DOIs. This option could be constrained by institutional policies and access limitations.</p></li>
<li><p><strong>No DOI</strong>: Opting not to assign a DOI to V-Sekai’s digital artifacts, which would complicate referencing and long-term accessibility.</p></li>
</ol>
</section>
<section id="can-this-enhancement-be-worked-around-with-a-few-lines-of-script-if-used-infrequently" class="level2">
<h2 class="anchored" data-anchor-id="can-this-enhancement-be-worked-around-with-a-few-lines-of-script-if-used-infrequently">Can this enhancement be worked around with a few lines of script if used infrequently?</h2>
<p>No, this solution demands integration between Github and Zenodo to produce a permanent DOI.</p>
</section>
<section id="is-there-a-reason-why-this-should-be-core-and-implemented-by-us" class="level2">
<h2 class="anchored" data-anchor-id="is-there-a-reason-why-this-should-be-core-and-implemented-by-us">Is there a reason why this should be core and implemented by us?</h2>
<p>Yes, allocating a permanent DOI to V-Sekai’s digital artifacts guarantees long-term accessibility and accurate referencing in publications or other materials.</p>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<ul>
<li><a href="https://v-sekai.org/">V-Sekai</a></li>
<li><a href="https://github.com/">Github</a></li>
<li><a href="https://zenodo.org/">Zenodo</a></li>
<li>https://github.com/GlobalEcologyFlinders/assignDOI</li>
</ul>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20230620-doi-github.html</guid>
  <pubDate>Wed, 19 Jul 2023 23:08:35 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20230619-move-cockroachdb-to-yugabyte.html</link>
  <description><![CDATA[ 



<section id="v-sekai-database-solution-for-50000-concurrent-online-users" class="level1">
<h1>V-Sekai Database Solution for 50,000 Concurrent Online Users</h1>
<section id="metadata" class="level2">
<h2 class="anchored" data-anchor-id="metadata">Metadata</h2>
<ul>
<li>Status: proposed</li>
<li>Deciders: V-Sekai, fire</li>
<li>Tags: V-Sekai, llm summarization</li>
</ul>
</section>
<section id="context-and-problem-statement" class="level2">
<h2 class="anchored" data-anchor-id="context-and-problem-statement">Context and Problem Statement</h2>
<p>V-Sekai is currently facing a decision on which database solution to use for their project that can handle the load of 50,000 concurrent online users. The options being considered are <a href="https://www.postgresql.org/">PostgreSQL</a>, <a href="https://www.cockroachlabs.com/">CockroachDB</a>, <a href="https://forums.foundationdb.org/t/mvsqlite-distributed-mvcc-sqlite-that-runs-on-foundationdb/3493">SQLite on FoundationDB</a>, or <a href="https://docs.yugabyte.com/stable/api/ysql/datatypes/">YugabyteDB</a>. Each option has its own set of advantages and disadvantages, and the team needs to determine which one best fits their requirements.</p>
</section>
<section id="proposed-solution" class="level2">
<h2 class="anchored" data-anchor-id="proposed-solution">Proposed Solution</h2>
<p>Based on the discussion, it seems that YugabyteDB might be a suitable choice for V-Sekai’s needs. It offers a single-node setup with the potential for growth, supports a wide range of data types, and provides externally consistent transaction levels. Additionally, YugabyteDB appears to be more compatible with the existing schema compared to SQLite.</p>
</section>
<section id="implementation" class="level2">
<h2 class="anchored" data-anchor-id="implementation">Implementation</h2>
<p>To implement YugabyteDB as the chosen database solution, the following steps should be taken:</p>
<ol type="1">
<li>Evaluate YugabyteDB’s compatibility with the existing schema and identify any necessary adjustments.</li>
<li>Set up a single-node YugabyteDB instance for initial development and testing.</li>
<li>Migrate existing data from the current database solution to YugabyteDB.</li>
<li>Update the application code to work with YugabyteDB.</li>
<li>Perform thorough testing to ensure stability and performance meet expectations.</li>
</ol>
</section>
<section id="positive-consequences" class="level2">
<h2 class="anchored" data-anchor-id="positive-consequences">Positive Consequences</h2>
<ul>
<li>Single-node setup with the potential for growth</li>
<li>Compatibility with the existing schema</li>
<li>Support for a wide range of data types</li>
<li>Externally consistent transaction levels</li>
</ul>
</section>
<section id="negative-consequences" class="level2">
<h2 class="anchored" data-anchor-id="negative-consequences">Negative Consequences</h2>
<ul>
<li>Potential new problems and challenges associated with adopting a new database solution</li>
<li>Possible learning curve for the team in working with YugabyteDB</li>
</ul>
</section>
<section id="option-graveyard" class="level2">
<h2 class="anchored" data-anchor-id="option-graveyard">Option graveyard</h2>
<ol type="1">
<li><strong>PostgreSQL</strong>: While a popular and powerful database solution, it may not offer the desired single-node setup with growth potential.</li>
<li><strong>CockroachDB</strong>: The current implementation has been problematic due to its 3-node distributed configuration in Kubernetes.</li>
<li><strong>SQLite on FoundationDB</strong>: Limited data types and compatibility issues with the existing schema make this option less desirable.</li>
</ol>
</section>
<section id="if-this-enhancement-will-be-used-infrequently-can-it-be-worked-around-with-a-few-lines-of-script" class="level2">
<h2 class="anchored" data-anchor-id="if-this-enhancement-will-be-used-infrequently-can-it-be-worked-around-with-a-few-lines-of-script">If this enhancement will be used infrequently, can it be worked around with a few lines of script?</h2>
<p>No, the choice of database solution is a core aspect of the project and cannot be easily worked around with a script.</p>
</section>
<section id="is-there-a-reason-why-this-should-be-core-and-done-by-us" class="level2">
<h2 class="anchored" data-anchor-id="is-there-a-reason-why-this-should-be-core-and-done-by-us">Is there a reason why this should be core and done by us?</h2>
<p>Yes, selecting the appropriate database solution is crucial for the success and stability of V-Sekai. It directly impacts the performance, scalability, and maintainability of the platform.</p>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<ul>
<li><a href="https://v-sekai.org/">V-Sekai</a></li>
<li><a href="https://docs.yugabyte.com/stable/api/ysql/datatypes/">YugabyteDB Data Types</a></li>
<li><a href="https://www.cockroachlabs.com/">Cockroach Labs</a></li>
<li><a href="https://forums.foundationdb.org/t/mvsqlite-distributed-mvcc-sqlite-that-runs-on-foundationdb/3493">MVSQLite: Distributed MVCC SQLite that runs on FoundationDB</a></li>
<li><a href="https://www.postgresql.org/">PostgreSQL</a></li>
</ul>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20230619-move-cockroachdb-to-yugabyte.html</guid>
  <pubDate>Wed, 19 Jul 2023 23:08:35 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20230619-membrane-framework-for-mesh-processing.html</link>
  <description><![CDATA[ 



<section id="networked-procedural-generation-as-a-sidecar-to-the-godot-engine-server" class="level1">
<h1>Networked Procedural Generation as a Sidecar to the Godot Engine Server</h1>
<section id="metadata" class="level2">
<h2 class="anchored" data-anchor-id="metadata">Metadata</h2>
<ul>
<li>Status: proposed</li>
<li>Deciders: V-Sekai, fire</li>
<li>Tags: V-Sekai, Chatbot GPT4 assistance</li>
</ul>
</section>
<section id="context-and-problem-statement" class="level2">
<h2 class="anchored" data-anchor-id="context-and-problem-statement">Context and Problem Statement</h2>
<p>Enable creation of more dynamic and engaging environments within V-Sekai.</p>
</section>
<section id="proposed-solution" class="level2">
<h2 class="anchored" data-anchor-id="proposed-solution">Proposed Solution</h2>
<p>V-Sekai, an open-source virtual reality platform, aims to deliver a user-friendly experience for the VR community. To boost its functionality and compatibility with other tools, we propose integrating networked procedural generation as a sidecar to the Godot engine server, allowing for more dynamic and immersive environments in V-Sekai.</p>
<p>To further address V-Sekai’s limitations, we suggest incorporating the Membrane Framework along with other relevant technologies such as Godot Engine, OpenMfx Support, Elixir Phoenix, and Elixir Nx. This comprehensive integration will not only enhance V-Sekai’s capabilities but also increase its versatility across various use cases.</p>
<p>The implementation involves connecting V-Sekai with the components mentioned in the Membrane Framework diagram below:</p>
<pre class="mermaid"><code>sequenceDiagram
  participant MembraneFramework
  participant WebAndGodotEngineAndBlenderClient
  participant ElixirNx
  participant AIMLFramework
  participant Yugabyte

  rect rgb(240, 248, 255)
    note over MembraneFramework, Yugabyte: Toggle Actions
    MembraneFramework-&gt;&gt;WebAndGodotEngineAndBlenderClient: TOGGLE_GAME_ENGINE_AND_CLIENTS
    MembraneFramework-&gt;&gt;ElixirNx: ACCELERATE_MEMBRANE_FRAMEWORK
    MembraneFramework-&gt;&gt;AIMLFramework: TOGGLE_AIML_FRAMEWORK
    MembraneFramework-&gt;&gt;Yugabyte: TOGGLE_YUGABYTE
  end

  box "Source" #CCFFCC
    participant MembraneFramework
    participant WebAndGodotEngineAndBlenderClient
  end

  box "Filter" #FFFFCC
    participant ElixirNx
    participant AIMLFramework
  end

  box "Sink &amp; Source of Data" #FFCCCC
    participant Yugabyte
  end</code></pre>
<section id="using-read-replicas" class="level3">
<h3 class="anchored" data-anchor-id="using-read-replicas">Using Read Replicas</h3>
<p>We propose using read replicas for applications needing single-zone writes and multi-region reads. Benefits include:</p>
<ul>
<li><strong>Resilience</strong>: Zone-level resilience with primary cluster nodes across multiple zones.</li>
<li><strong>Consistency</strong>: Timeline consistency in replica clusters, better than eventual consistency.</li>
<li><strong>Latency</strong>: Quick reads from primary and replica clusters; write latency depends on client-primary cluster distance.</li>
</ul>
</section>
</section>
<section id="positive-consequences" class="level2">
<h2 class="anchored" data-anchor-id="positive-consequences">Positive Consequences</h2>
<ul>
<li>Improved functionality and versatility of V-Sekai</li>
<li>Enhanced compatibility with other tools and platforms</li>
<li>Greater potential for collaboration and community involvement</li>
</ul>
</section>
<section id="negative-consequences" class="level2">
<h2 class="anchored" data-anchor-id="negative-consequences">Negative Consequences</h2>
<ul>
<li>Increased complexity in implementation and maintenance</li>
<li>Potential performance overhead due to integration of multiple components</li>
</ul>
</section>
<section id="option-graveyard" class="level2">
<h2 class="anchored" data-anchor-id="option-graveyard">Option Graveyard</h2>
<ol type="1">
<li><p><strong>Standalone procedural generation</strong>: Implementing procedural generation as a standalone feature without integrating it with the Godot Engine server. This option was discarded because it would not provide the same level of compatibility and versatility as the proposed solution.</p></li>
<li><p><strong>Using pre-built assets</strong>: Relying on pre-built assets for creating environments instead of implementing networked procedural generation. This option was discarded due to the limited flexibility and potential for repetitive content, which could negatively impact user engagement.</p></li>
<li><p><strong>Third-party procedural generation tools</strong>: Integrating third-party procedural generation tools instead of developing a custom solution. This option was discarded because it may not offer the same level of control and customization required for V-Sekai’s specific needs.</p></li>
<li><p><strong>Static environment design</strong>: Focusing on static environment design rather than dynamic, procedurally generated content. This option was discarded because it would not provide the desired level of immersion and interactivity for V-Sekai users.</p></li>
</ol>
</section>
<section id="if-this-enhancement-will-be-used-infrequently-can-it-be-worked-around-with-a-few-lines-of-script" class="level2">
<h2 class="anchored" data-anchor-id="if-this-enhancement-will-be-used-infrequently-can-it-be-worked-around-with-a-few-lines-of-script">If this enhancement will be used infrequently, can it be worked around with a few lines of script?</h2>
<p>No, the proposed solution involves integrating multiple technologies and cannot be achieved with a simple script workaround.</p>
</section>
<section id="is-there-a-reason-why-this-should-be-core-and-done-by-us" class="level2">
<h2 class="anchored" data-anchor-id="is-there-a-reason-why-this-should-be-core-and-done-by-us">Is there a reason why this should be core and done by us?</h2>
<p>Yes, addressing the limitations of V-Sekai is crucial for its success and adoption within the VR community. By integrating the proposed technologies, we can ensure that V-Sekai remains competitive and relevant in the rapidly evolving VR landscape.</p>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<ul>
<li><a href="https://v-sekai.org/">V-Sekai</a></li>
</ul>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20230619-membrane-framework-for-mesh-processing.html</guid>
  <pubDate>Wed, 19 Jul 2023 23:08:35 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20230618-v-sekai-roadmap.html</link>
  <description><![CDATA[ 



<section id="v-sekai-roadmap-and-goals-2023-06-18" class="level1">
<h1>V-Sekai Roadmap and Goals 2023-06-18</h1>
<section id="metadata" class="level3">
<h3 class="anchored" data-anchor-id="metadata">Metadata</h3>
<ul>
<li>Status: superseded</li>
<li>Deciders: V-Sekai, fire, guillefix</li>
<li>Tags: V-Sekai, chatgpt4 summary,</li>
</ul>
</section>
<section id="context-and-problem-statement" class="level3">
<h3 class="anchored" data-anchor-id="context-and-problem-statement">Context and Problem Statement</h3>
<p>What is the V-Sekai Roadmap and Goals?</p>
</section>
<section id="describe-the-proposed-option-and-how-it-helps-to-overcome-the-problem-or-limitation" class="level3">
<h3 class="anchored" data-anchor-id="describe-the-proposed-option-and-how-it-helps-to-overcome-the-problem-or-limitation">Describe the proposed option and how it helps to overcome the problem or limitation</h3>
<p>The roadmap presented here is short-term.</p>
</section>
<section id="describe-how-your-proposal-will-work-with-code-pseudo-code-mock-ups-or-diagrams" class="level3">
<h3 class="anchored" data-anchor-id="describe-how-your-proposal-will-work-with-code-pseudo-code-mock-ups-or-diagrams">Describe how your proposal will work with code, pseudo-code, mock-ups, or diagrams</h3>
<p>By avoiding work on User Generated Content (UGC) and world building, we can prioritize the three main states in the roadmap: “World / Avatar Performance” (WAP), “Networking” (NET), and “UI/UX”. This allows the team to focus on the core aspects of V-Sekai and achieve the goals more efficiently.</p>
</section>
<section id="goals" class="level3">
<h3 class="anchored" data-anchor-id="goals">Goals</h3>
<section id="world-avatar-performance-wap" class="level4">
<h4 class="anchored" data-anchor-id="world-avatar-performance-wap">World / Avatar Performance (WAP)</h4>
<ul>
<li>Timeline: Q2-Q3</li>
<li>Implement light assets and asynchronous loading to reduce load time by 30%</li>
<li>Utilize modern rendering techniques and high-performance libraries to achieve 60 FPS on mid-range devices</li>
<li>Apply network optimization and low latency protocols for better performance, reducing latency by 50%</li>
</ul>
</section>
<section id="networking-net" class="level4">
<h4 class="anchored" data-anchor-id="networking-net">Networking (NET)</h4>
<ul>
<li>Timeline: Q2-Q3</li>
<li>Use efficient data formats and optimized compression algorithms to reduce file size by 40%</li>
<li>Ensure accurate IK points are respected, achieving 95% accuracy</li>
<li>Explore multiple technologies and alternative solutions for continuous improvement, evaluating 3 new technologies per quarter</li>
</ul>
</section>
<section id="first-time-user-experience-ftux" class="level4">
<h4 class="anchored" data-anchor-id="first-time-user-experience-ftux">First Time User Experience (FTUX)</h4>
<ul>
<li>Timeline: Q3-Q4</li>
<li>Optimize first-time user experience by improving the loading process, increasing user retention by 20%</li>
</ul>
</section>
<section id="diagram" class="level4">
<h4 class="anchored" data-anchor-id="diagram">Diagram</h4>
<pre class="mermaid"><code>sequenceDiagram
    participant V-Sekai
    participant Player
    participant Creator
    participant Lyuma as "Lyuma (VRM1 - WAP)"

    Note over Lyuma: WAP: World / Avatar Performance
    Note over Lyuma: Timeline: Q2-Q3

    Creator-&gt;&gt;V-Sekai: Implement light assets and asynchronous loading (reduce load time by 30%)
    V-Sekai-&gt;&gt;Player: Utilize modern rendering techniques and high-performance libraries (achieve 60 FPS on mid-range devices)
    Player-&gt;&gt;Creator: Apply network optimization and low latency protocols for better performance (reduce latency by 50%)

    Note over Player, Creator: NET: Network Optimization Techniques
    Note over Player, Creator: Timeline: Q2-Q3

    Creator-&gt;&gt;V-Sekai: Use efficient data formats and optimized compression algorithms (reduce file size by 40%)
    V-Sekai-&gt;&gt;Player: Ensure accurate IK points are respected (achieve 95% accuracy)
    V-Sekai-&gt;&gt;Player: Explore multiple technologies and alternative solutions for continuous improvement (evaluate 3 new technologies per quarter)

    %% Metrics
    Note over Player, Creator: Metrics:
    Player-&gt;&gt;Player: File size reduction
    Player-&gt;&gt;Player: IK accuracy
    Player-&gt;&gt;Player: Technologies evaluated
</code></pre>
<pre class="mermaid"><code>sequenceDiagram
    participant Fire
    participant Creator

    Fire-&gt;&gt;Creator: Optimize first-time user experience by improving the loading process (increase user retention by 20%)

    Note over Fire, Creator: FTUX: First Time User Experience
    Note over Fire, Creator: Timeline: Q3-Q4

    %% Metrics
    Note over Fire, Creator: Metrics:
    Fire-&gt;&gt;Fire: Load time reduction
    Fire-&gt;&gt;Fire: Frame rate (FPS) for flat desktop
    Fire-&gt;&gt;Fire: Frame rate (FPS) for VR desktop
    Fire-&gt;&gt;Fire: Latency reduction
    Fire-&gt;&gt;Fire: User retention rate</code></pre>
</section>
</section>
<section id="positive-consequences" class="level3">
<h3 class="anchored" data-anchor-id="positive-consequences">Positive Consequences</h3>
<ul>
<li>Easier creation of V-Sekai.</li>
<li>Focused development on core aspects.</li>
</ul>
</section>
<section id="negative-consequences" class="level3">
<h3 class="anchored" data-anchor-id="negative-consequences">Negative Consequences</h3>
<ul>
<li>Potential overhead challenges.</li>
</ul>
</section>
<section id="option-graveyard" class="level3">
<h3 class="anchored" data-anchor-id="option-graveyard">Option graveyard</h3>
<ul>
<li>Waiting for Godot Engine 4.2 instead of assisting with 4.1 features.</li>
</ul>
</section>
<section id="if-this-enhancement-will-be-used-infrequently-can-it-be-worked-around-with-a-few-lines-of-script" class="level3">
<h3 class="anchored" data-anchor-id="if-this-enhancement-will-be-used-infrequently-can-it-be-worked-around-with-a-few-lines-of-script">If this enhancement will be used infrequently, can it be worked around with a few lines of script?</h3>
<p>No.&nbsp;This is a process.</p>
</section>
<section id="is-there-a-reason-why-this-should-be-core-and-done-by-us" class="level3">
<h3 class="anchored" data-anchor-id="is-there-a-reason-why-this-should-be-core-and-done-by-us">Is there a reason why this should be core and done by us?</h3>
<p>This is a core process for V-Sekai.</p>
</section>
<section id="references" class="level3">
<h3 class="anchored" data-anchor-id="references">References</h3>
<ul>
<li><a href="https://v-sekai.org/">V-Sekai</a></li>
</ul>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20230618-v-sekai-roadmap.html</guid>
  <pubDate>Wed, 19 Jul 2023 23:08:35 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20230616-pmx-to-vrm.html</link>
  <description><![CDATA[ 



<section id="v-sekai-bone-hierarchy-conversion" class="level1">
<h1>V-Sekai Bone Hierarchy Conversion</h1>
<section id="metadata" class="level2">
<h2 class="anchored" data-anchor-id="metadata">Metadata</h2>
<ul>
<li>Status: proposed <!-- draft | proposed | rejected | accepted | deprecated | superseded by --></li>
<li>Deciders: V-Sekai, fire</li>
<li>Tags: V-Sekai, AI Assisted</li>
</ul>
</section>
<section id="problem" class="level2">
<h2 class="anchored" data-anchor-id="problem">Problem</h2>
<p>V-Sekai has a problem with its bone hierarchy conversion. This causes issues with Alicia’s hips-spine angle.</p>
</section>
<section id="solution" class="level2">
<h2 class="anchored" data-anchor-id="solution">Solution</h2>
<p>We suggest a new conversion method. It keeps the original bone hierarchy and translates bone names from Japanese to English. This avoids problems caused by changing the hierarchy.</p>
</section>
<section id="changes" class="level2">
<h2 class="anchored" data-anchor-id="changes">Changes</h2>
<ol type="1">
<li><p>Original hierarchy (Japanese names):</p>
<pre><code>Center (センター)
├ UpperBody (上半身)
└ LowerBody (下半身)</code></pre></li>
<li><p>New method, same hierarchy, translated names:</p>
<pre><code>Center (Hips)
├ UpperBody (Spine)
└ LowerBody (Legs)</code></pre></li>
<li><p>After the second conversion, the hierarchy changes:</p>
<pre><code>Hips (LowerBody)
└ Spine (UpperBody)</code></pre></li>
</ol>
<p>This solution keeps the right hips-spine angle for Alicia.</p>
</section>
<section id="good-outcomes" class="level2">
<h2 class="anchored" data-anchor-id="good-outcomes">Good Outcomes</h2>
<ul>
<li>Keeps the original bone hierarchy, avoiding animation issues.</li>
<li>Translates bone names to English, helping non-Japanese speakers.</li>
</ul>
</section>
<section id="bad-outcomes" class="level2">
<h2 class="anchored" data-anchor-id="bad-outcomes">Bad Outcomes</h2>
<ul>
<li>Might need more time to create the new method.</li>
</ul>
</section>
<section id="other-options" class="level2">
<h2 class="anchored" data-anchor-id="other-options">Other Options</h2>
<ul>
<li>Changing the hierarchy during conversion caused the problem.</li>
</ul>
</section>
<section id="can-it-be-fixed-with-a-script" class="level2">
<h2 class="anchored" data-anchor-id="can-it-be-fixed-with-a-script">Can it be fixed with a script?</h2>
<p>No, this needs a new method in the bone hierarchy conversion process.</p>
</section>
<section id="should-we-do-it" class="level2">
<h2 class="anchored" data-anchor-id="should-we-do-it">Should we do it?</h2>
<p>Yes, it affects character animations and user experience with V-Sekai models.</p>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<ul>
<li><a href="https://v-sekai.org/">V-Sekai</a></li>
</ul>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20230616-pmx-to-vrm.html</guid>
  <pubDate>Wed, 19 Jul 2023 23:08:35 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20230614-llm-statechart.html</link>
  <description><![CDATA[ 



<section id="increase-variety-and-quality-with-generated-animation-trees" class="level1">
<h1>Increase variety and quality with generated animation trees</h1>
<section id="metadata" class="level2">
<h2 class="anchored" data-anchor-id="metadata">Metadata</h2>
<ul>
<li>Status: proposed</li>
<li>Deciders: V-Sekai</li>
<li>Tags: V-Sekai, ai assisted</li>
</ul>
</section>
<section id="context-and-problem-statement" class="level2">
<h2 class="anchored" data-anchor-id="context-and-problem-statement">Context and Problem Statement</h2>
<p>Generate an AnimationTrees with blend trees and nested state machines as a startchart json.</p>
</section>
<section id="proposed-solution" class="level2">
<h2 class="anchored" data-anchor-id="proposed-solution">Proposed Solution</h2>
<p>Create a script that generates a JSON file representing the AnimationTrees structure, including blend trees and nested state machines. This JSON file can then be used to create the corresponding AnimationTrees in the V-Sekai engine.</p>
</section>
<section id="implementation" class="level2">
<h2 class="anchored" data-anchor-id="implementation">Implementation</h2>
<ol type="1">
<li>Define the JSON schema for the AnimationTrees structure.</li>
<li>Create a script that reads the existing AnimationTrees data and converts it into the defined JSON format.</li>
<li>Implement a function in the V-Sekai engine that reads the generated JSON file and creates the corresponding AnimationTrees.</li>
</ol>
</section>
<section id="positive-consequences" class="level2">
<h2 class="anchored" data-anchor-id="positive-consequences">Positive Consequences</h2>
<ul>
<li>Easier management and sharing of AnimationTrees structures.</li>
<li>Simplified collaboration between developers working on the same project.</li>
<li>Potential for automation and procedural generation of AnimationTrees.</li>
</ul>
</section>
<section id="negative-consequences" class="level2">
<h2 class="anchored" data-anchor-id="negative-consequences">Negative Consequences</h2>
<ul>
<li>Additional development time required to implement the JSON conversion script and the corresponding function in the V-Sekai engine.</li>
<li>Possible performance overhead when reading and parsing the JSON file.</li>
</ul>
</section>
<section id="option-graveyard" class="level2">
<h2 class="anchored" data-anchor-id="option-graveyard">Option graveyard</h2>
<ul>
<li>Manually creating and managing AnimationTrees structures without using a JSON representation.</li>
</ul>
</section>
<section id="if-this-enhancement-will-be-used-infrequently-can-it-be-worked-around-with-a-few-lines-of-script" class="level2">
<h2 class="anchored" data-anchor-id="if-this-enhancement-will-be-used-infrequently-can-it-be-worked-around-with-a-few-lines-of-script">If this enhancement will be used infrequently, can it be worked around with a few lines of script?</h2>
<p>No, this enhancement aims to simplify the management and sharing of complex AnimationTrees structures, which cannot be easily achieved with just a few lines of script.</p>
</section>
<section id="is-there-a-reason-why-this-should-be-core-and-done-by-us" class="level2">
<h2 class="anchored" data-anchor-id="is-there-a-reason-why-this-should-be-core-and-done-by-us">Is there a reason why this should be core and done by us?</h2>
<p>Yes, implementing this feature as part of the core V-Sekai engine ensures consistency and compatibility across different projects and developers using the engine.</p>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<ul>
<li><a href="https://v-sekai.org/">V-Sekai</a></li>
<li><a href="https://github.com/1rgs/jsonformer">jsonformer</a></li>
<li><a href="https://python.langchain.com/en/latest/modules/models/llms/integrations/jsonformer_experimental.html">integrations/jsonformer_experimental</a></li>
</ul>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20230614-llm-statechart.html</guid>
  <pubDate>Wed, 19 Jul 2023 23:08:35 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20230611-wasm-in-v-sekai.html</link>
  <description><![CDATA[ 



<section id="wasm-in-v-sekai-proposal" class="level1">
<h1>Wasm in V-Sekai Proposal</h1>
<section id="metadata" class="level2">
<h2 class="anchored" data-anchor-id="metadata">Metadata</h2>
<ul>
<li>Status: proposed</li>
<li>Deciders: V-Sekai, fire</li>
<li>Tags: V-Sekai</li>
</ul>
</section>
<section id="context-and-problem-statement" class="level2">
<h2 class="anchored" data-anchor-id="context-and-problem-statement">Context and Problem Statement</h2>
<p>V-Sekai aims to provide a high-performance platform for virtual worlds and avatar-based social games. The current implementation relies on GDScript or C++ native modules, which may not offer the desired performance, user agency, complex calculations, graphics rendering, and algorithm execution.</p>
</section>
<section id="proposed-solution" class="level2">
<h2 class="anchored" data-anchor-id="proposed-solution">Proposed Solution</h2>
<p>V-Sekai utilizes WebAssembly (Wasm) to enhance performance, offering an alternative to GDScript.</p>
<section id="ownership" class="level3">
<h3 class="anchored" data-anchor-id="ownership">Ownership</h3>
<ul>
<li>Core modules: Owned by V-Sekai</li>
<li>Custom modules: Owned by users</li>
</ul>
</section>
<section id="security" class="level3">
<h3 class="anchored" data-anchor-id="security">Security</h3>
<p>User-uploaded Wasm modules undergo a two-step process for safety and unauthorized access prevention:</p>
<ol type="1">
<li><strong>Validation</strong>: Ensure module structure and integrity adhere to security standards.</li>
<li><strong>Sandboxing</strong>: Confine modules in a secure environment, restricting system resource access and mitigating potential harm.</li>
</ol>
</section>
<section id="functionality" class="level3">
<h3 class="anchored" data-anchor-id="functionality">Functionality</h3>
<p>Wasm modules facilitate advanced functions in virtual worlds and avatar-based social games, such as:</p>
<ul>
<li>Efficient character animations</li>
<li>Interactive environments</li>
<li>Real-time multiplayer networking</li>
<li>Immersive gameplay experiences</li>
</ul>
</section>
</section>
<section id="implementation" class="level2">
<h2 class="anchored" data-anchor-id="implementation">Implementation</h2>
<p>The proposed solution uses WebAssembly (Wasm) to enhance performance and functionality in V-Sekai through User-Generated Content (UGC) Wasm modules. These modules are attached to an existing base node as a script, enabling them to provide property data and behavior for nodes in the virtual world or game.</p>
<p>Here’s a concise explanation of the implementation:</p>
<ol type="1">
<li><strong>User uploads a Wasm module</strong>: Custom Wasm modules with desired functionality are uploaded to V-Sekai.</li>
<li><strong>Attach Wasm module to a node</strong>: The Wasm module is attached to a node as a script, providing advanced functionality for the node.</li>
<li><strong>Implement behavior within the Variant dictionary</strong>: Node behavior is defined within script variable, enabling Wasm modules to provide both property data and behavior.</li>
<li><strong>Utilize Godot’s set_script property</strong>: Using Godot’s <code>set_script</code> property, Wasm modules are attached to nodes and objects, simplifying dependency handling.</li>
<li><strong>Properties after the set script</strong>: Adding properties directly onto the node after the script = property is set</li>
</ol>
<p>This approach ensures graceful handling of missing resources while offering advanced functionality through user-uploaded Wasm modules.</p>
</section>
<section id="positive-consequences" class="level2">
<h2 class="anchored" data-anchor-id="positive-consequences">Positive Consequences</h2>
<ul>
<li>Improved performance for complex calculations, graphics rendering, and algorithm execution</li>
<li>Greater user control over scripts and customization</li>
<li>Enhanced functionality for virtual worlds and avatar-based social games</li>
</ul>
</section>
<section id="negative-consequences" class="level2">
<h2 class="anchored" data-anchor-id="negative-consequences">Negative Consequences</h2>
<ul>
<li>Potential security risks with user-uploaded Wasm modules</li>
<li>Increased complexity in implementation and maintenance</li>
<li>Ensuring a wasm module has no defects is difficult with or without source code.</li>
</ul>
</section>
<section id="option-graveyard" class="level2">
<h2 class="anchored" data-anchor-id="option-graveyard">Option graveyard</h2>
<ol type="1">
<li><strong>Optimizing GDScript</strong>: Improving the performance of GDScript was considered, but it would not provide the same level of performance boost as WebAssembly.</li>
<li><strong>Using a different scripting language</strong>: Alternative scripting languages like Lua or Python were considered, but they also do not offer the desired performance improvements compared to WebAssembly.</li>
<li><strong>Native code integration</strong>: Integrating native code (C++, Rust, etc.) directly into V-Sekai was considered, but it would increase complexity and maintenance efforts. Additionally, it would not provide the same level of security and sandboxing as WebAssembly.</li>
</ol>
</section>
<section id="if-this-enhancement-will-be-used-infrequently-can-it-be-worked-around-with-a-few-lines-of-script" class="level2">
<h2 class="anchored" data-anchor-id="if-this-enhancement-will-be-used-infrequently-can-it-be-worked-around-with-a-few-lines-of-script">If this enhancement will be used infrequently, can it be worked around with a few lines of script?</h2>
<p>No, the enhancement aims to provide a significant performance boost and advanced functionality that cannot be achieved with a few lines of script.</p>
</section>
<section id="is-there-a-reason-why-this-should-be-core-and-done-by-us" class="level2">
<h2 class="anchored" data-anchor-id="is-there-a-reason-why-this-should-be-core-and-done-by-us">Is there a reason why this should be core and done by us?</h2>
<p>Yes, integrating Wasm into V-Sekai’s core ensures optimal performance and seamless integration with existing systems.</p>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<ul>
<li><a href="https://v-sekai.org/">V-Sekai</a></li>
<li><a href="https://github.com/ashtonmeuser/godot-wasm/issues/43">ashtonmeuser/godot-wasm/issues/43</a></li>
<li>This article was assisted by AI.</li>
</ul>
</section>
<section id="glossary" class="level2">
<h2 class="anchored" data-anchor-id="glossary">Glossary</h2>
<p>Here’s a glossary of definitions to help people understand the terms used in the Wasm in V-Sekai proposal:</p>
<ol type="1">
<li><p><strong>WebAssembly (Wasm)</strong>: A type of code that is more portable than regular code, making games and virtual worlds work better. Originally made for the web.</p></li>
<li><p><strong>GDScript</strong>: A programming language used to make games and apps in the Godot game engine.</p></li>
<li><p><strong>C++ native modules</strong>: Pieces of code written in the C++ programming language that can be added to a game or app to make it work better.</p></li>
<li><p><strong>V-Sekai</strong>: A platform for creating virtual worlds and avatar-based social games.</p></li>
<li><p><strong>Metadata</strong>: Information about something, like who made it and what it’s for.</p></li>
<li><p><strong>Validation</strong>: Checking if something is correct and follows the rules.</p></li>
<li><p><strong>Sandboxing</strong>: Putting something in a safe area where it can’t cause harm or access things it shouldn’t.</p></li>
<li><p><strong>User-Generated Content (UGC)</strong>: Things that people who use a game or app create themselves, like characters, levels, or stories.</p></li>
<li><p><strong>MissingNode</strong>: A part of the game or app that needs a script to tell it what to do.</p></li>
<li><p><strong>MissingResource</strong>: Something that a game or app needs but doesn’t have yet, like an image or sound.</p></li>
<li><p><strong>Variant</strong>: A data type in Godot that can store different kinds of information, like numbers, text, or objects. It is used to represent and manipulate data in various ways within the game engine.</p></li>
<li><p><strong>Node3D</strong>: A point in a 3D space that helps build a virtual world or game.</p></li>
<li><p><strong>Godot</strong>: A free and open-source game engine used to create games and apps.</p></li>
<li><p><strong>Lua</strong>: A programming language often used in game development.</p></li>
<li><p><strong>Python</strong>: A popular programming language used for many purposes, including game development.</p></li>
<li><p><strong>Rust</strong>: A programming language focused on safety and performance, often used for creating fast and reliable software.</p></li>
</ol>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20230611-wasm-in-v-sekai.html</guid>
  <pubDate>Wed, 19 Jul 2023 23:08:35 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20230608-v-sekai-roadmap.html</link>
  <description><![CDATA[ 



<section id="v-sekai-roadmap-and-goals-2023-06-08" class="level1">
<h1>V-Sekai Roadmap and Goals 2023-06-08</h1>
<section id="metadata" class="level3">
<h3 class="anchored" data-anchor-id="metadata">Metadata</h3>
<ul>
<li>Status: superseded by <code>20230618-v-sekai-roadmap.md</code> <!-- draft | proposed | rejected | accepted | deprecated | superseded by --></li>
<li>Deciders: V-Sekai,fire,lyuma,</li>
<li>Tags: V-Sekai,chatgpt4 summary,</li>
</ul>
</section>
<section id="context-and-problem-statement" class="level3">
<h3 class="anchored" data-anchor-id="context-and-problem-statement">Context and Problem Statement</h3>
<p>What is the V-Sekai Roadmap and Goals?</p>
</section>
<section id="describe-the-proposed-option-and-how-it-helps-to-overcome-the-problem-or-limitation" class="level3">
<h3 class="anchored" data-anchor-id="describe-the-proposed-option-and-how-it-helps-to-overcome-the-problem-or-limitation">Describe the proposed option and how it helps to overcome the problem or limitation</h3>
<p>The roadmap presented here is short-term.</p>
</section>
<section id="describe-how-your-proposal-will-work-with-code-pseudo-code-mock-ups-or-diagrams" class="level3">
<h3 class="anchored" data-anchor-id="describe-how-your-proposal-will-work-with-code-pseudo-code-mock-ups-or-diagrams">Describe how your proposal will work with code, pseudo-code, mock-ups, or diagrams</h3>
<pre class="mermaid"><code>graph LR
  subgraph Short Term
    A[June 08th, 2023] --&gt; D[IK Points for V-sekai]
    D --&gt; E[Investigate ManyBoneIK &amp; mediapipe to support Facial Mocap to ARKit 52 blendshape and audio to face]
    E --&gt; F[Elixir mvsqlite Serversidecar]
    F --&gt; I[Add jitter buffer to godot_speech]
  end
  subgraph Mid-term Term
    D --&gt; E[Vrm upload to the asset library]
    F --&gt; G[Unidot Unity Import upload to the asset library]
    G --&gt; H[Add jitter buffer to godot_speech]
    H --&gt; I[Implement onevoip]
  end</code></pre>
</section>
<section id="positive-consequences" class="level3">
<h3 class="anchored" data-anchor-id="positive-consequences">Positive Consequences</h3>
<p>We can create V-Sekai easier.</p>
</section>
<section id="negative-consequences" class="level3">
<h3 class="anchored" data-anchor-id="negative-consequences">Negative Consequences</h3>
<p>Overhead might be hard.</p>
</section>
<section id="option-graveyard" class="level3">
<h3 class="anchored" data-anchor-id="option-graveyard">Option graveyard</h3>
<ul>
<li>Implementing a custom voice chat solution instead of using onevoip</li>
<li>Waiting for Godot Engine 4.2 instead of assisting with 4.1 features</li>
<li>Ignoring SkeletonIK3D issues and focusing on other aspects</li>
</ul>
</section>
<section id="if-this-enhancement-will-be-used-infrequently-can-it-be-worked-around-with-a-few-lines-of-script" class="level3">
<h3 class="anchored" data-anchor-id="if-this-enhancement-will-be-used-infrequently-can-it-be-worked-around-with-a-few-lines-of-script">If this enhancement will be used infrequently, can it be worked around with a few lines of script?</h3>
<p>No.&nbsp;This is a process.</p>
</section>
<section id="is-there-a-reason-why-this-should-be-core-and-done-by-us" class="level3">
<h3 class="anchored" data-anchor-id="is-there-a-reason-why-this-should-be-core-and-done-by-us">Is there a reason why this should be core and done by us?</h3>
<p>This is a core process for V-Sekai.</p>
</section>
<section id="references" class="level3">
<h3 class="anchored" data-anchor-id="references">References</h3>
<ul>
<li><a href="https://v-sekai.org/">V-Sekai</a></li>
</ul>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20230608-v-sekai-roadmap.html</guid>
  <pubDate>Wed, 19 Jul 2023 23:08:35 GMT</pubDate>
</item>
<item>
  <title></title>
  <link>https://v-sekai.github.io/manuals/decisions/20230602-v-sekai-roadmap.html</link>
  <description><![CDATA[ 



<section id="v-sekai-roadmap-and-goals-2023-06-02" class="level1">
<h1>V-Sekai Roadmap and Goals 2023-06-02</h1>
<section id="metadata" class="level3">
<h3 class="anchored" data-anchor-id="metadata">Metadata</h3>
<ul>
<li>Status: superseded by <code>20230608-v-sekai-roadmap.md</code> <!-- draft | proposed | rejected | accepted | deprecated | superseded by --></li>
<li>Deciders: V-Sekai, fire, lyuma</li>
<li>Tags: V-Sekai,gpt4 summary</li>
</ul>
</section>
<section id="context-and-problem-statement" class="level3">
<h3 class="anchored" data-anchor-id="context-and-problem-statement">Context and Problem Statement</h3>
<p>What is the V-Sekai Roadmap and Goals?</p>
</section>
<section id="describe-the-proposed-option-and-how-it-helps-to-overcome-the-problem-or-limitation" class="level3">
<h3 class="anchored" data-anchor-id="describe-the-proposed-option-and-how-it-helps-to-overcome-the-problem-or-limitation">Describe the proposed option and how it helps to overcome the problem or limitation</h3>
<p>The roadmap presented here is short-term.</p>
</section>
<section id="describe-how-your-proposal-will-work-with-code-pseudo-code-mock-ups-or-diagrams" class="level3">
<h3 class="anchored" data-anchor-id="describe-how-your-proposal-will-work-with-code-pseudo-code-mock-ups-or-diagrams">Describe how your proposal will work with code, pseudo-code, mock-ups, or diagrams</h3>
<pre class="mermaid"><code>graph LR
  subgraph Short Term
    A[June 02th, 2023] --&gt; E[VRM 1 import and export]
    E --&gt; F[VRM 1 and OMI_personality]
    F --&gt; G[Nightclub aquarium booth 4mx4mx5m]
    G --&gt; H[Add jitter buffer to godot_speech]
    H --&gt; I[Assist with onevoip]
    I --&gt; K[What is stretchsense?]
    K --&gt; L[How can we get more artwork?]
    L --&gt; M[Collective work and other matters?]
  end</code></pre>
</section>
<section id="positive-consequences" class="level3">
<h3 class="anchored" data-anchor-id="positive-consequences">Positive Consequences</h3>
<p>We can create V-Sekai easier.</p>
</section>
<section id="negative-consequences" class="level3">
<h3 class="anchored" data-anchor-id="negative-consequences">Negative Consequences</h3>
<p>Overhead might be hard.</p>
</section>
<section id="option-graveyard" class="level3">
<h3 class="anchored" data-anchor-id="option-graveyard">Option graveyard</h3>
<p>We can avoid planning.</p>
</section>
<section id="if-this-enhancement-will-be-used-infrequently-can-it-be-worked-around-with-a-few-lines-of-script" class="level3">
<h3 class="anchored" data-anchor-id="if-this-enhancement-will-be-used-infrequently-can-it-be-worked-around-with-a-few-lines-of-script">If this enhancement will be used infrequently, can it be worked around with a few lines of script?</h3>
<p>No.&nbsp;This is a process.</p>
</section>
<section id="is-there-a-reason-why-this-should-be-core-and-done-by-us" class="level3">
<h3 class="anchored" data-anchor-id="is-there-a-reason-why-this-should-be-core-and-done-by-us">Is there a reason why this should be core and done by us?</h3>
<p>This is a core process for V-Sekai.</p>
</section>
<section id="references" class="level3">
<h3 class="anchored" data-anchor-id="references">References</h3>
<ul>
<li><a href="https://v-sekai.org/">V-Sekai</a></li>
</ul>


</section>
</section>

 ]]></description>
  <guid>https://v-sekai.github.io/manuals/decisions/20230602-v-sekai-roadmap.html</guid>
  <pubDate>Wed, 19 Jul 2023 23:08:35 GMT</pubDate>
</item>
</channel>
</rss>
