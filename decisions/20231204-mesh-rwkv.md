# Proposed: Triangle Meshes Inferencing with MeshRWKV

## Metadata

- Status: Proposed
- Deciders: V-Sekai
- Tags: V-Sekai

## Background

MeshGPT uses a transformer model trained on geometric vocabulary to generate triangle meshes, resulting in clean, coherent, and compact meshes.

## Problem

The challenge is adapting GPT-like generative models for the 3D domain. Automated triangle mesh generation needs a robust solution.

## Strategy

The MeshRWKV model employs a sequence-based approach that autoregressively generates triangle meshes as sequences of triangles. The conversion process to RWKV4 can be broken down into two primary steps:

### Step 1: Learning a Vocabulary for Triangle Meshes

The initial step involves learning a vocabulary that can accurately represent triangle meshes from a large collection of 3D object meshes. This enables the encoding and decoding of triangles from this embedding.

A graph convolution encoder, specifically a series of SAGE-Conv graph convolution layers, is utilized in this process. This encoder processes the mesh in the form of a face graph. For each graph node, input features include the positionally encoded 9 coordinates of the face triangle, its area, the angles between its edges, and the normal of the face.

These geometrically rich features capture the intricate details of 3D shapes and are quantized as embeddings of a codebook using residual quantization. This effectively reduces the sequence lengths of the mesh representation.

These embeddings are then sequenced and decoded by a 1D ResNet-34 network, which interprets the face features as a 1D sequence. It outputs logits corresponding to the 9 discrete coordinates of each face triangle, which are discretized within a 1283 space. The codebook C has a size of 16384.

### Step 2: Autoregressive Mesh Generation

The next step is to train RWKV4, which leverages these quantized geometric embeddings. Given a sequence of geometric embeddings extracted from the triangles of a mesh, the transformer is trained to predict the codebook index of the next embedding in the sequence.

Once trained, the transformer can be auto-regressively sampled to predict sequences of embeddings. These embeddings can then be decoded to generate novel and diverse mesh structures that display efficient, irregular triangulations similar to human-crafted meshes.

### Ablations in MeshGPT

Table 3 presents a set of ablations on the task of unconditional mesh generation on ShapeNet Chair category. Additional ablations are detailed in the supplementary.

- Replacing naive tokenization with learned tokens and switching from per face quantization to per-vertex quantization significantly enhances shape quality.
- Implementing sequence compression in place of longer sequences prevents the model from forgetting the context and repeating shape elements in the output, thereby improving the model's performance.
- The use of geometric embeddings in vocabulary learning offers substantial improvement over naive coordinate tokenization.
- Opting for a model with a shorter sequence length, as opposed to one without sequence compression, results in better performance as shorter sequence lengths fit transformer context windows more effectively.
- Instead of having the same number of embeddings directly per face, aggregating and quantizing embeddings across vertex indices makes sequences easier to learn with the transformer.
- Using embeddings from the graph encoder and the codebook, rather than only using the codebook indices of these tokens as input to the transformer, proves to be more effective even though the transformer can still learn meaningful embeddings without encoder features.
- Pre-training our GPT transformer on all ShapeNet train shapes, instead of training only on shapes from individual categories, avoids overfitting and leads to optimal performance.

#### Limitations

MeshGPT significantly advances direct mesh generation but faces several limitations. Its autoregressive nature leads to slower sampling performance, with mesh generation times taking 30 to 90 seconds. Despite our learned tokenization approach reducing sequence lengths, which suffices for single object generation, it may not be as effective for scene-scale generation, suggesting an area for future enhancement. Moreover, our current computational resources limit us to using a GPT2-medium transformer, which is smaller than more sophisticated models like Llama2 [58]. Given that larger language models benefit from increased data and computational power, expanding these resources could significantly boost MeshGPT’s performance and capabilities.

### Key Terms

- **Encoder-Decoder Network:** A type of artificial neural network designed to convert inputs into a set of features, and then decode those features to produce a new output.
- **Residual Quantization:** A technique used to reduce the sequence lengths of the mesh representation.
- **1D ResNet34:** A type of convolutional neural network that is used to decode the sequenced embeddings.
- **RWKV4:** A robust and efficient model architecture called Receptance Weighted Key Value (RWKV) that we're using to train our MeshRWKV model for Elixir.
- **MeshRWKV:** The model we're proposing. It's specifically trained for Elixir using RWKV4 and uses an encoder-decoder network with vector quantization to generate triangle meshes from a learned vocabulary.
- **Autoregressive Model:** A type of statistical model used for time series data. In our case, we're using it to generate a mesh based on the sequence of words from our learned vocabulary.
- **Elixir:** A functional, concurrent, general-purpose programming language that runs on the Erlang virtual machine (BEAM). We're training our MeshRWKV model specifically for this language.
- **Triangle Meshes:** A type of polygon mesh commonly used in 3D computer graphics. They're composed entirely of triangular facets. Our model is designed to generate these meshes from a learned vocabulary.
- **Geometric Embeddings:** These are representations of triangles in a high-dimensional space that capture their geometric properties.
- **Graph Convolution Encoder:** This is a type of neural network architecture designed to operate on graph-structured data.
- **Auto-regressive Sampling:** A method of generating new data points based on previously generated ones.

## Benefits

Our approach produces compact meshes with sharp geometric details. It can suggest multiple shape completions for incomplete shapes.

## Drawbacks

Training the model may require significant computational resources. Learning a vocabulary for triangle meshes could be complex.

## Alternatives

Other methods like neural field-based approaches exist but often miss geometric details or produce over-triangulated meshes.

## Special Use Case

Generating complex 3D shapes for niche applications might need additional model training or fine-tuning.

## Core & Implemented by Us?

Yes, this proposal is core to our work at V-Sekai and will be implemented by us.

## References

1. [V-Sekai · GitHub](https://github.com/v-sekai)
2. [V-Sekai/v-sekai-game](https://github.com/v-sekai/v-sekai-game)
3. [MeshGPT](https://nihalsid.github.io/mesh-gpt/)

Assisted by AI assistant Aria.

## MeshGPT's Model and Metrics

In this experiment, a computer model is trained to generate 3D shapes. The training uses a dataset known as ShapeNetV2, which includes various categories of 3D shapes. The model is specifically fine-tuned, meaning it receives special training on four categories: Chair, Table, Bench, and Lamp.

During the training phase, several techniques are employed to enhance the model's ability to create diverse shapes. These techniques include random shifts (altering parts of the shape), scaling (modifying the size of the shape), and planar decimation (simplifying the shape).

The performance of the model is evaluated using several metrics:

- Minimum Matching Distance (MMD): This metric measures how closely the generated shape matches the real one. A lower MMD value indicates a closer match.
- Coverage (COV): This metric assesses how much of the actual shape is covered by the generated shape. A higher COV value is preferable.
- 1-Nearest-Neighbor Accuracy (1-NNA): This metric evaluates how frequently the closest shape to the generated one is the actual one. A score of 50% is considered optimal.
- Chamfer Distance (CD): This is a method for measuring distance in 3D.

To evaluate the visual similarity between the generated shapes and the actual ones, both are rendered as images from eight different viewpoints using a software called Blender. Two scores, FID and KID, are then calculated to measure the similarity between these image sets. Lower FID and KID scores indicate greater similarity.

Lastly, compactness is measured, which is the average number of vertices (corners) and faces (flat surfaces) in the generated shapes.

The results demonstrate that the MeshGPT model outperforms other models in generating high-quality, visually similar, and compact 3D shapes.
